{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yN8p2cmJqrGS"
   },
   "source": [
    "# SageMaker Pipelines to automate the training to deployment processes.\n",
    "\n",
    "1.  **Automated Training Pipeline**: A single SageMaker Pipeline will orchestrate data processing, training multiple models (one for each data version), evaluating them, and registering the best one.\n",
    "2.  **Conditional Model Registration**: The pipeline will only register a model if its performance (accuracy in this case) on the test set meets a predefined threshold.\n",
    "3.  **Automated Deployment**: The best model from the pipeline will be deployed to a SageMaker endpoint for real-time inference.\n",
    "\n",
    "-----\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "  * A running **SageMaker MLflow Tracking Server**. Use the existing one in SageMaker Studio Home Page.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Setup and Configuration\n",
    "\n",
    "First, let's install the necessary libraries and configure our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2obeKal0qrGT"
   },
   "outputs": [],
   "source": [
    "# The SageMaker Studio environment comes with most of these pre-installed.\n",
    "# This cell ensures all dependencies are present.\n",
    "!pip install -q boto3 sagemaker mlflow \"scikit-learn>=1.0\" \"pandas>=1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Ensure MLflow is installed\n",
    "try:\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow\n",
    "except ImportError:\n",
    "    print(\"Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",  \"boto3==1.37.1\", \"botocore==1.37.1\", \"s3transfer\", \"mlflow==2.22.0\", \"sagemaker-mlflow==0.1.0\"])\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show sagemaker_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlLIOYsVqrGU"
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "import os\n",
    "\n",
    "# Setup SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# --- IMPORTANT: CONFIGURE THESE VARIABLES ---\n",
    "s3_bucket = sess.default_bucket()\n",
    "# ----------------------\n",
    "# UPDATE THESE VARIABLES\n",
    "bucket_name = 'sagemaker-iti112-common'  # e.g., 'my-company-sagemaker-bucket'\n",
    "base_folder = '1234567a@nyp.edu.sg'      # e.g., 'users/my-name'\n",
    "# ----------------------\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Define the base path for our datasets if needed\n",
    "data_path = f\"s3://{bucket_name}/{base_folder}/mlflow-demo\"\n",
    "\n",
    "# Assuming you have your boto3 client and server name\n",
    "tracking_server_name = \"mlflow-server-1234567a\"\n",
    "\n",
    "try:\n",
    "    response = sagemaker_client.describe_mlflow_tracking_server(\n",
    "        TrackingServerName=tracking_server_name\n",
    "    )\n",
    "    tracking_server_arn = response['TrackingServerArn']\n",
    "    print(f\"Found MLflow Tracking Server ARN: {tracking_server_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find tracking server: {e}\")\n",
    "    tracking_server_arn = None\n",
    "\n",
    "# ARN of your MLflow Tracking Server\n",
    "# Find this in the SageMaker console or by running `aws sagemaker list-mlflow-tracking-servers`\n",
    "mlflow_tracking_server_arn = tracking_server_arn\n",
    "\n",
    "# IAM role for SageMaker execution\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"S3 Bucket: {data_path}\")\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0KLtPJjqrGV"
   },
   "outputs": [],
   "source": [
    "# Connect to the MLflow Tracking Server\n",
    "# Set the MLflow tracking URI to your managed server\n",
    "if tracking_server_arn:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "    print(\"MLflow tracking URI set successfully.\")\n",
    "\n",
    "# Define an experiment name. If it doesn't exist, MLflow creates it.\n",
    "experiment_name = \"Customer-Churn-Prediction\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow experiment set to: '{experiment_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fedY97ooqrGV"
   },
   "source": [
    "-----\n",
    "\n",
    "### 2\\. Data Versioning Simulation\n",
    "\n",
    "Reproducibility is key in MLOps. We'll simulate two versions of a dataset to see how MLflow can track experiments tied to specific data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ni1o0GqFqrGV"
   },
   "outputs": [],
   "source": [
    "# Create and Upload Data Version 1\n",
    "print(\"Creating data version 1...\")\n",
    "X_v1, y_v1 = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=42)\n",
    "df_v1 = pd.DataFrame(X_v1, columns=[f'feature_{i}' for i in range(10)])\n",
    "df_v1['target'] = y_v1\n",
    "\n",
    "# Define S3 path for v1\n",
    "s3_path_v1 = f\"s3://{s3_bucket}/{base_folder}/mlops-demo/data/v1/data.csv\"\n",
    "data_v1_s3_uri = os.path.dirname(s3_path_v1)\n",
    "\n",
    "# Upload to S3\n",
    "print(f\"Uploading data v1 to {s3_path_v1}\")\n",
    "df_v1.to_csv(s3_path_v1, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kdBq_uPqrGW"
   },
   "outputs": [],
   "source": [
    "# Create and Upload Data Version 2 (a slightly modified version)\n",
    "print(\"Creating data version 2 with more samples...\")\n",
    "X_v2, y_v2 = make_classification(n_samples=1500, n_features=10, n_informative=5, n_redundant=5, random_state=123) # More samples, different seed\n",
    "df_v2 = pd.DataFrame(X_v2, columns=[f'feature_{i}' for i in range(10)])\n",
    "df_v2['target'] = y_v2\n",
    "\n",
    "# Define S3 path for v2\n",
    "s3_path_v2 = f\"s3://{s3_bucket}/{base_folder}/mlops-demo/data/v2/data.csv\"\n",
    "data_v2_s3_uri = os.path.dirname(s3_path_v2) # Log the directory URI\n",
    "\n",
    "# Upload to S3\n",
    "print(f\"Uploading data v2 to {s3_path_v2}\")\n",
    "df_v2.to_csv(s3_path_v2, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSoYELr9qrGW"
   },
   "source": [
    "-----\n",
    "\n",
    "### 3\\. Creating the SageMaker Pipeline\n",
    "\n",
    "Now, we'll create the pipeline scripts that will be executed as steps in our SageMaker Pipeline.\n",
    "\n",
    "#### 3.1. Preprocessing Script\n",
    "\n",
    "This script will take the raw data, split it into training and testing sets, and save them back to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ScNBs_TaqrGX"
   },
   "outputs": [],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-path\", type=str, help=\"Directory containing data.csv\")\n",
    "    parser.add_argument(\"--output-train-path\", type=str, help=\"Output directory for train.csv\")\n",
    "    parser.add_argument(\"--output-test-path\", type=str, help=\"Output directory for test.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Use provided paths or fall back to SageMaker defaults\n",
    "    input_path = args.input_path or \"/opt/ml/processing/input\"\n",
    "    output_train_path = args.output_train_path or \"/opt/ml/processing/train\"\n",
    "    output_test_path = args.output_test_path or \"/opt/ml/processing/test\"\n",
    "\n",
    "    input_file = os.path.join(input_path, \"data.csv\")\n",
    "    print(f\"Reading input file from {input_file}...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    print(\"Splitting into train/test...\")\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    os.makedirs(output_train_path, exist_ok=True)\n",
    "    os.makedirs(output_test_path, exist_ok=True)\n",
    "\n",
    "    train_output = os.path.join(output_train_path, \"train.csv\")\n",
    "    test_output = os.path.join(output_test_path, \"test.csv\")\n",
    "\n",
    "    print(f\"Saving train to {train_output}\")\n",
    "    train.to_csv(train_output, index=False)\n",
    "\n",
    "    print(f\"Saving test to {test_output}\")\n",
    "    test.to_csv(test_output, index=False)\n",
    "\n",
    "    print(\"Preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjXii-anqrGY"
   },
   "source": [
    "#### 3.2. Training Script\n",
    "\n",
    "This script will train a model on the preprocessed data and log the results to MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3==1.28.57\n",
    "botocore==1.31.85\n",
    "\n",
    "mlflow\n",
    "sagemaker-mlflow\n",
    "scikit-learn\n",
    "pandas\n",
    "joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDua4mVRqrGY"
   },
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# # Ensure MLflow is installed\n",
    "try:\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow\n",
    "except ImportError:\n",
    "    print(\"Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",  \"boto3==1.37.1\", \"botocore==1.37.1\", \"s3transfer\", \"mlflow==2.22.0\", \"sagemaker-mlflow==0.1.0\"])\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow\n",
    "    \n",
    "# import mlflow\n",
    "# import sagemaker_mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import glob\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--tracking_server_arn\", type=str, required=True)\n",
    "parser.add_argument(\"--experiment_name\", type=str, default=\"Default\")\n",
    "parser.add_argument(\"--model_output_path\", type=str, default=\"/opt/ml/model\")\n",
    "parser.add_argument(\"-C\", \"--C\", type=float, default=0.5)\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "# Load training data\n",
    "train_path = glob.glob(\"/opt/ml/input/data/train/*.csv\")[0]\n",
    "df = pd.read_csv(train_path)\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_tracking_uri(args.tracking_server_arn)\n",
    "mlflow.set_experiment(args.experiment_name)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_param(\"C\", args.C)\n",
    "    model = LogisticRegression(C=args.C)\n",
    "    model.fit(X, y)\n",
    "    acc = accuracy_score(y, model.predict(X))\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "    mlflow.sklearn.log_model(sk_model=model, artifact_path=\"model\")\n",
    "\n",
    "    os.makedirs(args.model_output_path, exist_ok=True)\n",
    "    joblib.dump(model, os.path.join(args.model_output_path, \"model.joblib\"))\n",
    "    with open(os.path.join(args.model_output_path, \"run_id.txt\"), \"w\") as f:\n",
    "        f.write(run.info.run_id)\n",
    "\n",
    "    print(f\"Training complete. Accuracy: {acc:.4f}\")\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNSpMrDsqrGY"
   },
   "source": [
    "#### 3.3. Evaluation Script\n",
    "\n",
    "This script evaluates the model and creates an evaluation report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8Ed1lCaqrGZ"
   },
   "outputs": [],
   "source": [
    "%%writefile evaluate.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import tarfile\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Parse Arguments ---\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-path\", type=str, required=True, help=\"Path to the directory containing the model.tar.gz file.\")\n",
    "    parser.add_argument(\"--test-path\", type=str, required=True, help=\"Path to the directory containing test.csv.\")\n",
    "    parser.add_argument(\"--output-path\", type=str, required=True, help=\"Path to save the evaluation.json report.\")\n",
    "    parser.add_argument(\"--model-package-group-name\", type=str, required=True, help=\"Name of the SageMaker Model Package Group.\")\n",
    "    parser.add_argument(\"--region\", type=str, required=True, help=\"The AWS region for creating the boto3 client.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # --- Extract and Load Model ---\n",
    "    # SageMaker packages models in a .tar.gz file. We need to extract it first.\n",
    "    model_archive_path = os.path.join(args.model_path, 'model.tar.gz')\n",
    "    print(f\"Extracting model from archive: {model_archive_path}\")\n",
    "    with tarfile.open(model_archive_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=args.model_path)\n",
    "\n",
    "    # Load the model using joblib\n",
    "    model_file_path = os.path.join(args.model_path, \"model.joblib\")\n",
    "    if not os.path.exists(model_file_path):\n",
    "        raise FileNotFoundError(f\"Model file 'model.joblib' not found after extraction in: {args.model_path}\")\n",
    "    \n",
    "    print(f\"Loading model from: {model_file_path}\")\n",
    "    model = joblib.load(model_file_path)\n",
    "\n",
    "    # --- Prepare Data and Evaluate ---\n",
    "    test_file_path = os.path.join(args.test_path, \"test.csv\")\n",
    "    if not os.path.exists(test_file_path):\n",
    "        raise FileNotFoundError(f\"Test data not found: {test_file_path}\")\n",
    "    \n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "    X_test = test_df.drop(\"target\", axis=1)\n",
    "    y_test = test_df[\"target\"]\n",
    "    \n",
    "    print(\"Running predictions on the test dataset.\")\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    report = {\"accuracy\": accuracy}\n",
    "    print(f\"Calculated accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # --- Check for Existing Baseline Model in SageMaker Model Registry ---\n",
    "    print(f\"Checking for baseline model in region: {args.region}\")\n",
    "    sagemaker_client = boto3.client(\"sagemaker\", region_name=args.region)\n",
    "    try:\n",
    "        response = sagemaker_client.list_model_packages(\n",
    "            ModelPackageGroupName=args.model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            SortOrder=\"Descending\",\n",
    "            MaxResults=1,\n",
    "        )\n",
    "        # If the list is not empty, an approved model already exists\n",
    "        report[\"baseline_exists\"] = len(response[\"ModelPackageSummaryList\"]) > 0\n",
    "        if report[\"baseline_exists\"]:\n",
    "            print(f\"An approved baseline model was found in '{args.model_package_group_name}'.\")\n",
    "        else:\n",
    "             print(f\"No approved baseline model was found in '{args.model_package_group_name}'.\")\n",
    "\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        # If the ModelPackageGroup doesn't exist, there is no baseline\n",
    "        if \"ResourceNotFound\" in str(e):\n",
    "            report[\"baseline_exists\"] = False\n",
    "            print(f\"Model Package Group '{args.model_package_group_name}' not found. Assuming no baseline exists.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # --- Write Final Report ---\n",
    "    os.makedirs(args.output_path, exist_ok=True)\n",
    "    report_path = os.path.join(args.output_path, \"evaluation.json\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "        \n",
    "    print(f\"âœ… Evaluation complete. Report written to: {report_path}\")\n",
    "    print(\"Evaluation Report:\")\n",
    "    print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQFqaaTJqrGZ"
   },
   "source": [
    "### 3.4. Pipeline Definition\n",
    "\n",
    "Now, we'll define the SageMaker Pipeline using the scripts we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJVkKxWbqrGZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, TrainingInput\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.conditions import ConditionNot\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionEquals\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.parameters import ParameterFloat, ParameterString\n",
    "from sagemaker.model_metrics import ModelMetrics, FileSource\n",
    "\n",
    "# Parameters\n",
    "model_package_group_name = \"ChurnPredictorModels\"\n",
    "processing_instance_type = \"ml.t3.medium\"\n",
    "training_instance_type = \"ml.m5.large\"\n",
    "experiment_name_param = ParameterString(name=\"ExperimentName\", default_value=\"Customer-Churn-Prediction\")\n",
    "accuracy_threshold_param = ParameterFloat(name=\"AccuracyThreshold\", default_value=0.85)\n",
    "\n",
    "preprocessor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sess.boto_region_name, \"1.2-1\"),\n",
    "    command=[\n",
    "        \"python3\",\n",
    "    ],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"preprocess-data\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_preprocess = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=preprocessor,\n",
    "    inputs=[ProcessingInput(source=data_v2_s3_uri, destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"preprocess.py\",\n",
    ")\n",
    "\n",
    "# Training Step\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"train.py\", \n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=training_instance_type,\n",
    "    role=role,\n",
    "    hyperparameters={\n",
    "        \"tracking_server_arn\": mlflow_tracking_server_arn,\n",
    "        \"experiment_name\": experiment_name_param,\n",
    "        \"C\": 0.5,\n",
    "        \"model_output_path\": \"/opt/ml/model\",\n",
    "    },\n",
    "    py_version=\"py3\",\n",
    "    requirements=\"requirements.txt\" \n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        )\n",
    "    },\n",
    ")\n",
    "\n",
    "# Evaluation Step\n",
    "evaluation_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sess.boto_region_name, \"1.2-1\"),\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"evaluate-model\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")],\n",
    "    code=\"evaluate.py\",  # SageMaker will handle uploading and running this script\n",
    "    job_arguments=[  # Pass arguments here instead of in command\n",
    "        \"--model-path\", \"/opt/ml/processing/model\",\n",
    "        \"--test-path\", \"/opt/ml/processing/test\",\n",
    "        \"--output-path\", \"/opt/ml/processing/evaluation\",\n",
    "        \"--model-package-group-name\", model_package_group_name,\n",
    "        \"--region\", \"ap-southeast-1\",\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "\n",
    "model_metrics_report = ModelMetrics(\n",
    "    model_statistics=FileSource(\n",
    "        s3_uri=step_eval.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# RegisterModel step (always defined, but executed conditionally)\n",
    "step_register_new = RegisterModel(\n",
    "    name=\"RegisterNewModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=\"ChurnPredictorModels\",\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "step_register_better_model = RegisterModel(\n",
    "    name=\"RegisterBetterModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=\"ChurnPredictorModels\",\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "\n",
    "# Conditions: check accuracy > threshold OR no model exists\n",
    "cond_accuracy = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"accuracy\"\n",
    "    ),\n",
    "    right=accuracy_threshold_param\n",
    ")\n",
    "\n",
    "cond_no_registered = ConditionEquals(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"baseline_exists\" # Check the key added to the report\n",
    "    ),\n",
    "    right=False # Condition is TRUE if baseline_exists is False\n",
    ")\n",
    "\n",
    "# Outer step: Checks for existence of registered model first\n",
    "step_cond_accuracy = ConditionStep(\n",
    "    name=\"CheckAccuracy\",\n",
    "    conditions=[cond_accuracy],\n",
    "    if_steps=[step_register_better_model], # Register model if accuracy is high\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "step_cond_no_registered = ConditionStep(\n",
    "    name=\"CheckIfModelExists\",\n",
    "    conditions=[cond_no_registered],\n",
    "    if_steps=[step_register_new], # Register model if no baseline exists\n",
    "    else_steps=[step_cond_accuracy], # Do nothing if a model exists and accuracy was low\n",
    ")\n",
    "\n",
    "# Define Pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=\"ChurnPredictionPipeline\",\n",
    "    parameters=[experiment_name_param, accuracy_threshold_param],\n",
    "    steps=[step_preprocess, step_train, step_eval, step_cond_no_registered] # Use the 'no registered model' check as the primary condition step\n",
    ")\n",
    "\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqKCtZZcqrGa"
   },
   "source": [
    "### 4\\. Automated Deployment with a Second Pipeline\n",
    "\n",
    "Now, let's create a separate pipeline that is triggered by a new model registration. This pipeline will deploy the model to a SageMaker endpoint.\n",
    "\n",
    "#### 4.1. Deployment Script\n",
    "\n",
    "This script will take the registered model and deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1objt2YBqrGa"
   },
   "outputs": [],
   "source": [
    "%%writefile deploy.py\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# --- Install required packages ---\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"boto3==1.28.57\", \"botocore==1.31.57\", \"numpy==1.24.1\", \"sagemaker\" ])\n",
    "\n",
    "# Ensure sagemaker SDK is installed before importing\n",
    "try:\n",
    "    import sagemaker\n",
    "except ImportError:\n",
    "    print(\"sagemaker SDK not found. Installing now...\")\n",
    "    install(\"sagemaker\")\n",
    "    import sagemaker\n",
    "\n",
    "import argparse\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.model import ModelPackage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Accept the registered model's ARN instead of the S3 data path\n",
    "    parser.add_argument(\"--model-package-arn\", type=str, required=True)\n",
    "    parser.add_argument(\"--role\", type=str, required=True)\n",
    "    parser.add_argument(\"--endpoint-name\", type=str, required=True)\n",
    "    parser.add_argument(\"--region\", type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    boto_session = boto3.Session(region_name=args.region)\n",
    "    sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "    # Create a SageMaker Model object directly from the Model Package ARN\n",
    "    model = ModelPackage(\n",
    "        model_package_arn=args.model_package_arn,\n",
    "        role=args.role,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "\n",
    "    # Deploy the model to an endpoint\n",
    "    print(f\"Deploying registered model from ARN to endpoint: {args.endpoint_name}\")\n",
    "    model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.t2.medium\",\n",
    "        endpoint_name=args.endpoint_name,\n",
    "        # Update endpoint if it already exists\n",
    "        update_endpoint=True\n",
    "    )\n",
    "    print(\"Deployment complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQppkx_5qrGa"
   },
   "source": [
    "#### 4.2. Deployment Pipeline Definition\n",
    "\n",
    "This pipeline will be triggered when a new model is registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E3VbMYxqrGb"
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "import sagemaker\n",
    "\n",
    "# Define Parameters for the deployment pipeline\n",
    "# This will be provided by the EventBridge trigger\n",
    "model_package_arn_param = ParameterString(name=\"ModelPackageArn\", default_value=\"\")\n",
    "role_param = ParameterString(name=\"ExecutionRole\", default_value=role)\n",
    "endpoint_name_param = ParameterString(name=\"EndpointName\", default_value=\"churn-predictor-endpoint\")\n",
    "\n",
    "# Create a ScriptProcessor for deployment\n",
    "# Using a more recent scikit-learn version is generally a good idea\n",
    "deploy_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sess.boto_region_name, version=\"1.2-1\"),\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role_param,\n",
    "    base_job_name=\"deploy-registered-model\"\n",
    ")\n",
    "\n",
    "# Define the deployment step that takes the model ARN as an argument\n",
    "step_deploy = ProcessingStep(\n",
    "    name=\"DeployRegisteredModel\",\n",
    "    processor=deploy_processor,\n",
    "    code=\"deploy.py\",\n",
    "    job_arguments=[\n",
    "        \"--model-package-arn\", step_register.properties.ModelPackageArn,\n",
    "        \"--role\", role_param,\n",
    "        \"--endpoint-name\", endpoint_name_param,\n",
    "        \"--region\", \"ap-southeast-1\" \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the independent deployment pipeline\n",
    "deploy_pipeline = Pipeline(\n",
    "    name=\"DeployChurnModelPipeline\",\n",
    "    parameters=[model_package_arn_param, role_param, endpoint_name_param],\n",
    "    steps=[step_deploy]\n",
    ")\n",
    "\n",
    "# Create or update the pipeline definition\n",
    "# Capture the response which contains the ARN\n",
    "response = deploy_pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Extract the ARN from the response dictionary\n",
    "pipeline_arn = response['PipelineArn']\n",
    "\n",
    "print(f\"Deployment pipeline ARN: {pipeline_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize the EventBridge client\n",
    "events_client = boto3.client(\"events\")\n",
    "\n",
    "# Define the event pattern to listen for\n",
    "# This pattern triggers when a model package in your group has its status changed to \"Approved\"\n",
    "event_pattern = {\n",
    "    \"source\": [\"aws.sagemaker\"],\n",
    "    \"detail-type\": [\"SageMaker Model Package State Change\"],\n",
    "    \"detail\": {\n",
    "        \"ModelPackageGroupName\": [model_package_group_name], # From cell 10\n",
    "        \"ModelApprovalStatus\": [\"Approved\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the target for the rule (our deployment pipeline)\n",
    "# We need to map the event's detail to the pipeline's parameters\n",
    "target = {\n",
    "    \"Id\": \"DeployChurnModelPipelineTarget\",\n",
    "    \"Arn\": pipeline_arn, # The ARN of the pipeline we just created\n",
    "    \"RoleArn\": role, # The execution role for the pipeline\n",
    "    \"SageMakerPipelineParameters\": {\n",
    "        \"PipelineParameterList\": [\n",
    "            {\n",
    "                # Map the ARN from the event to the pipeline's \"ModelPackageArn\" parameter\n",
    "                \"Name\": \"ModelPackageArn\",\n",
    "                \"Value\": \"$.detail.ModelPackageArn\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create or update the EventBridge rule\n",
    "try:\n",
    "    username_lower = \"1234567a@nyp.edu.sg\".lower().replace(\"@\", \"-\")\n",
    "    rule_name = f\"{username_lower}-TriggerChurnDeploymentOnApproval\"\n",
    "    print(f\"Creating or updating EventBridge rule: {rule_name}\")\n",
    "    response = events_client.put_rule(\n",
    "        Name=rule_name,\n",
    "        EventPattern=json.dumps(event_pattern),\n",
    "        State=\"ENABLED\",\n",
    "        Description=\"Triggers the SageMaker pipeline to deploy a churn model upon approval.\"\n",
    "    )\n",
    "    \n",
    "    # Add the pipeline as a target for the rule\n",
    "    events_client.put_targets(Rule=rule_name, Targets=[target])\n",
    "    print(\"EventBridge rule created successfully!\")\n",
    "    print(\"Now, when a model is approved in the Model Registry, the deployment pipeline will trigger automatically.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating rule: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Cloudwatch Logs\n",
    "\n",
    "You can view the cloudwatch logs. Here is an example for the logs of a previous endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Enter the name of your SageMaker endpoint\n",
    "endpoint_name = \"sklearn-churn-predictor-v3\"\n",
    "\n",
    "# The log group is created based on the endpoint name\n",
    "log_group_name = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "\n",
    "# Create a CloudWatch Logs client\n",
    "logs_client = boto3.client(\"logs\")\n",
    "\n",
    "print(f\"Searching for logs in: {log_group_name}\\n\")\n",
    "\n",
    "try:\n",
    "    # Find all log streams in the log group, ordered by the most recent\n",
    "    response = logs_client.describe_log_streams(\n",
    "        logGroupName=log_group_name,\n",
    "        orderBy='LastEventTime',\n",
    "        descending=True\n",
    "    )\n",
    "\n",
    "    log_streams = response.get(\"logStreams\", [])\n",
    "\n",
    "    if not log_streams:\n",
    "        print(\"No log streams found. The endpoint might not have processed any requests yet.\")\n",
    "    \n",
    "    # Loop through each stream and print its recent log events\n",
    "    for stream in log_streams:\n",
    "        stream_name = stream['logStreamName']\n",
    "        print(f\"--- Logs from stream: {stream_name} ---\")\n",
    "\n",
    "        # Get log events from the stream\n",
    "        log_events = logs_client.get_log_events(\n",
    "            logGroupName=log_group_name,\n",
    "            logStreamName=stream_name,\n",
    "            startFromHead=False,  # False gets recent logs first\n",
    "            limit=50  # Get up to 50 recent log events\n",
    "        )\n",
    "        \n",
    "        # Print events in chronological order\n",
    "        for event in reversed(log_events.get(\"events\", [])):\n",
    "            print(event['message'].strip())\n",
    "        \n",
    "        print(\"-\" * (len(stream_name) + 24), \"\\n\")\n",
    "\n",
    "except logs_client.exceptions.ResourceNotFoundException:\n",
    "    print(f\"Error: Log group '{log_group_name}' was not found.\")\n",
    "    print(\"Please check the endpoint name and ensure it has been invoked.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4sVmRulqrGb"
   },
   "source": [
    "You can trigger this deployment pipeline manually or set up an EventBridge rule to trigger it automatically whenever a new model version is added to the \"ChurnPredictorModels\" model package group.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "To avoid incurring further charges, you should delete the resources you've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2zH3TbYqrGb"
   },
   "outputs": [],
   "source": [
    "# # Delete the SageMaker endpoint\n",
    "# predictor.delete_endpoint()\n",
    "\n",
    "# # Delete the SageMaker Pipelines\n",
    "# pipeline.delete()\n",
    "# deploy_pipeline.delete()\n",
    "\n",
    "# # Delete the MLflow Tracking Server from the SageMaker console."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
