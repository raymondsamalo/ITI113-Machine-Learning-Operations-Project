{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754bc338",
   "metadata": {},
   "source": [
    "# Manual Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac17cf",
   "metadata": {},
   "source": [
    "We perform manual setup to validate our cloud infrastructure before we create pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b36ef8",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4e9755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"botocore==1.38.23\" boto3 sagemaker mlflow s3fs fsspec \"scikit-learn>=1.0\" \"pandas>=1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc3d58",
   "metadata": {},
   "source": [
    "##  Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481b9455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:11:00.792482Z",
     "iopub.status.busy": "2025-07-24T03:11:00.791881Z",
     "iopub.status.idle": "2025-07-24T03:11:02.641267Z",
     "shell.execute_reply": "2025-07-24T03:11:02.640436Z",
     "shell.execute_reply.started": "2025-07-24T03:11:00.792455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   UDI                      10000 non-null  int64  \n",
      " 1   Product ID               10000 non-null  object \n",
      " 2   Type                     10000 non-null  object \n",
      " 3   Air temperature [K]      10000 non-null  float64\n",
      " 4   Process temperature [K]  10000 non-null  float64\n",
      " 5   Rotational speed [rpm]   10000 non-null  int64  \n",
      " 6   Torque [Nm]              10000 non-null  float64\n",
      " 7   Tool wear [min]          10000 non-null  int64  \n",
      " 8   Machine failure          10000 non-null  int64  \n",
      " 9   TWF                      10000 non-null  int64  \n",
      " 10  HDF                      10000 non-null  int64  \n",
      " 11  PWF                      10000 non-null  int64  \n",
      " 12  OSF                      10000 non-null  int64  \n",
      " 13  RNF                      10000 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "Columns: None\n",
      "Columns: ['UDI', 'Product ID', 'Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
      "First 3 rows:\n",
      "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
      "0    1     M14860    M                298.1                    308.6   \n",
      "1    2     L47181    L                298.2                    308.7   \n",
      "2    3     L47182    L                298.1                    308.5   \n",
      "\n",
      "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
      "0                    1551         42.8                0                0    0   \n",
      "1                    1408         46.3                3                0    0   \n",
      "2                    1498         49.4                5                0    0   \n",
      "\n",
      "   HDF  PWF  OSF  RNF  \n",
      "0    0    0    0    0  \n",
      "1    0    0    0    0  \n",
      "2    0    0    0    0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"ai4i2020.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.info()}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"First 3 rows:\\n{df.head(3)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efe56b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "## This file is created once during manual setup \n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "def unknown_fail_check(row): return ((row['Machine failure'] == 1)\n",
    "                                     & (row['RNF'] == 0)\n",
    "                                     & (row['HDF'] == 0)\n",
    "                                     & (row['TWF'] == 0)\n",
    "                                     & (row['PWF'] == 0)\n",
    "                                     & (row['OSF'] == 0))\n",
    "\n",
    "def pass_yet_fail_check(row): return (row['Machine failure'] == 0) & ((row['RNF'] == 1)\n",
    "                                                                     | (row['HDF'] == 1)\n",
    "                                                                     | (row['TWF'] == 1)\n",
    "                                                                     | (row['PWF'] == 1)\n",
    "                                                                     | (row['OSF'] == 1))\n",
    "def preprocessing(df):\n",
    "    print(\"# Preprocessing\")\n",
    "    df['Type'] = df['Type'].astype('category')\n",
    "    type_mapping = {'L': 0, 'M': 1, 'H': 2}\n",
    "    df['Type'] = df['Type'].map(type_mapping).astype('int')\n",
    "    print(\" Type  Unique Values after encoding: \", df['Type'].unique())\n",
    "    df.drop(columns=['UDI', 'Product ID'], inplace=True)\n",
    "    print(f\"shape of data after dropping columns {df.shape}\")\n",
    "    df.columns = [col.replace(\"[\",\"(\").replace(\"]\",\")\") for col in df.columns.values]\n",
    "    print(\"DF columns after clean up\", df.columns)\n",
    "    print(\"## Handle Duplicates\") \n",
    "    # our original dataset does not have duplicates\n",
    "    # However, there is no guarantee that production/new data is free of duplicates\n",
    "    duplicated_row_count = df.duplicated().sum()\n",
    "    total_row_count = df.shape[0]\n",
    "    duplicated_row_percentage = (duplicated_row_count/total_row_count*100)\n",
    "    print(f\"Total rows count: {total_row_count}\")\n",
    "    print(f\"Duplicated rows count: {duplicated_row_count}\")\n",
    "    print(f\"Duplicated rows percentage: {duplicated_row_percentage}\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"After removing duplicates rows count:\", df.shape[0])\n",
    "    print(\"## Handle NULL\") \n",
    "    print(\"number of null values : \", df.isnull().sum().sum())\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"After removing null rows count:\", df.shape[0])\n",
    "\n",
    "    passed_although_failed = df[pass_yet_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of samples that passed although failed: {len(passed_although_failed)}\")\n",
    "    passed_although_failed.loc[:, ['Machine failure',\n",
    "                                'TWF', 'HDF', 'PWF', 'OSF', 'RNF']].head(10)\n",
    "    df['Machine failure'] = np.where(\n",
    "        pass_yet_fail_check(df), 1, df['Machine failure'])\n",
    "    passed_although_failed = df[pass_yet_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of samples that passed although failed after fix: {len(passed_although_failed)}\")\n",
    "\n",
    "    print(f\"Number of machine failures: {df['Machine failure'].sum()}\")\n",
    "    unknown_failures = df[unknown_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of failures due to unknown reasons: {len(unknown_failures)}\")\n",
    "    unknown_failures.loc[:, ['Machine failure',\n",
    "                            'TWF', 'HDF', 'PWF', 'OSF', 'RNF']].head(10)\n",
    "    df['Machine failure'] = np.where(\n",
    "        unknown_fail_check(df), 0, df['Machine failure'])\n",
    "    unknown_failures = df[unknown_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of failures due to unknown reasons after fix: {len(unknown_failures)}\")\n",
    "    print(\"## Add Features\") \n",
    "    df['Strain (minNm)'] = df['Tool wear (min)'] * df['Torque (Nm)'] \n",
    "    df['Power (W)'] = df['Rotational speed (rpm)'] * df['Torque (Nm)'] * 2 * np.pi / 60\n",
    "    df['Temperature Difference (K)'] = df['Process temperature (K)'] - df['Air temperature (K)']\n",
    "    labels = ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "    print(\"# Splitting into train/test...\")\n",
    "    X = df.drop(columns=labels)\n",
    "    y = df[labels]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42,  stratify=y['Machine failure']) \n",
    "    train=pd.concat([X_train, y_train], axis=1)\n",
    "    test=pd.concat([X_test, y_test], axis=1)\n",
    "    return train, test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # The pipeline will pass arguments to this script.\n",
    "    # The argument will be used to pass the S3 path of our data.\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-path\", type=str, help=\"path containing data.csv\")\n",
    "    parser.add_argument(\"--output-train-path\", type=str, help=\"Output directory for train.csv\")\n",
    "    parser.add_argument(\"--output-test-path\", type=str, help=\"Output directory for test.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    input_path = args.input_path or \"/opt/ml/processing/input\"\n",
    "    output_train_path = args.output_train_path or \"/opt/ml/processing/train\"\n",
    "    output_test_path = args.output_test_path or \"/opt/ml/processing/test\"\n",
    "    print(f\"--- Starting Processing Job ---\")\n",
    "    print(f\"Input path: {input_path}\")\n",
    "    print(f\"Output train path: {output_train_path}\")\n",
    "    print(f\"Output test path: {output_test_path}\")\n",
    "    # Load the dataset\n",
    "    print(f\"Loading data from {input_path}/data.csv\")\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"Input path {input_path} does not exist.\")\n",
    "    if not os.path.exists(os.path.join(input_path, \"data.csv\")):\n",
    "        raise FileNotFoundError(f\"Data file not found in {input_path}. Please check the path.\")\n",
    "    # Read the CSV file \n",
    "    data_path = os.path.join(input_path, \"data.csv\")\n",
    "    df = pd.read_csv(data_path) \n",
    "    # Preprocess\n",
    "    train, test = preprocessing(df)\n",
    "    os.makedirs(output_train_path, exist_ok=True)\n",
    "    os.makedirs(output_test_path, exist_ok=True)\n",
    "    print(f\"Saving train data to {output_train_path}/train.csv\")\n",
    "    train.to_csv(os.path.join(output_train_path, \"train.csv\"), index=False)\n",
    "    print(f\"Saving test data to {output_test_path}/test.csv\")\n",
    "    test.to_csv(os.path.join(output_test_path, \"test.csv\"), index=False)\n",
    "    print(\"--- Processing Job Completed ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689fa19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Preprocessing\n",
      " Type  Unique Values after encoding:  [1 0 2]\n",
      "shape of data after dropping columns (10000, 12)\n",
      "DF columns after clean up Index(['Type', 'Air temperature (K)', 'Process temperature (K)',\n",
      "       'Rotational speed (rpm)', 'Torque (Nm)', 'Tool wear (min)',\n",
      "       'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'],\n",
      "      dtype='object')\n",
      "## Handle Duplicates\n",
      "Total rows count: 10000\n",
      "Duplicated rows count: 0\n",
      "Duplicated rows percentage: 0.0\n",
      "After removing duplicates rows count: 10000\n",
      "## Handle NULL\n",
      "number of null values :  0\n",
      "After removing null rows count: 10000\n",
      "Number of samples that passed although failed: 18\n",
      "Number of samples that passed although failed after fix: 0\n",
      "Number of machine failures: 357\n",
      "Number of failures due to unknown reasons: 9\n",
      "Number of failures due to unknown reasons after fix: 0\n",
      "## Add Features\n",
      "# Splitting into train/test...\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocessing \n",
    "# since we write the preprocess script we can now import it into our notebook\n",
    "train, test= preprocessing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70624031",
   "metadata": {},
   "source": [
    "##  Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "927704d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:11:12.546450Z",
     "iopub.status.busy": "2025-07-24T03:11:12.545712Z",
     "iopub.status.idle": "2025-07-24T03:11:12.550311Z",
     "shell.execute_reply": "2025-07-24T03:11:12.549511Z",
     "shell.execute_reply.started": "2025-07-24T03:11:12.546423Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "base_folder = 'ai4i'      # e.g., 'users/my-name'\n",
    "experiment_name = \"ai4i-Experiment\"  # e.g., 'my-experiment'\n",
    "model_name = \"ai4i-model\"  # e.g., 'my-model'\n",
    "tracking_server_name = \"Team16\"\n",
    "bucket_name=\"iti113-team16-bucket\" # s3://iti113-team16-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d95b6",
   "metadata": {},
   "source": [
    "## Create SageMaker and S3 Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21f88d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:11:18.139819Z",
     "iopub.status.busy": "2025-07-24T03:11:18.139522Z",
     "iopub.status.idle": "2025-07-24T03:11:23.379968Z",
     "shell.execute_reply": "2025-07-24T03:11:23.379034Z",
     "shell.execute_reply.started": "2025-07-24T03:11:18.139781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error initializing SageMaker session or S3 client: Could not connect to the endpoint URL: \"https://sts.ap-souhteast-1.amazonaws.com/\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> in &lt;module&gt;:22                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>s3_data_path = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 # minimize traceback in the output as we are not interested in the details</span>                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> sagemaker_client <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> s3_client:                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>22 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">Exception</span><span style=\"font-weight: bold; text-decoration: underline\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"Failed to initialize SageMaker session or S3 client.\"</span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Exception: </span>Failed to initialize SageMaker session or S3 client.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0mâ•­â”€\u001b[0m\u001b[38;2;255;0;0mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[38;2;255;0;0mâ”€â•®\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m in <module>:22                                                                                   \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m                                                                                                  \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2mâ”‚   \u001b[0ms3_data_path = \u001b[94mNone\u001b[0m                                                                     \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m# minimize traceback in the output as we are not interested in the details\u001b[0m                  \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m   \u001b[2m21 \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m sagemaker_client \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m s3_client:                                                   \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m22 \u001b[2mâ”‚   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mException\u001b[0m\u001b[1;4m(\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mFailed to initialize SageMaker session or S3 client.\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m)\u001b[0m                 \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m   \u001b[2m23 \u001b[0m                                                                                            \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
       "\u001b[1;91mException: \u001b[0mFailed to initialize SageMaker session or S3 client.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sagemaker_client = None\n",
    "s3_client = None\n",
    "try:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sagemaker_client = boto3.client(\"sagemaker\")\n",
    "    s3_bucket = sagemaker_session.default_bucket()\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_data_key=f\"{base_folder}/data/v1/data.csv\"\n",
    "    s3_data_path = f\"s3://{bucket_name}/{s3_data_key}\"\n",
    "    s3_data_dir_uri = f\"s3://{bucket_name}/{base_folder}/data/v1\"\n",
    "    print(f\"Your datasets will be versioned inside: {s3_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SageMaker session or S3 client: {e}\")\n",
    "    s3_data_path = None\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not sagemaker_client or not s3_client:\n",
    "    raise Exception(\"Failed to initialize SageMaker session or S3 client.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb6953",
   "metadata": {},
   "source": [
    "## Connect to Tracking Server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62538491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:11:23.382590Z",
     "iopub.status.busy": "2025-07-24T03:11:23.382292Z",
     "iopub.status.idle": "2025-07-24T03:11:24.068243Z",
     "shell.execute_reply": "2025-07-24T03:11:24.067595Z",
     "shell.execute_reply.started": "2025-07-24T03:11:23.382566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:287730026636:mlflow-tracking-server/mlflow-server-1234567a\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n",
      "S3 Bucket: s3://sagemaker-iti112-common/9002963k@myaccount.nyp.edu.sg/assignment/data/v1/iris_data.csv\n",
      "SageMaker Role ARN: arn:aws:iam::287730026636:role/sagemaker-lab-user-9002963k@myaccount.nyp.edu.sg\n",
      "MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:287730026636:mlflow-tracking-server/mlflow-server-1234567a\n",
      "MLflow tracking URI set successfully.\n",
      "MLflow tracking URI set to: arn:aws:sagemaker:ap-southeast-1:287730026636:mlflow-tracking-server/mlflow-server-1234567a\n",
      "MLflow experiment set to: '9002963k_Iris-Experiment'\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracking_server_arn = None\n",
    "try:\n",
    "    response = sagemaker_client.describe_mlflow_tracking_server(\n",
    "        TrackingServerName=tracking_server_name\n",
    "    )\n",
    "    # ARN of MLflow Tracking Server\n",
    "    mlflow_tracking_server_arn = response['TrackingServerArn']\n",
    "    print(f\"Found MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find tracking server: {e}\")\n",
    "    mlflow_tracking_server_arn = None\n",
    "\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not mlflow_tracking_server_arn:\n",
    "    raise Exception(\"Failed to find MLflow Tracking Server.\")\n",
    "\n",
    "# IAM role for SageMaker execution\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"S3 Bucket: {s3_data_path}\")\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "\n",
    "# Connect to the MLflow Tracking Server\n",
    "# Set the MLflow tracking URI to managed server\n",
    "if mlflow_tracking_server_arn:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "    print(\"MLflow tracking URI set successfully.\")\n",
    "\n",
    "# Define an experiment name. If it doesn't exist, MLflow creates it.\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow experiment set to: '{experiment_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce0ece",
   "metadata": {},
   "source": [
    "## Run Experiments and Track\n",
    "Let us setup our experiments, to simplify we create a function that can be called to run our experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e6d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:14:47.527711Z",
     "iopub.status.busy": "2025-07-24T03:14:47.527310Z",
     "iopub.status.idle": "2025-07-24T03:14:47.534392Z",
     "shell.execute_reply": "2025-07-24T03:14:47.533682Z",
     "shell.execute_reply.started": "2025-07-24T03:14:47.527683Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(experiment_name, run_name, C_param):\n",
    "    print(\"Starting experiment \", experiment_name, \" with run name \", run_name)\n",
    "    run_id = None\n",
    "    accuracy_score = None\n",
    "    # Start an MLflow run\n",
    "    # Use the experiment name and run name to organize runs\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"\\tMLflow Run ID : {run_id}\")\n",
    "        print(f\"\\tRunning experiment: {experiment_name}, Run Name: {run_name}\")\n",
    "        # Train the model\n",
    "        max_iter = 100\n",
    "        model = LogisticRegression(C=C_param, random_state=42,\n",
    "                                   max_iter=max_iter, solver='liblinear')\n",
    "        model.fit(X_train, y_train)\n",
    "        # Evaluate and log metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "        cr = classification_report(y_test, y_pred, \n",
    "                                   output_dict=True, zero_division=0)\n",
    "        accuracy_score = cr.pop(\"accuracy\")\n",
    "        print(f\"\\tModel accuracy: {accuracy_score:.4f}\")\n",
    "        mlflow.log_param(\"C\", C_param)\n",
    "        mlflow.log_param(\"max_iter\", max_iter)\n",
    "        mlflow.log_param(\"solver\", \"liblinear\")\n",
    "        # Logging all metrics in classification_report\n",
    "        mlflow.log_metric(\"accuracy\", accuracy_score)\n",
    "        for class_or_avg, metrics_dict in cr.items():\n",
    "            for metric, value in metrics_dict.items():\n",
    "                metric_name = f\"{class_or_avg}_{metric}\"\n",
    "                mlflow.log_metric(metric_name, value)\n",
    "        # Log the trained model as an artifact\n",
    "        # Provide the first 5 rows of the training data as an example\n",
    "        input_example = X_train.head(5)\n",
    "        mlflow.sklearn.log_model(sk_model=model,artifact_path=model_name,input_example=input_example)\n",
    "        # Get the run ID for later use\n",
    "        print(\"\\tFinished: experiment \", experiment_name, \n",
    "              \" with run name \", run_name)\n",
    "    return run_id, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410ef13",
   "metadata": {},
   "source": [
    "Let's run our experiments while varying the hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15be0a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:14:51.375115Z",
     "iopub.status.busy": "2025-07-24T03:14:51.374560Z",
     "iopub.status.idle": "2025-07-24T03:15:18.528819Z",
     "shell.execute_reply": "2025-07-24T03:15:18.528079Z",
     "shell.execute_reply.started": "2025-07-24T03:14:51.375087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment  9002963k_Iris-Experiment  with run name  C-0-0-1\n",
      "\tMLflow Run ID : d874dbb1fb244edc86842bd30ecf2474\n",
      "\tRunning experiment: 9002963k_Iris-Experiment, Run Name: C-0-0-1\n",
      "\tModel accuracy: 0.6667\n",
      "\tFinished: experiment  9002963k_Iris-Experiment  with run name  C-0-0-1\n",
      "ğŸƒ View run C-0-0-1 at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/70/runs/d874dbb1fb244edc86842bd30ecf2474\n",
      "ğŸ§ª View experiment at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/70\n",
      "Starting experiment  9002963k_Iris-Experiment  with run name  C-0-1-0\n",
      "\tMLflow Run ID : 754689b0eab84ff193db8fc280a2393f\n",
      "\tRunning experiment: 9002963k_Iris-Experiment, Run Name: C-0-1-0\n",
      "\tModel accuracy: 0.8333\n",
      "\tFinished: experiment  9002963k_Iris-Experiment  with run name  C-0-1-0\n",
      "ğŸƒ View run C-0-1-0 at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/70/runs/754689b0eab84ff193db8fc280a2393f\n",
      "ğŸ§ª View experiment at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/70\n",
      "Starting experiment  9002963k_Iris-Experiment  with run name  C-1-0-0\n",
      "\tMLflow Run ID : 2b3a5ec25a6e447f95075b8c929ae7bb\n",
      "\tRunning experiment: 9002963k_Iris-Experiment, Run Name: C-1-0-0\n",
      "\tModel accuracy: 0.9667\n",
      "\tFinished: experiment  9002963k_Iris-Experiment  with run name  C-1-0-0\n",
      "ğŸƒ View run C-1-0-0 at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/70/runs/2b3a5ec25a6e447f95075b8c929ae7bb\n",
      "ğŸ§ª View experiment at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/70\n",
      "Starting experiment  9002963k_Iris-Experiment  with run name  C-10\n",
      "\tMLflow Run ID : d64e0f064b2e4cffa13dc810edfa4e8e\n",
      "\tRunning experiment: 9002963k_Iris-Experiment, Run Name: C-10\n",
      "\tModel accuracy: 0.9667\n",
      "\tFinished: experiment  9002963k_Iris-Experiment  with run name  C-10\n",
      "ğŸƒ View run C-10 at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/70/runs/d64e0f064b2e4cffa13dc810edfa4e8e\n",
      "ğŸ§ª View experiment at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/70\n",
      "Found another run with same accuracy: 0.9667\n",
      "run C-1-0-0 vs run C-10\n",
      "\t Keeping best run C-1-0-0 with smaller C to have simpler model\n",
      "Best run: C-1-0-0 id: 2b3a5ec25a6e447f95075b8c929ae7bb with accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Run experiments with different C parameters\n",
    "#\n",
    "results = {}\n",
    "best_run_id = None\n",
    "best_run_name = None\n",
    "best_accuracy = 0.0\n",
    "best_c_param = None\n",
    "for run_name, C_param in experiments.items():\n",
    "    run_id, accuracy_score = run_experiment(experiment_name, run_name, C_param)\n",
    "    results[run_name] = {\n",
    "        'run_id': run_id,\n",
    "        'accuracy': accuracy_score\n",
    "    }\n",
    "    if best_accuracy < accuracy_score:\n",
    "        best_accuracy = accuracy_score\n",
    "        best_run_id = run_id\n",
    "        best_run_name = run_name\n",
    "        best_c_param = C_param\n",
    "    elif best_accuracy == accuracy_score:\n",
    "        print(f\"Found another run with same accuracy: {accuracy_score:.4f}\")\n",
    "        print(f\"run {best_run_name} vs run {run_name}\")\n",
    "        if best_c_param is None or C_param < best_c_param:\n",
    "            # Update the best run if the C parameter is lower\n",
    "            best_c_param = C_param\n",
    "            best_run_id = run_id\n",
    "            best_run_name = run_name\n",
    "            print(f\"\\t Updating best run to {run_name} with C={C_param} and accuracy={accuracy_score:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\t Keeping best run {best_run_name} with smaller C to have simpler model\")\n",
    "\n",
    "print(f\"Best run: {best_run_name} id: {best_run_id} with accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2d7fb",
   "metadata": {},
   "source": [
    "The best model is the one with the highest accuracy which we store in `best_run_id`.\n",
    "\n",
    "The best model is from the run 'C-1-0-0' with accuracy '0.9667' \n",
    "\n",
    "There is another model with the same accuracy from the run but we prioritise smaller C\n",
    "\n",
    "as it means stronger regularization ( C is inverse regularization )\n",
    "\n",
    "This will help us to get simpler model and less chance of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b031e",
   "metadata": {},
   "source": [
    "### 1.7:  Model Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c9f28",
   "metadata": {},
   "source": [
    "The best model is the one with run_id stored in `best_run_id`\n",
    "Let us save it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fa512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:15:18.530031Z",
     "iopub.status.busy": "2025-07-24T03:15:18.529800Z",
     "iopub.status.idle": "2025-07-24T03:15:18.825298Z",
     "shell.execute_reply": "2025-07-24T03:15:18.824641Z",
     "shell.execute_reply.started": "2025-07-24T03:15:18.530012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model with run ID: 2b3a5ec25a6e447f95075b8c929ae7bb to S3\n",
      "\tRegistering model from URI: runs:/2b3a5ec25a6e447f95075b8c929ae7bb/iris-classifier-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'iris-classifier-model' already exists. Creating a new version of this model...\n",
      "2025/07/24 03:15:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: iris-classifier-model, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel 'iris-classifier-model' registered with version: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'iris-classifier-model'.\n"
     ]
    }
   ],
   "source": [
    "def mlflow_register_model(run_id):\n",
    "    print(f\"Saving model with run ID: {run_id} to S3\")\n",
    "    model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "    print(f\"\\tRegistering model from URI: {model_uri}\")\n",
    "    # Register the model to the MLflow Model Registry\n",
    "    reg_model = mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=model_name\n",
    "    )\n",
    "    print(f\"\\tModel '{model_name}' registered with version: {reg_model.version}\")\n",
    "    return reg_model\n",
    "\n",
    "\n",
    "registered_model = mlflow_register_model(best_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef6b94",
   "metadata": {},
   "source": [
    "Check Model has been Registered properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09893156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:15:23.189139Z",
     "iopub.status.busy": "2025-07-24T03:15:23.188525Z",
     "iopub.status.idle": "2025-07-24T03:15:23.284082Z",
     "shell.execute_reply": "2025-07-24T03:15:23.283105Z",
     "shell.execute_reply.started": "2025-07-24T03:15:23.189108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model S3 Artifact URI: s3://sagemaker-iti112-common/mlflow-1/70/2b3a5ec25a6e447f95075b8c929ae7bb/artifacts/iris-classifier-model\n",
      "Model Version No     : 2\n",
      "Model Version Name   : iris-classifier-model\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "model_version = client.get_model_version(model_name, registered_model.version)\n",
    "model_artifact_s3 = model_version.source\n",
    "model_version_no = model_version.version\n",
    "model_version_name = model_version.name\n",
    "print(\"Model S3 Artifact URI:\", model_artifact_s3)\n",
    "print(\"Model Version No     :\", model_version_no)\n",
    "print(\"Model Version Name   :\", model_version_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b2c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:15:26.620774Z",
     "iopub.status.busy": "2025-07-24T03:15:26.619934Z",
     "iopub.status.idle": "2025-07-24T03:15:27.079995Z",
     "shell.execute_reply": "2025-07-24T03:15:27.079295Z",
     "shell.execute_reply.started": "2025-07-24T03:15:26.620741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cab69b0ff1d4d31911712e843fc0f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact models:/iris-classifier-model/2 downloaded to: /tmp/model\n",
      "Model archive created at: /tmp/model.tar.gz\n",
      "Uploading /tmp/model.tar.gz to s3 with key 9002963k@myaccount.nyp.edu.sg/models/iris-classifier-model-v2/model.tar.gz\n",
      "File /tmp/model.tar.gz uploaded to s3://sagemaker-iti112-common/9002963k@myaccount.nyp.edu.sg/models/iris-classifier-model-v2/model.tar.gz\n",
      "âœ… Compressed model uploaded to: s3://sagemaker-iti112-common/9002963k@myaccount.nyp.edu.sg/models/iris-classifier-model-v2/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "model_s3_uri = None\n",
    "def download_model_artifact(model_version_name,model_version_no, model_folder=\"/tmp/model\"):\n",
    "    \"\"\"\n",
    "    Download the model artifact from the MLflow Model Registry.\n",
    "    \"\"\"\n",
    "    artifact_uri=f\"models:/{model_version_name}/{model_version_no}\"\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    mlflow.artifacts.download_artifacts(\n",
    "        artifact_uri=artifact_uri,\n",
    "        dst_path=model_folder\n",
    "    )\n",
    "    print(f\"Model artifact {artifact_uri} downloaded to: {model_folder}\")\n",
    "\n",
    "# Download the model artifact\n",
    "\n",
    "def create_model_archive(model_folder=\"/tmp/model\", model_tgz_path=\"/tmp/model.tar.gz\"):\n",
    "    \"\"\"\n",
    "    Create a tar.gz archive of the model folder.\n",
    "    \"\"\"\n",
    "    with tarfile.open(model_tgz_path, \"w:gz\") as tar:\n",
    "        tar.add(model_folder, arcname=\".\")\n",
    "    print(f\"Model archive created at: {model_tgz_path}\")\n",
    "\n",
    "def upload_to_s3(local_file, model_version_name, model_version_no):\n",
    "    \"\"\"\n",
    "    Upload a local file to an S3 bucket.\n",
    "    \"\"\"\n",
    "    s3_key = f\"{base_folder}/models/{model_version_name}-v{model_version_no}/model.tar.gz\"\n",
    "    print(f\"Uploading {local_file} to s3 with key {s3_key}\")\n",
    "    model_s3_uri = None\n",
    "    try:\n",
    "        bucket = sagemaker_session.default_bucket() \n",
    "        s3_client.upload_file(local_file, bucket, s3_key)\n",
    "        model_s3_uri = f\"s3://{bucket}/{s3_key}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to S3: {e}\")\n",
    "    # minimize traceback in the output as we are not interested in the details\n",
    "    if not model_s3_uri:\n",
    "        raise Exception(\"Failed to upload model to S3.\")\n",
    "    print(f\"File {local_file} uploaded to {model_s3_uri}\")\n",
    "    return model_s3_uri\n",
    "\n",
    "# Create a compressed archive of the model folder\n",
    "model_folder=\"/tmp/model\"\n",
    "model_tgz_path=\"/tmp/model.tar.gz\"\n",
    "download_model_artifact(model_version_name, model_version_no, model_folder)\n",
    "create_model_archive(model_folder, model_tgz_path)\n",
    "model_s3_uri = upload_to_s3(model_tgz_path, model_version_name, model_version_no)\n",
    "# Upload to S3\n",
    "print(\"âœ… Compressed model uploaded to:\", model_s3_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3514b07",
   "metadata": {},
   "source": [
    "# Part 2: Model Deployment With SageMaker Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d2cf6",
   "metadata": {},
   "source": [
    "We will use `model_s3_uri` from part 1 to load our best model from `best_run_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067fa6fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:44:56.557228Z",
     "iopub.status.busy": "2025-07-22T07:44:56.556926Z",
     "iopub.status.idle": "2025-07-22T07:44:56.562048Z",
     "shell.execute_reply": "2025-07-22T07:44:56.561414Z",
     "shell.execute_reply.started": "2025-07-22T07:44:56.557198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best_run_id: c0a1cd2b43ce4cf69946e0573fc536d2 model_s3_uri: s3://sagemaker-iti112-common/9002963k@myaccount.nyp.edu.sg/models/iris-classifier-model-v1/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(f\" best_run_id: {best_run_id} model_s3_uri: {model_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf4c38-4ebc-455a-a22e-52e580c72232",
   "metadata": {},
   "source": [
    "Next we create entry point script to be hosted as SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2bca6-ff2b-4412-9ea8-1b93ba3c998e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T03:15:34.528956Z",
     "iopub.status.busy": "2025-07-24T03:15:34.528439Z",
     "iopub.status.idle": "2025-07-24T03:15:34.533716Z",
     "shell.execute_reply": "2025-07-24T03:15:34.533042Z",
     "shell.execute_reply.started": "2025-07-24T03:15:34.528932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "# inference.py\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    return joblib.load(os.path.join(model_dir, \"model.pkl\"))\n",
    "\n",
    "def input_fn(request_body, content_type):\n",
    "    if content_type == \"application/json\":\n",
    "        return pd.DataFrame.from_dict(eval(request_body))  # simple eval for test input\n",
    "    raise ValueError(f\"Unsupported content type: {content_type}\")\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    return str(prediction.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad12fd-7a6d-4d8a-b3d9-14ebb124a52b",
   "metadata": {},
   "source": [
    "Deploy our model to SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e8f72-9938-4593-8236-db454ca7903e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T04:06:04.269283Z",
     "iopub.status.busy": "2025-07-24T04:06:04.268610Z",
     "iopub.status.idle": "2025-07-24T04:10:08.670020Z",
     "shell.execute_reply": "2025-07-24T04:10:08.669321Z",
     "shell.execute_reply.started": "2025-07-24T04:06:04.269256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2025-07-24-04-06-05-128\n",
      "INFO:sagemaker:Creating endpoint-config with name sklearn-iris-classifier-endpoint-v2\n",
      "INFO:sagemaker:Creating endpoint with name sklearn-iris-classifier-endpoint-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!Model deployed at endpoint: sklearn-iris-classifier-endpoint-v2\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "# Define the endpoint name\n",
    "endpoint_name = f\"sklearn-iris-classifier-endpoint-v{model_version_no}\"\n",
    "\n",
    "# Create the model object\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_s3_uri,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\", \n",
    "    framework_version=\"1.2-1\",\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy to SageMaker\n",
    "predictor = sklearn_model.deploy(\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "print(f\"Model deployed at endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c36fb1-fbaa-45c8-86fc-8d86785369c9",
   "metadata": {},
   "source": [
    "The following sagemaker api call show the status of our endpoint and its arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854130c-9402-406a-ae39-c720a899cb1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T04:10:29.658607Z",
     "iopub.status.busy": "2025-07-24T04:10:29.658037Z",
     "iopub.status.idle": "2025-07-24T04:10:29.742632Z",
     "shell.execute_reply": "2025-07-24T04:10:29.741781Z",
     "shell.execute_reply.started": "2025-07-24T04:10:29.658580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint sklearn-iris-classifier-endpoint-v2 Status InService\n",
      "\t - ARN arn:aws:sagemaker:ap-southeast-1:287730026636:endpoint/sklearn-iris-classifier-endpoint-v2\n",
      "\t - Name sklearn-iris-classifier-endpoint-v2\n"
     ]
    }
   ],
   "source": [
    "def endpoint_info(endpoint_name):\n",
    "    arn = None\n",
    "    name = None\n",
    "    try:\n",
    "        response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response[\"EndpointStatus\"]\n",
    "        arn = response[\"EndpointArn\"]\n",
    "        name = response[\"EndpointName\"]\n",
    "        if status == \"Failed\":\n",
    "            status = status + \"-\" + response[\"FailureReason\"]\n",
    "    except Exception as e:\n",
    "        status = f\"Exception {e}\"\n",
    "    print(f\"Endpoint {endpoint_name} Status {status}\")\n",
    "    if arn:\n",
    "        print(f\"\\t - ARN {arn}\")\n",
    "    if name:\n",
    "        print(f\"\\t - Name {name}\")\n",
    "\n",
    "endpoint_info(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1170c-d908-4c0e-80e7-e3b6164c03c0",
   "metadata": {},
   "source": [
    "Wait until `endpoint_info(endpoint_name)` show status is InService.\n",
    "\n",
    "It will also log ARN of the endpoint e.g. `arn:aws:sagemaker:ap-southeast-1:287730026636:endpoint/sklearn-iris-classifier-endoint-v2`\n",
    "\n",
    "Once the endpoint is `InService`, let's test it and then clean up our resources to avoid incurring costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10bc47-e436-485e-9c05-9d90d18cb6db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T04:10:34.479093Z",
     "iopub.status.busy": "2025-07-24T04:10:34.478428Z",
     "iopub.status.idle": "2025-07-24T04:10:34.667868Z",
     "shell.execute_reply": "2025-07-24T04:10:34.666937Z",
     "shell.execute_reply.started": "2025-07-24T04:10:34.479066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending payload:\n",
      " {'sepal length (cm)': [4.4, 6.1, 4.9, 5.0, 4.4], 'sepal width (cm)': [3.0, 3.0, 2.4, 2.3, 3.2], 'petal length (cm)': [1.3, 4.9, 3.3, 3.3, 1.3], 'petal width (cm)': [0.2, 1.8, 1.0, 1.0, 0.2]}\n",
      "\n",
      "Received prediction: [0.0, 2.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import StringDeserializer\n",
    "\n",
    "# Create the predictor with JSON handling\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=StringDeserializer()\n",
    ")\n",
    "\n",
    "# Select 5 rows from X_test\n",
    "test_sample = X_test.iloc[:5]\n",
    "\n",
    "# Convert to a dict (records format: {col_name: [v1, v2, ...]})\n",
    "payload = test_sample.to_dict(orient=\"list\")\n",
    "print(\"Sending payload:\\n\", payload)\n",
    "\n",
    "# Make prediction\n",
    "response = predictor.predict(payload)\n",
    "\n",
    "# Print result\n",
    "print(\"\\nReceived prediction:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a9ef2-0a5d-458c-85d3-b3a6435b8ffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T04:10:40.019323Z",
     "iopub.status.busy": "2025-07-24T04:10:40.018878Z",
     "iopub.status.idle": "2025-07-24T04:10:40.370424Z",
     "shell.execute_reply": "2025-07-24T04:10:40.369476Z",
     "shell.execute_reply.started": "2025-07-24T04:10:40.019295Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: sklearn-iris-classifier-endpoint-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting SageMaker endpoint: sklearn-iris-classifier-endpoint-v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: sklearn-iris-classifier-endpoint-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Clean Up Resources\n",
    "print(f\"Deleting SageMaker endpoint: {endpoint_name}...\")\n",
    "predictor.delete_endpoint()\n",
    "print(\"Endpoint deleted successfully.\")\n",
    "\n",
    "# To delete the MLflow Tracking Server, go to the SageMaker console,\n",
    "# find your server, and delete it from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4dbf91",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84bfc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:23:49.352844Z",
     "iopub.status.busy": "2025-07-23T14:23:49.352291Z",
     "iopub.status.idle": "2025-07-23T14:23:49.356595Z",
     "shell.execute_reply": "2025-07-23T14:23:49.355704Z",
     "shell.execute_reply.started": "2025-07-23T14:23:49.352813Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "bucket_name = 'sagemaker-iti112-common'  # e.g., 'my-company-sagemaker-bucket'\n",
    "base_folder = '9002963k@myaccount.nyp.edu.sg'      # e.g., 'users/my-name'\n",
    "experiment_name = \"Iris-Pipeline-Experiment\"  # e.g., 'my-experiment'\n",
    "model_name = \"iris-classifier-pipeline-model\"  # e.g., 'my-model'\n",
    "model_package_group_name = \"IrisClassifierPipelineModels\"\n",
    "pipeline_name = \"IrisClassifierPipeline\"\n",
    "# ----------------------\n",
    "tracking_server_name = \"mlflow-server-1234567a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333828be",
   "metadata": {},
   "source": [
    "## Install dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ba6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:23:53.289640Z",
     "iopub.status.busy": "2025-07-23T14:23:53.289119Z",
     "iopub.status.idle": "2025-07-23T14:23:55.203105Z",
     "shell.execute_reply": "2025-07-23T14:23:55.202344Z",
     "shell.execute_reply.started": "2025-07-23T14:23:53.289612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# The SageMaker Studio environment comes with most of these pre-installed.\n",
    "# This cell ensures all dependencies are present.\n",
    "%pip install -q boto3 sagemaker mlflow \"scikit-learn>=1.0\" \"pandas>=1.2\" \"sagemaker_mlflow==0.1.0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a2b0a",
   "metadata": {},
   "source": [
    "## Session setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af232277",
   "metadata": {},
   "source": [
    "Setup sagemaker and s3 session clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f679a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:23:57.459002Z",
     "iopub.status.busy": "2025-07-23T14:23:57.458626Z",
     "iopub.status.idle": "2025-07-23T14:23:58.126736Z",
     "shell.execute_reply": "2025-07-23T14:23:58.126132Z",
     "shell.execute_reply.started": "2025-07-23T14:23:57.458974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/Ray/Library/Application Support/sagemaker/config.yaml\n",
      "Error initializing SageMaker session or S3 client: Could not connect to the endpoint URL: \"https://sts.ap-souhteast-1.amazonaws.com/\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> in &lt;module&gt;:29                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span>s3_data_path = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 # minimize traceback in the output as we are not interested in the details</span>                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> sagemaker_client <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> s3_client:                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>29 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">Exception</span><span style=\"font-weight: bold; text-decoration: underline\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\"Failed to initialize SageMaker session or S3 client.\"</span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">â”‚</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Exception: </span>Failed to initialize SageMaker session or S3 client.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0mâ•­â”€\u001b[0m\u001b[38;2;255;0;0mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[38;2;255;0;0mâ”€â•®\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m in <module>:29                                                                                   \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m                                                                                                  \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2mâ”‚   \u001b[0ms3_data_path = \u001b[94mNone\u001b[0m                                                                     \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m# minimize traceback in the output as we are not interested in the details\u001b[0m                  \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m   \u001b[2m28 \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m sagemaker_client \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m s3_client:                                                   \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m29 \u001b[2mâ”‚   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mException\u001b[0m\u001b[1;4m(\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mFailed to initialize SageMaker session or S3 client.\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m)\u001b[0m                 \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ”‚\u001b[0m   \u001b[2m30 \u001b[0m                                                                                            \u001b[38;2;255;0;0mâ”‚\u001b[0m\n",
       "\u001b[38;2;255;0;0mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
       "\u001b[1;91mException: \u001b[0mFailed to initialize SageMaker session or S3 client.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "sagemaker_client = None\n",
    "s3_client = None\n",
    "try:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sagemaker_client = boto3.client(\"sagemaker\")\n",
    "    s3_bucket = sagemaker_session.default_bucket()\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_data_key=f\"{base_folder}/data/v1/data.csv\"\n",
    "    s3_data_path = f\"s3://{bucket_name}/{s3_data_key}\"\n",
    "    s3_data_dir_uri = f\"s3://{bucket_name}/{base_folder}/data/v1\"\n",
    "    print(f\"DataSet will be stored inside: {s3_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SageMaker session or S3 client: {e}\")\n",
    "    s3_data_path = None\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not sagemaker_client or not s3_client:\n",
    "    raise Exception(\"Failed to initialize SageMaker session or S3 client.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfd1b6",
   "metadata": {},
   "source": [
    "Setup mlflow client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d27e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T13:16:38.002969Z",
     "iopub.status.busy": "2025-07-23T13:16:38.002663Z",
     "iopub.status.idle": "2025-07-23T13:16:38.562025Z",
     "shell.execute_reply": "2025-07-23T13:16:38.561332Z",
     "shell.execute_reply.started": "2025-07-23T13:16:38.002947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:287730026636:mlflow-tracking-server/mlflow-server-1234567a\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n",
      "SageMaker Role ARN: arn:aws:iam::287730026636:role/sagemaker-lab-user-9002963k@myaccount.nyp.edu.sg\n",
      "MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:287730026636:mlflow-tracking-server/mlflow-server-1234567a\n",
      "MLflow tracking URI set successfully.\n",
      "MLflow tracking URI set to: arn:aws:sagemaker:ap-southeast-1:287730026636:mlflow-tracking-server/mlflow-server-1234567a\n",
      "MLflow experiment set to: '9002963k_Iris-Pipeline-Experiment'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow_tracking_server_arn = None\n",
    "try:\n",
    "    response = sagemaker_client.describe_mlflow_tracking_server(\n",
    "        TrackingServerName=tracking_server_name\n",
    "    )\n",
    "    # ARN of MLflow Tracking Server\n",
    "    mlflow_tracking_server_arn = response['TrackingServerArn']\n",
    "    print(f\"Found MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find tracking server: {e}\")\n",
    "    mlflow_tracking_server_arn = None\n",
    "\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not mlflow_tracking_server_arn:\n",
    "    raise Exception(\"Failed to find MLflow Tracking Server.\")\n",
    "\n",
    "# IAM role for SageMaker execution\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "\n",
    "# Connect to the MLflow Tracking Server\n",
    "# Set the MLflow tracking URI to managed server\n",
    "if mlflow_tracking_server_arn:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "    print(\"MLflow tracking URI set successfully.\")\n",
    "\n",
    "# Define an experiment name. If it doesn't exist, MLflow creates it.\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow experiment set to: '{experiment_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e6dda-51ff-4029-bca6-4ead406782fe",
   "metadata": {},
   "source": [
    "## Upload DataSet To S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96aa4c-acb2-4ce4-b775-4fcada322812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:24:06.735114Z",
     "iopub.status.busy": "2025-07-23T14:24:06.734732Z",
     "iopub.status.idle": "2025-07-23T14:24:06.825982Z",
     "shell.execute_reply": "2025-07-23T14:24:06.825479Z",
     "shell.execute_reply.started": "2025-07-23T14:24:06.735089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset v1.0 created and uploaded to: s3://sagemaker-iti112-common/9002963k@myaccount.nyp.edu.sg/assignment/data/v1/data.csv\n"
     ]
    }
   ],
   "source": [
    "if s3_data_path is None:\n",
    "    raise Exception(\"S3 data path is not set. Cannot proceed with dataset creation.\")\n",
    "df.to_csv(s3_data_path, index=False)\n",
    "print(f\"Dataset v1.0 created and uploaded to: {s3_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699e1a3-1023-429c-8717-5679d80be9f5",
   "metadata": {},
   "source": [
    "Let us test whether we can load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a39b1-031a-416b-98b1-13c64f30aadb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:24:10.860970Z",
     "iopub.status.busy": "2025-07-23T14:24:10.860313Z",
     "iopub.status.idle": "2025-07-23T14:24:10.906400Z",
     "shell.execute_reply": "2025-07-23T14:24:10.905692Z",
     "shell.execute_reply.started": "2025-07-23T14:24:10.860941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded dataset v1.0:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_loaded = pd.read_csv(s3_data_path)\n",
    "    print(\"Successfully loaded dataset v1.0:\")\n",
    "    print(df_loaded.head(1))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"\\nPlease double-check that your bucket and folder names are correct in Step 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b61f3c",
   "metadata": {},
   "source": [
    "## Create the SageMaker Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546bdfb",
   "metadata": {},
   "source": [
    "### Requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b00e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:24:21.712760Z",
     "iopub.status.busy": "2025-07-23T14:24:21.712489Z",
     "iopub.status.idle": "2025-07-23T14:24:21.717234Z",
     "shell.execute_reply": "2025-07-23T14:24:21.716596Z",
     "shell.execute_reply.started": "2025-07-23T14:24:21.712740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3==1.28.57\n",
    "botocore==1.31.85\n",
    "\n",
    "mlflow\n",
    "sagemaker-mlflow\n",
    "scikit-learn\n",
    "pandas\n",
    "joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75c4ee",
   "metadata": {},
   "source": [
    "### Preprocessing script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd761d8",
   "metadata": {},
   "source": [
    "We already create our preprocessing script during manual setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfc8b3",
   "metadata": {},
   "source": [
    "### Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06c0ab-352b-4f33-bffc-7291ce13cbb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:25:19.769522Z",
     "iopub.status.busy": "2025-07-23T14:25:19.769235Z",
     "iopub.status.idle": "2025-07-23T14:25:19.774540Z",
     "shell.execute_reply": "2025-07-23T14:25:19.773741Z",
     "shell.execute_reply.started": "2025-07-23T14:25:19.769503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# # Ensure MLflow is installed\n",
    "try:\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow\n",
    "except ImportError:\n",
    "    print(\"Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",  \"boto3==1.37.1\", \"botocore==1.37.1\", \"s3transfer\", \"mlflow==2.22.0\", \"sagemaker-mlflow==0.1.0\"])\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow\n",
    "    \n",
    "# import mlflow\n",
    "# import sagemaker_mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import glob\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--tracking_server_arn\", type=str, required=True)\n",
    "parser.add_argument(\"--experiment_name\", type=str, default=\"Default\")\n",
    "parser.add_argument(\"--model_output_path\", type=str, default=\"/opt/ml/model\")\n",
    "parser.add_argument(\"-C\", \"--C\", type=float, default=0.5)\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "# Load training data\n",
    "train_path = glob.glob(\"/opt/ml/input/data/train/*.csv\")[0]\n",
    "df = pd.read_csv(train_path)\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_tracking_uri(args.tracking_server_arn)\n",
    "mlflow.set_experiment(args.experiment_name)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_param(\"C\", args.C)\n",
    "    model = LogisticRegression(C=args.C,random_state=42,max_iter=100, solver='liblinear')\n",
    "    model.fit(X, y)\n",
    "    acc = accuracy_score(y, model.predict(X))\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "    mlflow.sklearn.log_model(sk_model=model, artifact_path=\"model\")\n",
    "\n",
    "    os.makedirs(args.model_output_path, exist_ok=True)\n",
    "    joblib.dump(model, os.path.join(args.model_output_path, \"model.joblib\"))\n",
    "    with open(os.path.join(args.model_output_path, \"run_id.txt\"), \"w\") as f:\n",
    "        f.write(run.info.run_id)\n",
    "\n",
    "    print(f\"Training complete. Accuracy: {acc:.4f}\")\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ac900",
   "metadata": {},
   "source": [
    "### Evaluation script\n",
    "\n",
    "Here we create evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebdd63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:25:26.106255Z",
     "iopub.status.busy": "2025-07-23T14:25:26.105852Z",
     "iopub.status.idle": "2025-07-23T14:25:26.113000Z",
     "shell.execute_reply": "2025-07-23T14:25:26.112381Z",
     "shell.execute_reply.started": "2025-07-23T14:25:26.106232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluate.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import tarfile\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Parse Arguments ---\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-path\", type=str, required=True, help=\"Path to the directory containing the model.tar.gz file.\")\n",
    "    parser.add_argument(\"--test-path\", type=str, required=True, help=\"Path to the directory containing test.csv.\")\n",
    "    parser.add_argument(\"--output-path\", type=str, required=True, help=\"Path to save the evaluation.json report.\")\n",
    "    parser.add_argument(\"--model-package-group-name\", type=str, required=True, help=\"Name of the SageMaker Model Package Group.\")\n",
    "    parser.add_argument(\"--region\", type=str, required=True, help=\"The AWS region for creating the boto3 client.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # --- Extract and Load Model ---\n",
    "    # SageMaker packages models in a .tar.gz file. We need to extract it first.\n",
    "    model_archive_path = os.path.join(args.model_path, 'model.tar.gz')\n",
    "    print(f\"Extracting model from archive: {model_archive_path}\")\n",
    "    with tarfile.open(model_archive_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=args.model_path)\n",
    "\n",
    "    # Load the model using joblib\n",
    "    model_file_path = os.path.join(args.model_path, \"model.joblib\")\n",
    "    if not os.path.exists(model_file_path):\n",
    "        raise FileNotFoundError(f\"Model file 'model.joblib' not found after extraction in: {args.model_path}\")\n",
    "    \n",
    "    print(f\"Loading model from: {model_file_path}\")\n",
    "    model = joblib.load(model_file_path)\n",
    "\n",
    "    # --- Prepare Data and Evaluate ---\n",
    "    test_file_path = os.path.join(args.test_path, \"test.csv\")\n",
    "    if not os.path.exists(test_file_path):\n",
    "        raise FileNotFoundError(f\"Test data not found: {test_file_path}\")\n",
    "    \n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "    X_test = test_df.drop(\"target\", axis=1)\n",
    "    y_test = test_df[\"target\"]\n",
    "    \n",
    "    print(\"Running predictions on the test dataset.\")\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    report = {\"accuracy\": accuracy}\n",
    "    print(f\"Calculated accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # --- Check for Existing Baseline Model in SageMaker Model Registry ---\n",
    "    print(f\"Checking for baseline model in region: {args.region}\")\n",
    "    sagemaker_client = boto3.client(\"sagemaker\", region_name=args.region)\n",
    "    try:\n",
    "        response = sagemaker_client.list_model_packages(\n",
    "            ModelPackageGroupName=args.model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            SortOrder=\"Descending\",\n",
    "            MaxResults=1,\n",
    "        )\n",
    "        # If the list is not empty, an approved model already exists\n",
    "        report[\"baseline_exists\"] = len(response[\"ModelPackageSummaryList\"]) > 0\n",
    "        if report[\"baseline_exists\"]:\n",
    "            print(f\"An approved baseline model was found in '{args.model_package_group_name}'.\")\n",
    "        else:\n",
    "             print(f\"No approved baseline model was found in '{args.model_package_group_name}'.\")\n",
    "\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        # If the ModelPackageGroup doesn't exist, there is no baseline\n",
    "        if \"ResourceNotFound\" in str(e):\n",
    "            report[\"baseline_exists\"] = False\n",
    "            print(f\"Model Package Group '{args.model_package_group_name}' not found. Assuming no baseline exists.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # --- Write Final Report ---\n",
    "    os.makedirs(args.output_path, exist_ok=True)\n",
    "    report_path = os.path.join(args.output_path, \"evaluation.json\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "        \n",
    "    print(f\"âœ… Evaluation complete. Report written to: {report_path}\")\n",
    "    print(\"Evaluation Report:\")\n",
    "    print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e4d1a",
   "metadata": {},
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b4939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:25:30.463079Z",
     "iopub.status.busy": "2025-07-23T14:25:30.462799Z",
     "iopub.status.idle": "2025-07-23T14:25:30.468045Z",
     "shell.execute_reply": "2025-07-23T14:25:30.467325Z",
     "shell.execute_reply.started": "2025-07-23T14:25:30.463057Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, TrainingInput\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.conditions import ConditionNot\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionEquals\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.parameters import ParameterFloat, ParameterString\n",
    "from sagemaker.model_metrics import ModelMetrics, FileSource\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02679f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:25:34.541101Z",
     "iopub.status.busy": "2025-07-23T14:25:34.540482Z",
     "iopub.status.idle": "2025-07-23T14:25:34.544211Z",
     "shell.execute_reply": "2025-07-23T14:25:34.543732Z",
     "shell.execute_reply.started": "2025-07-23T14:25:34.541072Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name_param = ParameterString(name=\"ExperimentName\", default_value=experiment_name)\n",
    "accuracy_threshold_param = ParameterFloat(name=\"AccuracyThreshold\", default_value=0.85)\n",
    "pipeline_parameters = [experiment_name_param, accuracy_threshold_param]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0751ec",
   "metadata": {},
   "source": [
    "### Processing Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b50f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:25:37.253262Z",
     "iopub.status.busy": "2025-07-23T14:25:37.252968Z",
     "iopub.status.idle": "2025-07-23T14:25:38.469630Z",
     "shell.execute_reply": "2025-07-23T14:25:38.468917Z",
     "shell.execute_reply.started": "2025-07-23T14:25:37.253239Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
     ]
    }
   ],
   "source": [
    "processing_instance_type = \"ml.t3.medium\" # cheapest $0.063/hour\n",
    "preprocessor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, \"1.2-1\"),\n",
    "    command=[\n",
    "        \"python3\",\n",
    "    ],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"preprocess-data\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_preprocess = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=preprocessor,\n",
    "    inputs=[ProcessingInput(source=s3_data_dir_uri, destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"preprocess.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8554ae",
   "metadata": {},
   "source": [
    "### Training Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9c770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:25:43.960351Z",
     "iopub.status.busy": "2025-07-23T14:25:43.959792Z",
     "iopub.status.idle": "2025-07-23T14:25:45.294951Z",
     "shell.execute_reply": "2025-07-23T14:25:45.294289Z",
     "shell.execute_reply.started": "2025-07-23T14:25:43.960322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
     ]
    }
   ],
   "source": [
    "training_instance_type = \"ml.t3.large\" # second cheapest $0.127/hour\n",
    "\n",
    "# Training Step\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"train.py\", \n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=training_instance_type,\n",
    "    role=role,\n",
    "    hyperparameters={\n",
    "        \"tracking_server_arn\": mlflow_tracking_server_arn,\n",
    "        \"experiment_name\": experiment_name_param,\n",
    "        \"C\": 1.0,\n",
    "        \"model_output_path\": \"/opt/ml/model\",\n",
    "    },\n",
    "    py_version=\"py3\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    depends_on=[step_preprocess]  # Explicitly depends on the preprocess\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004d9f7",
   "metadata": {},
   "source": [
    "### Evaluation Step Defintion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b2f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:25:50.308336Z",
     "iopub.status.busy": "2025-07-23T14:25:50.307983Z",
     "iopub.status.idle": "2025-07-23T14:25:51.561728Z",
     "shell.execute_reply": "2025-07-23T14:25:51.560952Z",
     "shell.execute_reply.started": "2025-07-23T14:25:50.308313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
     ]
    }
   ],
   "source": [
    "evaluation_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, \"1.2-1\"),\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"evaluate-model\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")],\n",
    "    code=\"evaluate.py\",  # SageMaker will handle uploading and running this script\n",
    "    job_arguments=[  # Pass arguments here instead of in command\n",
    "        \"--model-path\", \"/opt/ml/processing/model\",\n",
    "        \"--test-path\", \"/opt/ml/processing/test\",\n",
    "        \"--output-path\", \"/opt/ml/processing/evaluation\",\n",
    "        \"--model-package-group-name\", model_package_group_name,\n",
    "        \"--region\", \"ap-southeast-1\",\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    "    depends_on=[step_train]  # Explicitly depends on the train process\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4994b",
   "metadata": {},
   "source": [
    "### Model Registration Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403732f",
   "metadata": {},
   "source": [
    "The model registration follows the following logic \n",
    "```bash\n",
    "if cond_no_registered \n",
    "   step_register_new\n",
    "else if cond_accuracy \n",
    "   step_register_better_model\n",
    "end if\n",
    "```\n",
    "where :\n",
    "- cond_no_registered check whether existing baseline model exist\n",
    "- cond_accuracy check whether new model has higher accuracy than existing baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8dc392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:25:55.413171Z",
     "iopub.status.busy": "2025-07-23T14:25:55.412898Z",
     "iopub.status.idle": "2025-07-23T14:25:55.420864Z",
     "shell.execute_reply": "2025-07-23T14:25:55.419883Z",
     "shell.execute_reply.started": "2025-07-23T14:25:55.413150Z"
    }
   },
   "outputs": [],
   "source": [
    "# RegisterModel step (always defined, but executed conditionally)\n",
    "model_metrics_report = ModelMetrics(\n",
    "    model_statistics=FileSource(\n",
    "        s3_uri=step_eval.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "step_register_new = RegisterModel(\n",
    "    name=\"RegisterNewModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "step_register_better_model = RegisterModel(\n",
    "    name=\"RegisterBetterModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "\n",
    "# Conditions: check accuracy > threshold OR no model exists\n",
    "cond_accuracy = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"accuracy\"\n",
    "    ),\n",
    "    right=accuracy_threshold_param\n",
    ")\n",
    "\n",
    "cond_no_registered = ConditionEquals(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"baseline_exists\" # Check the key added to the report\n",
    "    ),\n",
    "    right=False # Condition is TRUE if baseline_exists is False\n",
    ")\n",
    "\n",
    "# Outer step: Checks for existence of registered model first\n",
    "step_cond_accuracy = ConditionStep(\n",
    "    name=\"CheckAccuracy\",\n",
    "    conditions=[cond_accuracy],\n",
    "    if_steps=[step_register_better_model], # Register model if accuracy is high\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "step_cond_no_registered = ConditionStep(\n",
    "    name=\"CheckIfModelExists\",\n",
    "    conditions=[cond_no_registered],\n",
    "    if_steps=[step_register_new], # Register model if no baseline exists\n",
    "    else_steps=[step_cond_accuracy], # Do nothing if a model exists and accuracy was low\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d286d5",
   "metadata": {},
   "source": [
    "### Pipeline Definition And Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd971683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:26:16.743435Z",
     "iopub.status.busy": "2025-07-23T14:26:16.743080Z",
     "iopub.status.idle": "2025-07-23T14:26:19.886548Z",
     "shell.execute_reply": "2025-07-23T14:26:19.885909Z",
     "shell.execute_reply.started": "2025-07-23T14:26:16.743411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "# Define steps in the pipeline\n",
    "pipeline_steps = []\n",
    "pipeline_steps.append(step_preprocess)\n",
    "pipeline_steps.append(step_train)\n",
    "pipeline_steps.append(step_eval)\n",
    "pipeline_steps.append(step_cond_no_registered) \n",
    "# Define Pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=pipeline_parameters,\n",
    "    steps=pipeline_steps\n",
    ")\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b36b9",
   "metadata": {},
   "source": [
    "### Pipeline Status or  Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f10d7e-e90f-4e35-88ea-5d2426b9afd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:26:21.836871Z",
     "iopub.status.busy": "2025-07-23T14:26:21.836596Z",
     "iopub.status.idle": "2025-07-23T14:26:21.989983Z",
     "shell.execute_reply": "2025-07-23T14:26:21.989252Z",
     "shell.execute_reply.started": "2025-07-23T14:26:21.836849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active\n"
     ]
    }
   ],
   "source": [
    "def get_pipeline_status()->str:\n",
    "    try:\n",
    "        response = sagemaker_client.describe_pipeline(\n",
    "            PipelineName=pipeline_name\n",
    "        )\n",
    "        result= response[\"PipelineStatus\"]\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'ResourceNotFound':\n",
    "            result= (f\"Pipeline {pipeline_name} not found {e}\")\n",
    "        else:\n",
    "            result= (f\"Unknown error {e.response} {type(e)}\")\n",
    "    return result\n",
    "\n",
    "print(get_pipeline_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a46ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T14:26:13.290259Z",
     "iopub.status.busy": "2025-07-23T14:26:13.289687Z",
     "iopub.status.idle": "2025-07-23T14:26:13.647534Z",
     "shell.execute_reply": "2025-07-23T14:26:13.646903Z",
     "shell.execute_reply.started": "2025-07-23T14:26:13.290230Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.workflow.pipeline:If triggers have been setup for this target, they will become orphaned.You will need to clean them up manually via the CLI or EventBridge console.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline IrisClassifierPipeline not found An error occurred (ResourceNotFound) when calling the DescribePipeline operation: Pipeline 'arn:aws:sagemaker:ap-southeast-1:287730026636:pipeline/IrisClassifierPipeline' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# uncomment this to remove pipeline\n",
    "#pipeline.delete()\n",
    "print(get_pipeline_status())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
