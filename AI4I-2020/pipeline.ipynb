{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754bc338",
   "metadata": {},
   "source": [
    "# Manual Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac17cf",
   "metadata": {},
   "source": [
    "We perform manual run to validate our cloud infrastructure and scripts\n",
    "before we create our pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b36ef8",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a0878c8-ade9-4273-8a26-ade72b2d570a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:05:50.077481Z",
     "iopub.status.busy": "2025-08-20T15:05:50.077235Z",
     "iopub.status.idle": "2025-08-20T15:05:50.083245Z",
     "shell.execute_reply": "2025-08-20T15:05:50.082678Z",
     "shell.execute_reply.started": "2025-08-20T15:05:50.077458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.245.0\n",
      "1.5.1\n",
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import joblib\n",
    "import sagemaker\n",
    "print(sagemaker.__version__)\n",
    "print(joblib.__version__)\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc3d58",
   "metadata": {},
   "source": [
    "##  Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "481b9455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:05:58.275412Z",
     "iopub.status.busy": "2025-08-20T15:05:58.275062Z",
     "iopub.status.idle": "2025-08-20T15:05:58.396130Z",
     "shell.execute_reply": "2025-08-20T15:05:58.395432Z",
     "shell.execute_reply.started": "2025-08-20T15:05:58.275387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   UDI                      10000 non-null  int64  \n",
      " 1   Product ID               10000 non-null  object \n",
      " 2   Type                     10000 non-null  object \n",
      " 3   Air temperature [K]      10000 non-null  float64\n",
      " 4   Process temperature [K]  10000 non-null  float64\n",
      " 5   Rotational speed [rpm]   10000 non-null  int64  \n",
      " 6   Torque [Nm]              10000 non-null  float64\n",
      " 7   Tool wear [min]          10000 non-null  int64  \n",
      " 8   Machine failure          10000 non-null  int64  \n",
      " 9   TWF                      10000 non-null  int64  \n",
      " 10  HDF                      10000 non-null  int64  \n",
      " 11  PWF                      10000 non-null  int64  \n",
      " 12  OSF                      10000 non-null  int64  \n",
      " 13  RNF                      10000 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "Columns: None\n",
      "Columns: ['UDI', 'Product ID', 'Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
      "First 3 rows:\n",
      "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
      "0    1     M14860    M                298.1                    308.6   \n",
      "1    2     L47181    L                298.2                    308.7   \n",
      "2    3     L47182    L                298.1                    308.5   \n",
      "\n",
      "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
      "0                    1551         42.8                0                0    0   \n",
      "1                    1408         46.3                3                0    0   \n",
      "2                    1498         49.4                5                0    0   \n",
      "\n",
      "   HDF  PWF  OSF  RNF  \n",
      "0    0    0    0    0  \n",
      "1    0    0    0    0  \n",
      "2    0    0    0    0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"ai4i2020.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.info()}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"First 3 rows:\\n{df.head(3)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459637f0",
   "metadata": {},
   "source": [
    "## Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b52f1a",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a0385",
   "metadata": {},
   "source": [
    "We write our preprocessing step as a separate script file.\n",
    "\n",
    "We then import the preprocessing function to our notebook.\n",
    "\n",
    "This allows us to re-use it in our pipeline definition later.\n",
    "\n",
    "One drawback is that we need to restart our kernel whenever we update this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efe56b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:06:03.145607Z",
     "iopub.status.busy": "2025-08-20T15:06:03.145246Z",
     "iopub.status.idle": "2025-08-20T15:06:03.160484Z",
     "shell.execute_reply": "2025-08-20T15:06:03.159360Z",
     "shell.execute_reply.started": "2025-08-20T15:06:03.145583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "## This file is created once during manual setup \n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "def unknown_fail_check(row): return ((row['Machine failure'] == 1)\n",
    "                                     & (row['RNF'] == 0)\n",
    "                                     & (row['HDF'] == 0)\n",
    "                                     & (row['TWF'] == 0)\n",
    "                                     & (row['PWF'] == 0)\n",
    "                                     & (row['OSF'] == 0))\n",
    "\n",
    "def pass_yet_fail_check(row): return (row['Machine failure'] == 0) & ((row['RNF'] == 1)\n",
    "                                                                     | (row['HDF'] == 1)\n",
    "                                                                     | (row['TWF'] == 1)\n",
    "                                                                     | (row['PWF'] == 1)\n",
    "                                                                     | (row['OSF'] == 1))\n",
    "def preprocessing(df):\n",
    "    print(\"# Preprocessing\")\n",
    "    df['Type'] = df['Type'].astype('category')\n",
    "    type_mapping = {'L': 0, 'M': 1, 'H': 2}\n",
    "    df['Type'] = df['Type'].map(type_mapping).astype('int')\n",
    "    print(\" Type  Unique Values after encoding: \", df['Type'].unique())\n",
    "    df.drop(columns=['UDI', 'Product ID'], inplace=True)\n",
    "    print(f\"shape of data after dropping columns {df.shape}\")\n",
    "    df.columns = [col.replace(\"[\",\"(\").replace(\"]\",\")\") for col in df.columns.values]\n",
    "    print(\"DF columns after clean up\", df.columns)\n",
    "    print(\"## Handle Duplicates\") \n",
    "    # our original dataset does not have duplicates\n",
    "    # However, there is no guarantee that production/new data is free of duplicates\n",
    "    duplicated_row_count = df.duplicated().sum()\n",
    "    total_row_count = df.shape[0]\n",
    "    duplicated_row_percentage = (duplicated_row_count/total_row_count*100)\n",
    "    print(f\"Total rows count: {total_row_count}\")\n",
    "    print(f\"Duplicated rows count: {duplicated_row_count}\")\n",
    "    print(f\"Duplicated rows percentage: {duplicated_row_percentage}\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"After removing duplicates rows count:\", df.shape[0])\n",
    "    print(\"## Handle NULL\") \n",
    "    print(\"number of null values : \", df.isnull().sum().sum())\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"After removing null rows count:\", df.shape[0])\n",
    "    # declare our target labels columns\n",
    "    labels = ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "    passed_although_failed = df[pass_yet_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of samples that passed although failed: {len(passed_although_failed)}\")\n",
    "    passed_although_failed.loc[:, labels].head(10)\n",
    "    df['Machine failure'] = np.where(\n",
    "        pass_yet_fail_check(df), 1, df['Machine failure'])\n",
    "    passed_although_failed = df[pass_yet_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of samples that passed although failed after fix: {len(passed_although_failed)}\")\n",
    "\n",
    "    print(f\"Number of machine failures: {df['Machine failure'].sum()}\")\n",
    "    unknown_failures = df[unknown_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of failures due to unknown reasons: {len(unknown_failures)}\")\n",
    "    unknown_failures.loc[:, labels].head(10)\n",
    "    df['Machine failure'] = np.where(\n",
    "        unknown_fail_check(df), 0, df['Machine failure'])\n",
    "    unknown_failures = df[unknown_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of failures due to unknown reasons after fix: {len(unknown_failures)}\")\n",
    "    print(\"## Add Features\") \n",
    "    df['Strain (minNm)'] = df['Tool wear (min)'] * df['Torque (Nm)'] \n",
    "    df['Power (W)'] = df['Rotational speed (rpm)'] * df['Torque (Nm)'] * 2 * np.pi / 60\n",
    "    df['Temperature Difference (K)'] = df['Process temperature (K)'] - df['Air temperature (K)']\n",
    "    print(\"columns after new feature : \",df.columns)\n",
    "    print(\"## Drop Redudant Features\")\n",
    "    df.drop(columns=['Torque (Nm)', 'Process temperature (K)', 'Air temperature (K)'], inplace=True)\n",
    "    print(\"columns after drop :\",df.columns)\n",
    "    print(\"## Convert Int to Float for MLFlow\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.int64 or df[col].dtype == np.int32: # Check for common integer types\n",
    "            df[col] = df[col].astype(np.float64)\n",
    "    print(\"# Splitting into train/test...\")\n",
    "    X = df.drop(columns=labels)\n",
    "    y = df[labels]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42,  stratify=y['Machine failure']) \n",
    "    train=pd.concat([X_train, y_train], axis=1)\n",
    "    test=pd.concat([X_test, y_test], axis=1)\n",
    "    return train, test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # The pipeline will pass arguments to this script.\n",
    "    # The argument will be used to pass the S3 path of our data.\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-path\", type=str, help=\"path containing data.csv\")\n",
    "    parser.add_argument(\"--output-train-path\", type=str, help=\"Output directory for train.csv\")\n",
    "    parser.add_argument(\"--output-test-path\", type=str, help=\"Output directory for test.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    input_path = args.input_path or \"/opt/ml/processing/input\"\n",
    "    output_train_path = args.output_train_path or \"/opt/ml/processing/train\"\n",
    "    output_test_path = args.output_test_path or \"/opt/ml/processing/test\"\n",
    "    print(f\"--- Starting Processing Job ---\")\n",
    "    print(f\"Input path: {input_path}\")\n",
    "    print(f\"Output train path: {output_train_path}\")\n",
    "    print(f\"Output test path: {output_test_path}\")\n",
    "    # Load the dataset\n",
    "    print(f\"Loading data from {input_path}/data.csv\")\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"Input path {input_path} does not exist.\")\n",
    "    if not os.path.exists(os.path.join(input_path, \"data.csv\")):\n",
    "        raise FileNotFoundError(f\"Data file not found in {input_path}. Please check the path.\")\n",
    "    # Read the CSV file \n",
    "    data_path = os.path.join(input_path, \"data.csv\")\n",
    "    df = pd.read_csv(data_path) \n",
    "    # Preprocess\n",
    "    train, test = preprocessing(df)\n",
    "    os.makedirs(output_train_path, exist_ok=True)\n",
    "    os.makedirs(output_test_path, exist_ok=True)\n",
    "    print(f\"Saving train data to {output_train_path}/train.csv\")\n",
    "    train.to_csv(os.path.join(output_train_path, \"train.csv\"), index=False)\n",
    "    print(f\"Saving test data to {output_test_path}/test.csv\")\n",
    "    test.to_csv(os.path.join(output_test_path, \"test.csv\"), index=False)\n",
    "    print(\"--- Processing Job Completed ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800be3d1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bda7f984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:06:05.984591Z",
     "iopub.status.busy": "2025-08-20T15:06:05.984243Z",
     "iopub.status.idle": "2025-08-20T15:06:05.992729Z",
     "shell.execute_reply": "2025-08-20T15:06:05.991700Z",
     "shell.execute_reply.started": "2025-08-20T15:06:05.984569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "# # Ensure MLflow is installed\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "try:\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow\n",
    "except ImportError:\n",
    "    print(\"Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
    "                            \"boto3==1.37.1\", \"botocore==1.37.1\", \"s3transfer\",\n",
    "                            \"mlflow==2.22.0\", \"sagemaker-mlflow==0.1.0\"])\n",
    "import mlflow\n",
    "import sagemaker_mlflow\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def train(df, max_depth=5, min_samples_leaf=30, min_samples_split=20):\n",
    "    # declare our target labels columns\n",
    "    labels = ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "    X = df.drop(columns=labels)\n",
    "    y = df[labels]\n",
    "    model = DecisionTreeClassifier(random_state=42,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   min_samples_split=min_samples_split)\n",
    "    model = MultiOutputClassifier(model)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = pd.DataFrame(y_pred, columns=y.columns)\n",
    "    y_pred_omf = y_pred[\"Machine failure\"]\n",
    "    y_omf = y[\"Machine failure\"]\n",
    "    f2 = fbeta_score(y_omf, y_pred_omf, beta=2)\n",
    "    recall = recall_score(y_omf, y_pred_omf)\n",
    "    precision = precision_score(y_omf, y_pred_omf, zero_division=0)\n",
    "    accuracy = accuracy_score(y_omf, y_pred_omf)\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"f2\": f2,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"input_example\": X.head(5)\n",
    "    }\n",
    "\n",
    "\n",
    "def run_experiment(df, experiment_name, run_name=None, model_name=\"model\",\n",
    "                   max_depth=5, min_samples_leaf=30, min_samples_split=20):\n",
    "    print(\"Starting experiment \", experiment_name, \" with run name \", run_name)\n",
    "    run_id = None\n",
    "    # Start an MLflow run\n",
    "    # Use the experiment name and run name to organize runs\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"\\tMLflow Run ID : {run_id}\")\n",
    "        print(f\"\\tRunning experiment: {experiment_name}, Run Name: {run_name}\")\n",
    "        # Train the model\n",
    "        # Provide the first 5 rows of the training data as an example\n",
    "        result = train(df,\n",
    "                       max_depth=max_depth,\n",
    "                       min_samples_leaf=min_samples_leaf,\n",
    "                       min_samples_split=min_samples_split)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
    "        mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "        mlflow.log_metric(\"f2\", result[\"f2\"])\n",
    "        mlflow.log_metric(\"accuracy\", result[\"accuracy\"])\n",
    "        mlflow.log_metric(\"recall\", result[\"recall\"])\n",
    "        mlflow.log_metric(\"precision\", result[\"precision\"])\n",
    "        model = result[\"model\"]\n",
    "       # Train the model\n",
    "        # Provide the first 5 rows of the training data as an example\n",
    "        input_example = result[\"input_example\"]\n",
    "        # Get the run ID for later use\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model, artifact_path=model_name, input_example=input_example)\n",
    "        print(\"\\tFinished: experiment \", experiment_name,\n",
    "              \" with run name \", run_name)\n",
    "    return model, run_id, result[\"accuracy\"], result[\"f2\"]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    # import mlflow\n",
    "    # import sagemaker_mlflow\n",
    "    import mlflow.sklearn\n",
    "    import os\n",
    "    import argparse\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    import glob\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--tracking_server_arn\", type=str, required=True)\n",
    "    parser.add_argument(\"--experiment_name\", type=str, default=\"Default\")\n",
    "    parser.add_argument(\"--model_output_path\", type=str,\n",
    "                        default=\"/opt/ml/model\")\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=5)\n",
    "    parser.add_argument(\"--min_samples_leaf\", type=int, default=30)\n",
    "    parser.add_argument(\"--min_samples_split\", type=int, default=20)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Load training data\n",
    "    train_path = glob.glob(\"/opt/ml/input/data/train/*.csv\")[0]\n",
    "    df = pd.read_csv(train_path)\n",
    "    # Set up MLflow\n",
    "    mlflow.set_tracking_uri(args.tracking_server_arn)\n",
    "    the_model, run_id, accuracy_score, f2_score = run_experiment(df=df,\n",
    "                                                             experiment_name=args.experiment_name,\n",
    "                                                             run_name=\"run_name\",\n",
    "                                                             model_name=\"model\",\n",
    "                                                             max_depth=args.max_depth,\n",
    "                                                             min_samples_leaf=args.min_samples_leaf,\n",
    "                                                             min_samples_split=args.min_samples_split\n",
    "                                                             )\n",
    "    os.makedirs(args.model_output_path, exist_ok=True)\n",
    "    joblib.dump(the_model, os.path.join(args.model_output_path, \"model.joblib\"))\n",
    "    with open(os.path.join(args.model_output_path, \"run_id.txt\"), \"w\") as f:\n",
    "        f.write(run_id)\n",
    "\n",
    "    print(\n",
    "        f\"Training complete. F2:{f2_score:.4f} Accuracy: {accuracy_score:.4f}\")\n",
    "    print(f\"MLflow Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af048e3e",
   "metadata": {},
   "source": [
    "## Preprocessing Manual Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7028cf",
   "metadata": {},
   "source": [
    "Let's import preprocessing function from preprocess.py and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "689fa19f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:06:09.373499Z",
     "iopub.status.busy": "2025-08-20T15:06:09.373121Z",
     "iopub.status.idle": "2025-08-20T15:06:09.431181Z",
     "shell.execute_reply": "2025-08-20T15:06:09.430288Z",
     "shell.execute_reply.started": "2025-08-20T15:06:09.373478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Preprocessing\n",
      " Type  Unique Values after encoding:  [1 0 2]\n",
      "shape of data after dropping columns (10000, 12)\n",
      "DF columns after clean up Index(['Type', 'Air temperature (K)', 'Process temperature (K)',\n",
      "       'Rotational speed (rpm)', 'Torque (Nm)', 'Tool wear (min)',\n",
      "       'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'],\n",
      "      dtype='object')\n",
      "## Handle Duplicates\n",
      "Total rows count: 10000\n",
      "Duplicated rows count: 0\n",
      "Duplicated rows percentage: 0.0\n",
      "After removing duplicates rows count: 10000\n",
      "## Handle NULL\n",
      "number of null values :  0\n",
      "After removing null rows count: 10000\n",
      "Number of samples that passed although failed: 18\n",
      "Number of samples that passed although failed after fix: 0\n",
      "Number of machine failures: 357\n",
      "Number of failures due to unknown reasons: 9\n",
      "Number of failures due to unknown reasons after fix: 0\n",
      "## Add Features\n",
      "columns after new feature :  Index(['Type', 'Air temperature (K)', 'Process temperature (K)',\n",
      "       'Rotational speed (rpm)', 'Torque (Nm)', 'Tool wear (min)',\n",
      "       'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Strain (minNm)',\n",
      "       'Power (W)', 'Temperature Difference (K)'],\n",
      "      dtype='object')\n",
      "## Drop Redudant Features\n",
      "columns after drop : Index(['Type', 'Rotational speed (rpm)', 'Tool wear (min)', 'Machine failure',\n",
      "       'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Strain (minNm)', 'Power (W)',\n",
      "       'Temperature Difference (K)'],\n",
      "      dtype='object')\n",
      "## Convert Int to Float for MLFlow\n",
      "# Splitting into train/test...\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocessing \n",
    "# since we write the preprocess script we can now import it into our notebook\n",
    "train, test= preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca208d98-4cba-4e31-bd0d-f863aefbf97e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:06:13.128022Z",
     "iopub.status.busy": "2025-08-20T15:06:13.127661Z",
     "iopub.status.idle": "2025-08-20T15:06:13.138477Z",
     "shell.execute_reply": "2025-08-20T15:06:13.137534Z",
     "shell.execute_reply.started": "2025-08-20T15:06:13.128001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Type                        10000 non-null  float64\n",
      " 1   Rotational speed (rpm)      10000 non-null  float64\n",
      " 2   Tool wear (min)             10000 non-null  float64\n",
      " 3   Machine failure             10000 non-null  float64\n",
      " 4   TWF                         10000 non-null  float64\n",
      " 5   HDF                         10000 non-null  float64\n",
      " 6   PWF                         10000 non-null  float64\n",
      " 7   OSF                         10000 non-null  float64\n",
      " 8   RNF                         10000 non-null  float64\n",
      " 9   Strain (minNm)              10000 non-null  float64\n",
      " 10  Power (W)                   10000 non-null  float64\n",
      " 11  Temperature Difference (K)  10000 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01a276a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:06:16.335263Z",
     "iopub.status.busy": "2025-08-20T15:06:16.334507Z",
     "iopub.status.idle": "2025-08-20T15:06:30.134939Z",
     "shell.execute_reply": "2025-08-20T15:06:30.134233Z",
     "shell.execute_reply.started": "2025-08-20T15:06:16.335238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment  experiment  with run name  run\n",
      "\tMLflow Run ID : 765a580b22e8434c93a4ee562743fe93\n",
      "\tRunning experiment: experiment, Run Name: run\n",
      "\tFinished: experiment  experiment  with run name  run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MultiOutputClassifier(estimator=DecisionTreeClassifier(max_depth=5,\n",
       "                                                        min_samples_leaf=30,\n",
       "                                                        min_samples_split=20,\n",
       "                                                        random_state=42)),\n",
       " '765a580b22e8434c93a4ee562743fe93',\n",
       " 0.9912,\n",
       " 0.8134684147794994)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train import train, run_experiment\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "run_experiment(df, \"experiment\",\"run\", \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70624031",
   "metadata": {},
   "source": [
    "##  Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "927704d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:06:30.136517Z",
     "iopub.status.busy": "2025-08-20T15:06:30.135969Z",
     "iopub.status.idle": "2025-08-20T15:06:30.142161Z",
     "shell.execute_reply": "2025-08-20T15:06:30.141365Z",
     "shell.execute_reply.started": "2025-08-20T15:06:30.136494Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "base_folder = 'ai4i'      # e.g., 'users/my-name'\n",
    "experiment_name = \"ai4i-Experiment\"  # e.g., 'my-experiment'\n",
    "model_name = \"ai4i-model\"  # e.g., 'my-model'\n",
    "tracking_server_name = \"Team16-MLFlow\"\n",
    "bucket_name=\"iti113-team16-bucket\" # s3://iti113-team16-bucket/ai4i/mlflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d95b6",
   "metadata": {},
   "source": [
    "## Create SageMaker and S3 Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21f88d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:06:52.002300Z",
     "iopub.status.busy": "2025-08-20T15:06:52.001408Z",
     "iopub.status.idle": "2025-08-20T15:06:52.246882Z",
     "shell.execute_reply": "2025-08-20T15:06:52.246145Z",
     "shell.execute_reply.started": "2025-08-20T15:06:52.002265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your datasets will be versioned inside: s3://iti113-team16-bucket/ai4i/data/v1/data.csv\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sagemaker_client = None\n",
    "s3_client = None\n",
    "try:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sagemaker_client = boto3.client(\"sagemaker\")\n",
    "    s3_bucket = sagemaker_session.default_bucket()\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_data_key=f\"{base_folder}/data/v1/data.csv\"\n",
    "    s3_data_path = f\"s3://{bucket_name}/{s3_data_key}\"\n",
    "    s3_data_dir_uri = f\"s3://{bucket_name}/{base_folder}/data/v1\"\n",
    "    print(f\"Your datasets will be versioned inside: {s3_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SageMaker session or S3 client: {e}\")\n",
    "    s3_data_path = None\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not sagemaker_client or not s3_client:\n",
    "    raise Exception(\"Failed to initialize SageMaker session or S3 client.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb6953",
   "metadata": {},
   "source": [
    "## Connect to Tracking Server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62538491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:09:33.340117Z",
     "iopub.status.busy": "2025-08-20T15:09:33.339774Z",
     "iopub.status.idle": "2025-08-20T15:09:33.629397Z",
     "shell.execute_reply": "2025-08-20T15:09:33.628653Z",
     "shell.execute_reply.started": "2025-08-20T15:09:33.340095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "S3 Bucket: s3://iti113-team16-bucket/ai4i/data/v1/data.csv\n",
      "SageMaker Role ARN: arn:aws:iam::837028399719:role/iti113-team16-sagemaker-iti113-team16-domain-iti113-team16-Role\n",
      "MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "MLflow tracking URI set successfully.\n",
      "MLflow tracking URI set to: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "MLflow experiment set to: 'ai4i-Experiment'\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracking_server_arn = None\n",
    "try:\n",
    "    response = sagemaker_client.describe_mlflow_tracking_server(\n",
    "        TrackingServerName=tracking_server_name\n",
    "    )\n",
    "    # ARN of MLflow Tracking Server\n",
    "    mlflow_tracking_server_arn = response['TrackingServerArn']\n",
    "    print(f\"Found MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find tracking server: {e}\")\n",
    "    mlflow_tracking_server_arn = None\n",
    "\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not mlflow_tracking_server_arn:\n",
    "    raise Exception(\"Failed to find MLflow Tracking Server.\")\n",
    "\n",
    "# IAM role for SageMaker execution\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"S3 Bucket: {s3_data_path}\")\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "\n",
    "# Connect to the MLflow Tracking Server\n",
    "# Set the MLflow tracking URI to managed server\n",
    "if mlflow_tracking_server_arn:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "    print(\"MLflow tracking URI set successfully.\")\n",
    "\n",
    "# Define an experiment name. If it doesn't exist, MLflow creates it.\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow experiment set to: '{experiment_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce0ece",
   "metadata": {},
   "source": [
    "## Run Experiments and Track\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410ef13",
   "metadata": {},
   "source": [
    "Let's run our experiments while varying the hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15be0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments with different max_depth parameters\n",
    "#\n",
    "experiments={\n",
    "    \"md4\":4,\n",
    "    \"md5\":5,\n",
    "    \"md100\":100\n",
    "}\n",
    "results = {}\n",
    "best_run_id = None\n",
    "best_run_name = None\n",
    "best_f2 = 0.0\n",
    "best_md_param = None\n",
    "for run_name, md_param in experiments.items():\n",
    "    model, run_id, accuracy_score, f2_score = run_experiment(df, experiment_name, run_name, model_name, max_depth=md_param)\n",
    "    results[run_name] = {\n",
    "        'run_id': run_id,\n",
    "        'accuracy': accuracy_score,\n",
    "        'f2': f2_score\n",
    "    }\n",
    "    if best_f2 < f2_score:\n",
    "        best_f2 = f2_score\n",
    "        best_run_id = run_id\n",
    "        best_run_name = run_name\n",
    "        best_md_param = md_param\n",
    "    elif best_f2 == f2_score:\n",
    "        print(f\"Found another run with same accuracy: {f2_score:.4f}\")\n",
    "        print(f\"run {best_run_name} vs run {run_name}\")\n",
    "        if best_md_param is None or md_param < best_md_param:\n",
    "            # Update the best run if the C parameter is lower\n",
    "            best_md_param = md_param\n",
    "            best_run_id = run_id\n",
    "            best_run_name = run_name\n",
    "            print(f\"\\t Updating best run to {run_name} with max_depth={md_param} and f2_score={f2_score:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\t Keeping best run {best_run_name} with smaller max_depth to have simpler model\")\n",
    "\n",
    "print(f\"Best run: {best_run_name} id: {best_run_id} with f2_score: {best_f2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b031e",
   "metadata": {},
   "source": [
    "### Model Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c9f28",
   "metadata": {},
   "source": [
    "The best model is the one with run_id stored in `best_run_id`\n",
    "Let us save it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fa512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_register_model(run_id):\n",
    "    print(f\"Saving model with run ID: {run_id} to S3\")\n",
    "    model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "    print(f\"\\tRegistering model from URI: {model_uri}\")\n",
    "    # Register the model to the MLflow Model Registry\n",
    "    reg_model = mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=model_name\n",
    "    )\n",
    "    print(f\"\\tModel '{model_name}' registered with version: {reg_model.version}\")\n",
    "    return reg_model\n",
    "\n",
    "\n",
    "registered_model = mlflow_register_model(best_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef6b94",
   "metadata": {},
   "source": [
    "Check Model has been Registered properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09893156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "model_version = client.get_model_version(model_name, registered_model.version)\n",
    "model_artifact_s3 = model_version.source\n",
    "model_version_no = model_version.version\n",
    "model_version_name = model_version.name\n",
    "print(\"Model S3 Artifact URI:\", model_artifact_s3)\n",
    "print(\"Model Version No     :\", model_version_no)\n",
    "print(\"Model Version Name   :\", model_version_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "model_s3_uri = None\n",
    "def download_model_artifact(model_version_name,model_version_no, model_folder=\"/tmp/model\"):\n",
    "    \"\"\"\n",
    "    Download the model artifact from the MLflow Model Registry.\n",
    "    \"\"\"\n",
    "    artifact_uri=f\"models:/{model_version_name}/{model_version_no}\"\n",
    "    print(f\"Model artifact {artifact_uri}\")\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    mlflow.artifacts.download_artifacts(\n",
    "        artifact_uri=artifact_uri,\n",
    "        dst_path=model_folder\n",
    "    )\n",
    "    print(f\"Model artifact {artifact_uri} downloaded to: {model_folder}\")\n",
    "\n",
    "# Download the model artifact\n",
    "def create_model_archive(model_folder=\"/tmp/model\", model_tgz_path=\"/tmp/model.tar.gz\"):\n",
    "    \"\"\"\n",
    "    Create a tar.gz archive of the model folder.\n",
    "    \"\"\"\n",
    "    with tarfile.open(model_tgz_path, \"w:gz\") as tar:\n",
    "        tar.add(model_folder, arcname=\".\")\n",
    "    print(f\"Model archive created at: {model_tgz_path}\")\n",
    "\n",
    "def test_load_archive(model_folder=\"/tmp/model\"):\n",
    "    model=joblib.load(os.path.join(model_folder, \"model.pkl\"))\n",
    "    print(model)\n",
    "\n",
    "def upload_to_s3(local_file, model_version_name, model_version_no):\n",
    "    \"\"\"\n",
    "    Upload a local file to an S3 bucket.\n",
    "    \"\"\"\n",
    "    s3_key = f\"{base_folder}/models/{model_version_name}-v{model_version_no}/model.tar.gz\"\n",
    "    print(f\"Uploading {local_file} to s3 with key {s3_key}\")\n",
    "    model_s3_uri = None\n",
    "    try:\n",
    "        bucket = sagemaker_session.default_bucket() \n",
    "        s3_client.upload_file(local_file, bucket, s3_key)\n",
    "        model_s3_uri = f\"s3://{bucket}/{s3_key}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to S3: {e}\")\n",
    "    # minimize traceback in the output as we are not interested in the details\n",
    "    if not model_s3_uri:\n",
    "        raise Exception(\"Failed to upload model to S3.\")\n",
    "    print(f\"File {local_file} uploaded to {model_s3_uri}\")\n",
    "    return model_s3_uri\n",
    "\n",
    "# Create a compressed archive of the model folder\n",
    "model_folder=\"/tmp/model\"\n",
    "model_tgz_path=\"/tmp/model.tar.gz\"\n",
    "print(\"expect s3://iti113-team16-bucket/ai4i/mlflow/1/fc49513036cb442ea9eb764c32509bfa/artifacts/model\")\n",
    "download_model_artifact(model_version_name, model_version_no, model_folder)\n",
    "create_model_archive(model_folder, model_tgz_path)\n",
    "test_load_archive(model_folder)\n",
    "model_s3_uri = upload_to_s3(model_tgz_path, model_version_name, model_version_no)\n",
    "# Upload to S3\n",
    "print(\"✅ Compressed model uploaded to:\", model_s3_uri)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d3af4-688b-4370-8beb-500c5c9e6f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T11:52:24.629739Z",
     "iopub.status.busy": "2025-08-20T11:52:24.629444Z",
     "iopub.status.idle": "2025-08-20T11:52:24.633423Z",
     "shell.execute_reply": "2025-08-20T11:52:24.632672Z",
     "shell.execute_reply.started": "2025-08-20T11:52:24.629717Z"
    }
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4dbf91",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf84bfc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T14:58:45.117782Z",
     "iopub.status.busy": "2025-08-20T14:58:45.117032Z",
     "iopub.status.idle": "2025-08-20T14:58:45.121368Z",
     "shell.execute_reply": "2025-08-20T14:58:45.120629Z",
     "shell.execute_reply.started": "2025-08-20T14:58:45.117751Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "model_name = \"ai4i-pipeline-model\"  # e.g., 'my-model'\n",
    "model_package_group_name = \"AI4IPipelineModels\"\n",
    "pipeline_name = \"AI4IClassifierPipeline\"\n",
    "# ----------------------\n",
    "base_folder = 'ai4i'      # e.g., 'users/my-name'\n",
    "experiment_name = \"ai4i-Experiment\"  # e.g., 'my-experiment'\n",
    "model_name = \"ai4i-model\"  # e.g., 'my-model'\n",
    "tracking_server_name = \"Team16-MLFlow\"\n",
    "bucket_name=\"iti113-team16-bucket\" # s3://iti113-team16-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333828be",
   "metadata": {},
   "source": [
    "## Install dependencies and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a2b0a",
   "metadata": {},
   "source": [
    "## Session setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af232277",
   "metadata": {},
   "source": [
    "Setup sagemaker and s3 session clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f679a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T14:58:59.602483Z",
     "iopub.status.busy": "2025-08-20T14:58:59.601986Z",
     "iopub.status.idle": "2025-08-20T14:59:00.496631Z",
     "shell.execute_reply": "2025-08-20T14:59:00.496014Z",
     "shell.execute_reply.started": "2025-08-20T14:58:59.602458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet will be stored inside: s3://iti113-team16-bucket/ai4i/data/v1/data.csv\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "sagemaker_client = None\n",
    "s3_client = None\n",
    "try:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sagemaker_client = boto3.client(\"sagemaker\")\n",
    "    s3_bucket = sagemaker_session.default_bucket()\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_data_key=f\"{base_folder}/data/v1/data.csv\"\n",
    "    s3_data_path = f\"s3://{bucket_name}/{s3_data_key}\"\n",
    "    s3_data_dir_uri = f\"s3://{bucket_name}/{base_folder}/data/v1\"\n",
    "    print(f\"DataSet will be stored inside: {s3_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SageMaker session or S3 client: {e}\")\n",
    "    s3_data_path = None\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not sagemaker_client or not s3_client:\n",
    "    raise Exception(\"Failed to initialize SageMaker session or S3 client.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfd1b6",
   "metadata": {},
   "source": [
    "Setup mlflow client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43d27e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T14:59:05.362373Z",
     "iopub.status.busy": "2025-08-20T14:59:05.361492Z",
     "iopub.status.idle": "2025-08-20T14:59:07.952065Z",
     "shell.execute_reply": "2025-08-20T14:59:07.951443Z",
     "shell.execute_reply.started": "2025-08-20T14:59:05.362342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "SageMaker Role ARN: arn:aws:iam::837028399719:role/iti113-team16-sagemaker-iti113-team16-domain-iti113-team16-Role\n",
      "MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "MLflow tracking URI set successfully.\n",
      "MLflow tracking URI set to: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "MLflow experiment set to: 'ai4i-Experiment'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow_tracking_server_arn = None\n",
    "try:\n",
    "    response = sagemaker_client.describe_mlflow_tracking_server(\n",
    "        TrackingServerName=tracking_server_name\n",
    "    )\n",
    "    # ARN of MLflow Tracking Server\n",
    "    mlflow_tracking_server_arn = response['TrackingServerArn']\n",
    "    print(f\"Found MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find tracking server: {e}\")\n",
    "    mlflow_tracking_server_arn = None\n",
    "\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not mlflow_tracking_server_arn:\n",
    "    raise Exception(\"Failed to find MLflow Tracking Server.\")\n",
    "\n",
    "# IAM role for SageMaker execution\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "\n",
    "# Connect to the MLflow Tracking Server\n",
    "# Set the MLflow tracking URI to managed server\n",
    "if mlflow_tracking_server_arn:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "    print(\"MLflow tracking URI set successfully.\")\n",
    "\n",
    "# Define an experiment name. If it doesn't exist, MLflow creates it.\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow experiment set to: '{experiment_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e6dda-51ff-4029-bca6-4ead406782fe",
   "metadata": {},
   "source": [
    "## Upload DataSet To S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b96aa4c-acb2-4ce4-b775-4fcada322812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:06.093907Z",
     "iopub.status.busy": "2025-08-20T15:00:06.093532Z",
     "iopub.status.idle": "2025-08-20T15:00:06.951420Z",
     "shell.execute_reply": "2025-08-20T15:00:06.950422Z",
     "shell.execute_reply.started": "2025-08-20T15:00:06.093875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset v1.0 created and uploaded to: s3://iti113-team16-bucket/ai4i/data/v1/data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "if s3_data_path is None:\n",
    "    raise Exception(\"S3 data path is not set. Cannot proceed with dataset creation.\")\n",
    "df = pd.read_csv(\"ai4i2020.csv\")\n",
    "df.to_csv(s3_data_path, index=False)\n",
    "print(f\"Dataset v1.0 created and uploaded to: {s3_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699e1a3-1023-429c-8717-5679d80be9f5",
   "metadata": {},
   "source": [
    "Let us test whether we can load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99a39b1-031a-416b-98b1-13c64f30aadb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:10.506207Z",
     "iopub.status.busy": "2025-08-20T15:00:10.505626Z",
     "iopub.status.idle": "2025-08-20T15:00:10.584470Z",
     "shell.execute_reply": "2025-08-20T15:00:10.575160Z",
     "shell.execute_reply.started": "2025-08-20T15:00:10.506178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded dataset v1.0:\n",
      "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
      "0    1     M14860    M                298.1                    308.6   \n",
      "\n",
      "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
      "0                    1551         42.8                0                0    0   \n",
      "\n",
      "   HDF  PWF  OSF  RNF  \n",
      "0    0    0    0    0  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_loaded = pd.read_csv(s3_data_path)\n",
    "    print(\"Successfully loaded dataset v1.0:\")\n",
    "    print(df_loaded.head(1))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"\\nPlease double-check that your bucket and folder names are correct in Step 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b61f3c",
   "metadata": {},
   "source": [
    "## Create the SageMaker Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546bdfb",
   "metadata": {},
   "source": [
    "### Requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b00e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:17.586961Z",
     "iopub.status.busy": "2025-08-20T15:00:17.586674Z",
     "iopub.status.idle": "2025-08-20T15:00:17.596709Z",
     "shell.execute_reply": "2025-08-20T15:00:17.593087Z",
     "shell.execute_reply.started": "2025-08-20T15:00:17.586940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3==1.28.57\n",
    "botocore==1.31.85\n",
    "pandas==1.5.3\n",
    "numpy==1.24.3\n",
    "mlflow\n",
    "sagemaker-mlflow\n",
    "scikit-learn==1.2.2\n",
    "joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75c4ee",
   "metadata": {},
   "source": [
    "### Preprocessing script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd761d8",
   "metadata": {},
   "source": [
    "We already create our preprocessing script during manual setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfc8b3",
   "metadata": {},
   "source": [
    "### Training script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55002c5-4dd9-491a-8368-407781c15c94",
   "metadata": {},
   "source": [
    "We already create our preprocessing script during manual setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ac900",
   "metadata": {},
   "source": [
    "### Evaluation script\n",
    "\n",
    "Here we create evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ebdd63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:31.256138Z",
     "iopub.status.busy": "2025-08-20T15:00:31.255542Z",
     "iopub.status.idle": "2025-08-20T15:00:31.262500Z",
     "shell.execute_reply": "2025-08-20T15:00:31.261575Z",
     "shell.execute_reply.started": "2025-08-20T15:00:31.256114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluate.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import tarfile\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Parse Arguments ---\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-path\", type=str, required=True, help=\"Path to the directory containing the model.tar.gz file.\")\n",
    "    parser.add_argument(\"--test-path\", type=str, required=True, help=\"Path to the directory containing test.csv.\")\n",
    "    parser.add_argument(\"--output-path\", type=str, required=True, help=\"Path to save the evaluation.json report.\")\n",
    "    parser.add_argument(\"--model-package-group-name\", type=str, required=True, help=\"Name of the SageMaker Model Package Group.\")\n",
    "    parser.add_argument(\"--region\", type=str, required=True, help=\"The AWS region for creating the boto3 client.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # --- Extract and Load Model ---\n",
    "    # SageMaker packages models in a .tar.gz file. We need to extract it first.\n",
    "    model_archive_path = os.path.join(args.model_path, 'model.tar.gz')\n",
    "    print(f\"Extracting model from archive: {model_archive_path}\")\n",
    "    with tarfile.open(model_archive_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=args.model_path)\n",
    "\n",
    "    # Load the model using joblib\n",
    "    model_file_path = os.path.join(args.model_path, \"model.joblib\")\n",
    "    if not os.path.exists(model_file_path):\n",
    "        raise FileNotFoundError(f\"Model file 'model.joblib' not found after extraction in: {args.model_path}\")\n",
    "    \n",
    "    print(f\"Loading model from: {model_file_path}\")\n",
    "    model = joblib.load(model_file_path)\n",
    "\n",
    "    # --- Prepare Data and Evaluate ---\n",
    "    test_file_path = os.path.join(args.test_path, \"test.csv\")\n",
    "    if not os.path.exists(test_file_path):\n",
    "        raise FileNotFoundError(f\"Test data not found: {test_file_path}\")\n",
    "    \n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "    labels = ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "    X_test = test_df.drop(columns=labels)\n",
    "    y_test= test_df[labels]\n",
    "    \n",
    "    print(\"Running predictions on the test dataset.\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = pd.DataFrame(y_pred, columns=y_test.columns)\n",
    "    y_pred_omf = y_pred[\"Machine failure\"]\n",
    "    y_test_omf = y_test[\"Machine failure\"]\n",
    "    f2_score = fbeta_score(y_test_omf, y_pred_omf, beta=2)\n",
    "    report = {\"f2\": f2_score}\n",
    "    print(f\"Calculated f2: {f2_score:.4f}\")\n",
    "\n",
    "    # --- Check for Existing Baseline Model in SageMaker Model Registry ---\n",
    "    print(f\"Checking for baseline model in region: {args.region}\")\n",
    "    sagemaker_client = boto3.client(\"sagemaker\", region_name=args.region)\n",
    "    try:\n",
    "        response = sagemaker_client.list_model_packages(\n",
    "            ModelPackageGroupName=args.model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            SortOrder=\"Descending\",\n",
    "            MaxResults=1,\n",
    "        )\n",
    "        # If the list is not empty, an approved model already exists\n",
    "        report[\"baseline_exists\"] = len(response[\"ModelPackageSummaryList\"]) > 0\n",
    "        if report[\"baseline_exists\"]:\n",
    "            print(f\"An approved baseline model was found in '{args.model_package_group_name}'.\")\n",
    "        else:\n",
    "             print(f\"No approved baseline model was found in '{args.model_package_group_name}'.\")\n",
    "\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        # If the ModelPackageGroup doesn't exist, there is no baseline\n",
    "        if \"ResourceNotFound\" in str(e):\n",
    "            report[\"baseline_exists\"] = False\n",
    "            print(f\"Model Package Group '{args.model_package_group_name}' not found. Assuming no baseline exists.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # --- Write Final Report ---\n",
    "    os.makedirs(args.output_path, exist_ok=True)\n",
    "    report_path = os.path.join(args.output_path, \"evaluation.json\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "        \n",
    "    print(f\"✅ Evaluation complete. Report written to: {report_path}\")\n",
    "    print(\"Evaluation Report:\")\n",
    "    print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e4d1a",
   "metadata": {},
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a4b4939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:36.254012Z",
     "iopub.status.busy": "2025-08-20T15:00:36.253651Z",
     "iopub.status.idle": "2025-08-20T15:00:36.348539Z",
     "shell.execute_reply": "2025-08-20T15:00:36.347851Z",
     "shell.execute_reply.started": "2025-08-20T15:00:36.253988Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, TrainingInput\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.conditions import ConditionNot\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionEquals\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.parameters import ParameterFloat, ParameterString\n",
    "from sagemaker.model_metrics import ModelMetrics, FileSource\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02679f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:40.029963Z",
     "iopub.status.busy": "2025-08-20T15:00:40.029616Z",
     "iopub.status.idle": "2025-08-20T15:00:40.033897Z",
     "shell.execute_reply": "2025-08-20T15:00:40.033121Z",
     "shell.execute_reply.started": "2025-08-20T15:00:40.029939Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name_param = ParameterString(name=\"ExperimentName\", default_value=experiment_name)\n",
    "metric_threshold_param = ParameterFloat(name=\"F2Threshold\", default_value=0.70)\n",
    "pipeline_parameters = [experiment_name_param, metric_threshold_param]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0751ec",
   "metadata": {},
   "source": [
    "### Processing Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "716b50f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:43.568434Z",
     "iopub.status.busy": "2025-08-20T15:00:43.568089Z",
     "iopub.status.idle": "2025-08-20T15:00:43.925165Z",
     "shell.execute_reply": "2025-08-20T15:00:43.924505Z",
     "shell.execute_reply.started": "2025-08-20T15:00:43.568411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "processing_instance_type = \"ml.t3.medium\" # cheapest $0.063/hour\n",
    "preprocessor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, \"1.2-1\"),\n",
    "    command=[\n",
    "        \"python3\",\n",
    "    ],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"preprocess-data\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_preprocess = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=preprocessor,\n",
    "    inputs=[ProcessingInput(source=s3_data_dir_uri, destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"preprocess.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8554ae",
   "metadata": {},
   "source": [
    "### Training Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ade9c770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:55.342565Z",
     "iopub.status.busy": "2025-08-20T15:00:55.341775Z",
     "iopub.status.idle": "2025-08-20T15:00:55.401122Z",
     "shell.execute_reply": "2025-08-20T15:00:55.400289Z",
     "shell.execute_reply.started": "2025-08-20T15:00:55.342534Z"
    }
   },
   "outputs": [],
   "source": [
    "training_instance_type = \"ml.t3.large\" # second cheapest $0.127/hour\n",
    "\n",
    "# Training Step\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"train.py\", \n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=training_instance_type,\n",
    "    role=role,\n",
    "    hyperparameters={\n",
    "        \"tracking_server_arn\": mlflow_tracking_server_arn,\n",
    "        \"experiment_name\": experiment_name_param,\n",
    "        \"model_output_path\": \"/opt/ml/model\",\n",
    "    },\n",
    "    py_version=\"py3\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    depends_on=[step_preprocess]  # Explicitly depends on the preprocess\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004d9f7",
   "metadata": {},
   "source": [
    "### Evaluation Step Defintion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e8b2f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:00:59.778927Z",
     "iopub.status.busy": "2025-08-20T15:00:59.778558Z",
     "iopub.status.idle": "2025-08-20T15:00:59.828747Z",
     "shell.execute_reply": "2025-08-20T15:00:59.828081Z",
     "shell.execute_reply.started": "2025-08-20T15:00:59.778897Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "evaluation_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, \"1.2-1\"),\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"evaluate-model\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")],\n",
    "    code=\"evaluate.py\",  # SageMaker will handle uploading and running this script\n",
    "    job_arguments=[  # Pass arguments here instead of in command\n",
    "        \"--model-path\", \"/opt/ml/processing/model\",\n",
    "        \"--test-path\", \"/opt/ml/processing/test\",\n",
    "        \"--output-path\", \"/opt/ml/processing/evaluation\",\n",
    "        \"--model-package-group-name\", model_package_group_name,\n",
    "        \"--region\", \"ap-southeast-1\",\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    "    depends_on=[step_train]  # Explicitly depends on the train process\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4994b",
   "metadata": {},
   "source": [
    "### Model Registration Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403732f",
   "metadata": {},
   "source": [
    "The model registration follows the following logic \n",
    "```bash\n",
    "if cond_no_registered \n",
    "   step_register_new\n",
    "else if cond_metric \n",
    "   step_register_better_model\n",
    "end if\n",
    "```\n",
    "where :\n",
    "- cond_no_registered check whether existing baseline model exist\n",
    "- cond_metric check whether new model has higher value of metric (F2) than existing baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb8dc392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:01:04.072842Z",
     "iopub.status.busy": "2025-08-20T15:01:04.072216Z",
     "iopub.status.idle": "2025-08-20T15:01:04.082891Z",
     "shell.execute_reply": "2025-08-20T15:01:04.081724Z",
     "shell.execute_reply.started": "2025-08-20T15:01:04.072809Z"
    }
   },
   "outputs": [],
   "source": [
    "# RegisterModel step (always defined, but executed conditionally)\n",
    "model_metrics_report = ModelMetrics(\n",
    "    model_statistics=FileSource(\n",
    "        s3_uri=step_eval.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "step_register_new = RegisterModel(\n",
    "    name=\"RegisterNewModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "step_register_better_model = RegisterModel(\n",
    "    name=\"RegisterBetterModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "\n",
    "# Conditions: check accuracy > threshold OR no model exists\n",
    "cond_metric = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"f2\"\n",
    "    ),\n",
    "    right=metric_threshold_param\n",
    ")\n",
    "\n",
    "cond_no_registered = ConditionEquals(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"baseline_exists\" # Check the key added to the report\n",
    "    ),\n",
    "    right=False # Condition is TRUE if baseline_exists is False\n",
    ")\n",
    "\n",
    "# Outer step: Checks for existence of registered model first\n",
    "step_cond_metric = ConditionStep(\n",
    "    name=\"CheckAccuracy\",\n",
    "    conditions=[cond_metric],\n",
    "    if_steps=[step_register_better_model], # Register model if accuracy is high\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "step_cond_no_registered = ConditionStep(\n",
    "    name=\"CheckIfModelExists\",\n",
    "    conditions=[cond_no_registered],\n",
    "    if_steps=[step_register_new], # Register model if no baseline exists\n",
    "    else_steps=[step_cond_metric], # Do nothing if a model exists and accuracy was low\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d286d5",
   "metadata": {},
   "source": [
    "### Pipeline Definition And Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd971683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:01:07.786255Z",
     "iopub.status.busy": "2025-08-20T15:01:07.785498Z",
     "iopub.status.idle": "2025-08-20T15:01:09.708284Z",
     "shell.execute_reply": "2025-08-20T15:01:09.707505Z",
     "shell.execute_reply.started": "2025-08-20T15:01:07.786223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "# Define steps in the pipeline\n",
    "pipeline_steps = []\n",
    "pipeline_steps.append(step_preprocess)\n",
    "pipeline_steps.append(step_train)\n",
    "pipeline_steps.append(step_eval)\n",
    "pipeline_steps.append(step_cond_no_registered) \n",
    "# Define Pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=pipeline_parameters,\n",
    "    steps=pipeline_steps\n",
    ")\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b36b9",
   "metadata": {},
   "source": [
    "### Pipeline Status or  Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f10d7e-e90f-4e35-88ea-5d2426b9afd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:01:21.383992Z",
     "iopub.status.busy": "2025-08-20T15:01:21.383335Z",
     "iopub.status.idle": "2025-08-20T15:01:21.520997Z",
     "shell.execute_reply": "2025-08-20T15:01:21.520286Z",
     "shell.execute_reply.started": "2025-08-20T15:01:21.383965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active\n"
     ]
    }
   ],
   "source": [
    "def get_pipeline_status()->str:\n",
    "    try:\n",
    "        response = sagemaker_client.describe_pipeline(\n",
    "            PipelineName=pipeline_name\n",
    "        )\n",
    "        result= response[\"PipelineStatus\"]\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'ResourceNotFound':\n",
    "            result= (f\"Pipeline {pipeline_name} not found {e}\")\n",
    "        else:\n",
    "            result= (f\"Unknown error {e.response} {type(e)}\")\n",
    "    return result\n",
    "\n",
    "print(get_pipeline_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "543a46ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T15:05:03.530440Z",
     "iopub.status.busy": "2025-08-20T15:05:03.529490Z",
     "iopub.status.idle": "2025-08-20T15:05:03.682871Z",
     "shell.execute_reply": "2025-08-20T15:05:03.682007Z",
     "shell.execute_reply.started": "2025-08-20T15:05:03.530406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active\n"
     ]
    }
   ],
   "source": [
    "# uncomment this to remove pipeline\n",
    "#pipeline.delete()\n",
    "print(get_pipeline_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040aba62-46ce-422f-9842-8ff4fa3796c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
