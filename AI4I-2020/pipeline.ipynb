{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154eb31d",
   "metadata": {},
   "source": [
    "# AI4I MLOps for Predictive Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b3cff",
   "metadata": {},
   "source": [
    "##  Issues with Jupyter Notebook Space vs Sagemaker container\n",
    "sagemaker-scikit-learn-container requirements are defined in https://github.com/aws/sagemaker-scikit-learn-container/blob/master/requirements.txt\n",
    "\n",
    "we are interested in the following from the requirements:\n",
    "```python\n",
    "pandas==1.1.3\n",
    "scikit-learn==1.2.1\n",
    "```\n",
    "One of the challenges we encountered is that our sagemaker jupyter notebook is running scikit-learn 1.6.1 as we used the default space\n",
    "https://github.com/aws/sagemaker-distribution/blob/main/build_artifacts/v3/v3.3/v3.3.2/RELEASE.md\n",
    "with scikit-learn == 1.6.1 \n",
    "\n",
    "This cause our manually serialized model failed to be loaded by sagemaker due to the changes between scikit-learn==1.6.1 (model) and scikit-learn==1.2.1 (sagemaker endpoint container)\n",
    "\n",
    "We were unable to solve this and failed to create endpoint manually\n",
    "\n",
    "We then try to create new space to run our jupyter notebook using much older sagemaker distribution\n",
    "\n",
    "The only one that should work is \n",
    "https://github.com/aws/sagemaker-distribution/blob/main/build_artifacts/v0/v0.1/v0.1.2/RELEASE.md\n",
    "with scikit-learn == 1.2.2 \n",
    "\n",
    "However, AWS no longer provide Space with this image.\n",
    "\n",
    "Hence we are not able to manually setup sagemaker endpoint unless we can train using sagemaker pipeline instead of our jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ebe6b",
   "metadata": {},
   "source": [
    "## Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2faab0f",
   "metadata": {},
   "source": [
    "Here we write our scripts into files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64701b57",
   "metadata": {},
   "source": [
    "### Requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d33a79d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:49:56.730021Z",
     "iopub.status.busy": "2025-08-22T08:49:56.729400Z",
     "iopub.status.idle": "2025-08-22T08:49:56.734679Z",
     "shell.execute_reply": "2025-08-22T08:49:56.733937Z",
     "shell.execute_reply.started": "2025-08-22T08:49:56.729994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3\n",
    "botocore\n",
    "pandas\n",
    "numpy\n",
    "mlflow\n",
    "sagemaker-mlflow\n",
    "scikit-learn==1.2.2\n",
    "joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82560c4c",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640caf03",
   "metadata": {},
   "source": [
    "We write our preprocessing step as a separate script file.\n",
    "\n",
    "We then import the preprocessing function to our notebook.\n",
    "\n",
    "This allows us to re-use it in our pipeline definition later.\n",
    "\n",
    "One drawback is that we need to restart our kernel whenever we update this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05b437aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:05.141196Z",
     "iopub.status.busy": "2025-08-22T08:50:05.140908Z",
     "iopub.status.idle": "2025-08-22T08:50:05.149657Z",
     "shell.execute_reply": "2025-08-22T08:50:05.148487Z",
     "shell.execute_reply.started": "2025-08-22T08:50:05.141174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "## This file is created once during manual setup \n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "def unknown_fail_check(row): return ((row['Machine failure'] == 1)\n",
    "                                     & (row['RNF'] == 0)\n",
    "                                     & (row['HDF'] == 0)\n",
    "                                     & (row['TWF'] == 0)\n",
    "                                     & (row['PWF'] == 0)\n",
    "                                     & (row['OSF'] == 0))\n",
    "\n",
    "def pass_yet_fail_check(row): return (row['Machine failure'] == 0) & ((row['RNF'] == 1)\n",
    "                                                                     | (row['HDF'] == 1)\n",
    "                                                                     | (row['TWF'] == 1)\n",
    "                                                                     | (row['PWF'] == 1)\n",
    "                                                                     | (row['OSF'] == 1))\n",
    "def preprocessing(df):\n",
    "    print(\"# Preprocessing\")\n",
    "    df['Type'] = df['Type'].astype('category')\n",
    "    type_mapping = {'L': 0, 'M': 1, 'H': 2}\n",
    "    df['Type'] = df['Type'].map(type_mapping).astype('int')\n",
    "    print(\" Type  Unique Values after encoding: \", df['Type'].unique())\n",
    "    df.drop(columns=['UDI', 'Product ID'], inplace=True)\n",
    "    print(f\"shape of data after dropping columns {df.shape}\")\n",
    "    df.columns = [col.replace(\"[\",\"(\").replace(\"]\",\")\") for col in df.columns.values]\n",
    "    print(\"DF columns after clean up\", df.columns)\n",
    "    print(\"## Handle Duplicates\") \n",
    "    # our original dataset does not have duplicates\n",
    "    # However, there is no guarantee that production/new data is free of duplicates\n",
    "    duplicated_row_count = df.duplicated().sum()\n",
    "    total_row_count = df.shape[0]\n",
    "    duplicated_row_percentage = (duplicated_row_count/total_row_count*100)\n",
    "    print(f\"Total rows count: {total_row_count}\")\n",
    "    print(f\"Duplicated rows count: {duplicated_row_count}\")\n",
    "    print(f\"Duplicated rows percentage: {duplicated_row_percentage}\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"After removing duplicates rows count:\", df.shape[0])\n",
    "    print(\"## Handle NULL\") \n",
    "    print(\"number of null values : \", df.isnull().sum().sum())\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"After removing null rows count:\", df.shape[0])\n",
    "    # declare our target labels columns\n",
    "    labels = ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "    passed_although_failed = df[pass_yet_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of samples that passed although failed: {len(passed_although_failed)}\")\n",
    "    passed_although_failed.loc[:, labels].head(10)\n",
    "    df['Machine failure'] = np.where(\n",
    "        pass_yet_fail_check(df), 1, df['Machine failure'])\n",
    "    passed_although_failed = df[pass_yet_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of samples that passed although failed after fix: {len(passed_although_failed)}\")\n",
    "\n",
    "    print(f\"Number of machine failures: {df['Machine failure'].sum()}\")\n",
    "    unknown_failures = df[unknown_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of failures due to unknown reasons: {len(unknown_failures)}\")\n",
    "    unknown_failures.loc[:, labels].head(10)\n",
    "    df['Machine failure'] = np.where(\n",
    "        unknown_fail_check(df), 0, df['Machine failure'])\n",
    "    unknown_failures = df[unknown_fail_check(df)]\n",
    "    print(\n",
    "        f\"Number of failures due to unknown reasons after fix: {len(unknown_failures)}\")\n",
    "    print(\"## Add Features\") \n",
    "    df['Strain (minNm)'] = df['Tool wear (min)'] * df['Torque (Nm)'] \n",
    "    df['Power (W)'] = df['Rotational speed (rpm)'] * df['Torque (Nm)'] * 2 * np.pi / 60\n",
    "    df['Temperature Difference (K)'] = df['Process temperature (K)'] - df['Air temperature (K)']\n",
    "    print(\"columns after new feature : \",df.columns)\n",
    "    print(\"## Drop Redudant Features\")\n",
    "    df.drop(columns=['Torque (Nm)', 'Process temperature (K)', 'Air temperature (K)'], inplace=True)\n",
    "    print(\"columns after drop :\",df.columns)\n",
    "    print(\"## Convert Int to Float for MLFlow\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.int64 or df[col].dtype == np.int32: # Check for common integer types\n",
    "            df[col] = df[col].astype(np.float64)\n",
    "    print(\"# Splitting into train/test...\")\n",
    "    X = df.drop(columns=labels)\n",
    "    y = df[labels]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42,  stratify=y['Machine failure']) \n",
    "    train=pd.concat([X_train, y_train], axis=1)\n",
    "    test=pd.concat([X_test, y_test], axis=1)\n",
    "    print(\"# Processing Done\")\n",
    "    return train, test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # The pipeline will pass arguments to this script.\n",
    "    # The argument will be used to pass the S3 path of our data.\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-path\", type=str, help=\"path containing data.csv\")\n",
    "    parser.add_argument(\"--output-train-path\", type=str, help=\"Output directory for train.csv\")\n",
    "    parser.add_argument(\"--output-test-path\", type=str, help=\"Output directory for test.csv\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    input_path = args.input_path or \"/opt/ml/processing/input\"\n",
    "    output_train_path = args.output_train_path or \"/opt/ml/processing/train\"\n",
    "    output_test_path = args.output_test_path or \"/opt/ml/processing/test\"\n",
    "    print(f\"--- Starting Processing Job ---\")\n",
    "    print(f\"Input path: {input_path}\")\n",
    "    print(f\"Output train path: {output_train_path}\")\n",
    "    print(f\"Output test path: {output_test_path}\")\n",
    "    # Load the dataset\n",
    "    print(f\"Loading data from {input_path}/data.csv\")\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"Input path {input_path} does not exist.\")\n",
    "    if not os.path.exists(os.path.join(input_path, \"data.csv\")):\n",
    "        raise FileNotFoundError(f\"Data file not found in {input_path}. Please check the path.\")\n",
    "    # Read the CSV file \n",
    "    data_path = os.path.join(input_path, \"data.csv\")\n",
    "    df = pd.read_csv(data_path) \n",
    "    # Preprocess\n",
    "    train, test = preprocessing(df)\n",
    "    os.makedirs(output_train_path, exist_ok=True)\n",
    "    os.makedirs(output_test_path, exist_ok=True)\n",
    "    print(f\"Saving train data to {output_train_path}/train.csv\")\n",
    "    train.to_csv(os.path.join(output_train_path, \"train.csv\"), index=False)\n",
    "    print(f\"Saving test data to {output_test_path}/test.csv\")\n",
    "    test.to_csv(os.path.join(output_test_path, \"test.csv\"), index=False)\n",
    "    print(\"--- Processing Job Completed ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da2e297",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dcb2a82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:08.353649Z",
     "iopub.status.busy": "2025-08-22T08:50:08.352864Z",
     "iopub.status.idle": "2025-08-22T08:50:08.361086Z",
     "shell.execute_reply": "2025-08-22T08:50:08.360160Z",
     "shell.execute_reply.started": "2025-08-22T08:50:08.353618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "# # Ensure MLflow is installed\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "try:\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow\n",
    "except ImportError:\n",
    "    print(\"Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
    "                            \"boto3==1.37.1\", \"botocore==1.37.1\", \"s3transfer\",\n",
    "                            \"mlflow==2.22.0\", \"sagemaker-mlflow==0.1.0\"])\n",
    "import mlflow\n",
    "import sagemaker_mlflow\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train(df, max_depth=10):\n",
    "    # declare our target labels columns\n",
    "    labels = ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "    X = df.drop(columns=labels)\n",
    "    y = df[labels]\n",
    "    model = RandomForestClassifier(random_state=42, max_depth=max_depth)\n",
    "    model = MultiOutputClassifier(model)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = pd.DataFrame(y_pred, columns=y.columns)\n",
    "    y_pred_omf = y_pred[\"Machine failure\"]\n",
    "    y_omf = y[\"Machine failure\"]\n",
    "    f2 = fbeta_score(y_omf, y_pred_omf, beta=2)\n",
    "    recall = recall_score(y_omf, y_pred_omf)\n",
    "    precision = precision_score(y_omf, y_pred_omf, zero_division=0)\n",
    "    accuracy = accuracy_score(y_omf, y_pred_omf)\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"f2\": f2,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"input_example\": X.head(5)\n",
    "    }\n",
    "\n",
    "\n",
    "def run_experiment(df, experiment_name, run_name=None, model_name=\"model\",\n",
    "                   max_depth=10):\n",
    "    print(\"Starting experiment \", experiment_name, \" with run name \", run_name)\n",
    "    run_id = None\n",
    "    # Start an MLflow run\n",
    "    # Use the experiment name and run name to organize runs\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"\\tMLflow Run ID : {run_id}\")\n",
    "        print(f\"\\tRunning experiment: {experiment_name}, Run Name: {run_name}\")\n",
    "        # Train the model\n",
    "        # Provide the first 5 rows of the training data as an example\n",
    "        result = train(df, max_depth=max_depth)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_metric(\"f2\", result[\"f2\"])\n",
    "        mlflow.log_metric(\"accuracy\", result[\"accuracy\"])\n",
    "        mlflow.log_metric(\"recall\", result[\"recall\"])\n",
    "        mlflow.log_metric(\"precision\", result[\"precision\"])\n",
    "        model = result[\"model\"]\n",
    "        # Train the model\n",
    "        # Provide the first 5 rows of the training data as an example\n",
    "        input_example = result[\"input_example\"]\n",
    "        # Get the run ID for later use\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model, artifact_path=model_name, input_example=input_example)\n",
    "        print(\"\\tFinished: experiment \", experiment_name,\n",
    "              \" with run name \", run_name)\n",
    "    return model, run_id, result[\"accuracy\"], result[\"f2\"]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # import mlflow\n",
    "    # import sagemaker_mlflow\n",
    "    import mlflow.sklearn\n",
    "    import os\n",
    "    import argparse\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    import glob\n",
    "    import shutil\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--tracking_server_arn\", type=str, required=True)\n",
    "    parser.add_argument(\"--experiment_name\", type=str, default=\"Default\")\n",
    "    parser.add_argument('--model_output_path', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=5)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Load training data\n",
    "    train_path = glob.glob(\"/opt/ml/input/data/train/*.csv\")[0]\n",
    "    df = pd.read_csv(train_path)\n",
    "    # Set up MLflow\n",
    "    mlflow.set_tracking_uri(args.tracking_server_arn)\n",
    "    the_model, run_id, accuracy_score, f2_score = run_experiment(df=df,\n",
    "                                                             experiment_name=args.experiment_name,\n",
    "                                                             run_name=\"run_name\",\n",
    "                                                             model_name=\"model\",\n",
    "                                                             max_depth=args.max_depth\n",
    "                                                             )\n",
    "    output_path=args.model_output_path\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    joblib.dump(the_model, os.path.join(output_path, \"model.joblib\"))\n",
    "    ###\n",
    "    #with open(os.path.join(args.model_output_path, \"run_id.txt\"), \"w\") as f:\n",
    "    #    f.write(run_id)\n",
    "    #shutil.copy(\"requirements.txt\", os.path.join(output_path, \"requirements.txt\"))\n",
    "    #shutil.copy(\"inference.py\", os.path.join(output_path, \"inference.py\"))\n",
    "    print(\n",
    "        f\"Training complete. F2:{f2_score:.4f} Accuracy: {accuracy_score:.4f}\")\n",
    "    print(f\"MLflow Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc308a2e",
   "metadata": {},
   "source": [
    "### Evaluation script\n",
    "\n",
    "Here we create evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad298a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:11.155683Z",
     "iopub.status.busy": "2025-08-22T08:50:11.155393Z",
     "iopub.status.idle": "2025-08-22T08:50:11.162014Z",
     "shell.execute_reply": "2025-08-22T08:50:11.161326Z",
     "shell.execute_reply.started": "2025-08-22T08:50:11.155662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluate.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import tarfile\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Parse Arguments ---\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-path\", type=str, required=True, help=\"Path to the directory containing the model.tar.gz file.\")\n",
    "    parser.add_argument(\"--test-path\", type=str, required=True, help=\"Path to the directory containing test.csv.\")\n",
    "    parser.add_argument(\"--output-path\", type=str, required=True, help=\"Path to save the evaluation.json report.\")\n",
    "    parser.add_argument(\"--model-package-group-name\", type=str, required=True, help=\"Name of the SageMaker Model Package Group.\")\n",
    "    parser.add_argument(\"--region\", type=str, required=True, help=\"The AWS region for creating the boto3 client.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # --- Extract and Load Model ---\n",
    "    # SageMaker packages models in a .tar.gz file. We need to extract it first.\n",
    "    model_archive_path = os.path.join(args.model_path, 'model.tar.gz')\n",
    "    print(f\"Extracting model from archive: {model_archive_path}\")\n",
    "    with tarfile.open(model_archive_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=args.model_path)\n",
    "\n",
    "    # Load the model using joblib\n",
    "    model_file_path = os.path.join(args.model_path, \"model.joblib\")\n",
    "    if not os.path.exists(model_file_path):\n",
    "        raise FileNotFoundError(f\"Model file 'model.joblib' not found after extraction in: {args.model_path}\")\n",
    "    \n",
    "    print(f\"Loading model from: {model_file_path}\")\n",
    "    model = joblib.load(model_file_path)\n",
    "\n",
    "    # --- Prepare Data and Evaluate ---\n",
    "    test_file_path = os.path.join(args.test_path, \"test.csv\")\n",
    "    if not os.path.exists(test_file_path):\n",
    "        raise FileNotFoundError(f\"Test data not found: {test_file_path}\")\n",
    "    \n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "    labels = ['Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "    X_test = test_df.drop(columns=labels)\n",
    "    y_test= test_df[labels]\n",
    "    \n",
    "    print(\"Running predictions on the test dataset.\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = pd.DataFrame(y_pred, columns=y_test.columns)\n",
    "    y_pred_omf = y_pred[\"Machine failure\"]\n",
    "    y_test_omf = y_test[\"Machine failure\"]\n",
    "    f2_score = fbeta_score(y_test_omf, y_pred_omf, beta=2)\n",
    "    report = {\"f2\": f2_score}\n",
    "    print(f\"Calculated f2: {f2_score:.4f}\")\n",
    "\n",
    "    # --- Check for Existing Baseline Model in SageMaker Model Registry ---\n",
    "    print(f\"Checking for baseline model in region: {args.region}\")\n",
    "    sagemaker_client = boto3.client(\"sagemaker\", region_name=args.region)\n",
    "    try:\n",
    "        response = sagemaker_client.list_model_packages(\n",
    "            ModelPackageGroupName=args.model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            SortOrder=\"Descending\",\n",
    "            MaxResults=1,\n",
    "        )\n",
    "        # If the list is not empty, an approved model already exists\n",
    "        report[\"baseline_exists\"] = len(response[\"ModelPackageSummaryList\"]) > 0\n",
    "        if report[\"baseline_exists\"]:\n",
    "            print(f\"An approved baseline model was found in '{args.model_package_group_name}'.\")\n",
    "        else:\n",
    "             print(f\"No approved baseline model was found in '{args.model_package_group_name}'.\")\n",
    "\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        # If the ModelPackageGroup doesn't exist, there is no baseline\n",
    "        if \"ResourceNotFound\" in str(e):\n",
    "            report[\"baseline_exists\"] = False\n",
    "            print(f\"Model Package Group '{args.model_package_group_name}' not found. Assuming no baseline exists.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # --- Write Final Report ---\n",
    "    os.makedirs(args.output_path, exist_ok=True)\n",
    "    report_path = os.path.join(args.output_path, \"evaluation.json\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "        \n",
    "    print(f\"‚úÖ Evaluation complete. Report written to: {report_path}\")\n",
    "    print(\"Evaluation Report:\")\n",
    "    print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b8757b-3e31-442f-892c-0a86c4c50452",
   "metadata": {},
   "source": [
    "### Deployment Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc674828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:17.488325Z",
     "iopub.status.busy": "2025-08-22T08:50:17.487612Z",
     "iopub.status.idle": "2025-08-22T08:50:17.493209Z",
     "shell.execute_reply": "2025-08-22T08:50:17.492475Z",
     "shell.execute_reply.started": "2025-08-22T08:50:17.488171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy.py\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# --- Install required packages ---\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"boto3==1.28.57\", \"botocore==1.31.57\", \"numpy==1.24.1\", \"sagemaker\" ])\n",
    "\n",
    "# Ensure sagemaker SDK is installed before importing\n",
    "try:\n",
    "    import sagemaker\n",
    "except ImportError:\n",
    "    print(\"sagemaker SDK not found. Installing now...\")\n",
    "    install(\"sagemaker\")\n",
    "    import sagemaker\n",
    "\n",
    "import argparse\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.model import ModelPackage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Accept the registered model's ARN instead of the S3 data path\n",
    "    parser.add_argument(\"--model-package-arn\", type=str, required=True)\n",
    "    parser.add_argument(\"--role\", type=str, required=True)\n",
    "    parser.add_argument(\"--endpoint-name\", type=str, required=True)\n",
    "    parser.add_argument(\"--region\", type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    boto_session = boto3.Session(region_name=args.region)\n",
    "    sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "    # Create a SageMaker Model object directly from the Model Package ARN\n",
    "    model = ModelPackage(\n",
    "        model_package_arn=args.model_package_arn,\n",
    "        role=args.role,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "\n",
    "    # Deploy the model to an endpoint\n",
    "    print(f\"Deploying registered model from ARN to endpoint: {args.endpoint_name}\")\n",
    "    model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.t2.medium\", # lowest cost availa\n",
    "        endpoint_name=args.endpoint_name,\n",
    "        # Update endpoint if it already exists\n",
    "        update_endpoint=True\n",
    "    )\n",
    "    print(\"Deployment complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec334ad1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Manual Run\n",
    "\n",
    "We perform manual run to validate our cloud infrastructure and scripts\n",
    "before we create our pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b36ef8",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0878c8-ade9-4273-8a26-ade72b2d570a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:18.009976Z",
     "iopub.status.busy": "2025-08-22T08:12:18.009443Z",
     "iopub.status.idle": "2025-08-22T08:12:20.319243Z",
     "shell.execute_reply": "2025-08-22T08:12:20.318479Z",
     "shell.execute_reply.started": "2025-08-22T08:12:18.009944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "2.245.0\n",
      "1.5.1\n",
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import joblib\n",
    "import sagemaker\n",
    "print(sagemaker.__version__)\n",
    "print(joblib.__version__)\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc3d58",
   "metadata": {},
   "source": [
    "###  Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481b9455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:20.324370Z",
     "iopub.status.busy": "2025-08-22T08:12:20.324134Z",
     "iopub.status.idle": "2025-08-22T08:12:20.368288Z",
     "shell.execute_reply": "2025-08-22T08:12:20.367500Z",
     "shell.execute_reply.started": "2025-08-22T08:12:20.324349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   UDI                      10000 non-null  int64  \n",
      " 1   Product ID               10000 non-null  object \n",
      " 2   Type                     10000 non-null  object \n",
      " 3   Air temperature [K]      10000 non-null  float64\n",
      " 4   Process temperature [K]  10000 non-null  float64\n",
      " 5   Rotational speed [rpm]   10000 non-null  int64  \n",
      " 6   Torque [Nm]              10000 non-null  float64\n",
      " 7   Tool wear [min]          10000 non-null  int64  \n",
      " 8   Machine failure          10000 non-null  int64  \n",
      " 9   TWF                      10000 non-null  int64  \n",
      " 10  HDF                      10000 non-null  int64  \n",
      " 11  PWF                      10000 non-null  int64  \n",
      " 12  OSF                      10000 non-null  int64  \n",
      " 13  RNF                      10000 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "Columns: None\n",
      "Columns: ['UDI', 'Product ID', 'Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
      "First 3 rows:\n",
      "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
      "0    1     M14860    M                298.1                    308.6   \n",
      "1    2     L47181    L                298.2                    308.7   \n",
      "2    3     L47182    L                298.1                    308.5   \n",
      "\n",
      "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
      "0                    1551         42.8                0                0    0   \n",
      "1                    1408         46.3                3                0    0   \n",
      "2                    1498         49.4                5                0    0   \n",
      "\n",
      "   HDF  PWF  OSF  RNF  \n",
      "0    0    0    0    0  \n",
      "1    0    0    0    0  \n",
      "2    0    0    0    0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"ai4i2020.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.info()}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"First 3 rows:\\n{df.head(3)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af048e3e",
   "metadata": {},
   "source": [
    "### Preprocessing Manual Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7028cf",
   "metadata": {},
   "source": [
    "Let's import preprocessing function from preprocess.py and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689fa19f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:20.379816Z",
     "iopub.status.busy": "2025-08-22T08:12:20.379342Z",
     "iopub.status.idle": "2025-08-22T08:12:20.461610Z",
     "shell.execute_reply": "2025-08-22T08:12:20.460751Z",
     "shell.execute_reply.started": "2025-08-22T08:12:20.379786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Preprocessing\n",
      " Type  Unique Values after encoding:  [1 0 2]\n",
      "shape of data after dropping columns (10000, 12)\n",
      "DF columns after clean up Index(['Type', 'Air temperature (K)', 'Process temperature (K)',\n",
      "       'Rotational speed (rpm)', 'Torque (Nm)', 'Tool wear (min)',\n",
      "       'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF'],\n",
      "      dtype='object')\n",
      "## Handle Duplicates\n",
      "Total rows count: 10000\n",
      "Duplicated rows count: 0\n",
      "Duplicated rows percentage: 0.0\n",
      "After removing duplicates rows count: 10000\n",
      "## Handle NULL\n",
      "number of null values :  0\n",
      "After removing null rows count: 10000\n",
      "Number of samples that passed although failed: 18\n",
      "Number of samples that passed although failed after fix: 0\n",
      "Number of machine failures: 357\n",
      "Number of failures due to unknown reasons: 9\n",
      "Number of failures due to unknown reasons after fix: 0\n",
      "## Add Features\n",
      "columns after new feature :  Index(['Type', 'Air temperature (K)', 'Process temperature (K)',\n",
      "       'Rotational speed (rpm)', 'Torque (Nm)', 'Tool wear (min)',\n",
      "       'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Strain (minNm)',\n",
      "       'Power (W)', 'Temperature Difference (K)'],\n",
      "      dtype='object')\n",
      "## Drop Redudant Features\n",
      "columns after drop : Index(['Type', 'Rotational speed (rpm)', 'Tool wear (min)', 'Machine failure',\n",
      "       'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Strain (minNm)', 'Power (W)',\n",
      "       'Temperature Difference (K)'],\n",
      "      dtype='object')\n",
      "## Convert Int to Float for MLFlow\n",
      "# Splitting into train/test...\n",
      "# Processing Done\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocessing \n",
    "# since we write the preprocess script we can now import it into our notebook\n",
    "train, test= preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca208d98-4cba-4e31-bd0d-f863aefbf97e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:20.463326Z",
     "iopub.status.busy": "2025-08-22T08:12:20.462652Z",
     "iopub.status.idle": "2025-08-22T08:12:20.473687Z",
     "shell.execute_reply": "2025-08-22T08:12:20.472859Z",
     "shell.execute_reply.started": "2025-08-22T08:12:20.463302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Type                        10000 non-null  float64\n",
      " 1   Rotational speed (rpm)      10000 non-null  float64\n",
      " 2   Tool wear (min)             10000 non-null  float64\n",
      " 3   Machine failure             10000 non-null  float64\n",
      " 4   TWF                         10000 non-null  float64\n",
      " 5   HDF                         10000 non-null  float64\n",
      " 6   PWF                         10000 non-null  float64\n",
      " 7   OSF                         10000 non-null  float64\n",
      " 8   RNF                         10000 non-null  float64\n",
      " 9   Strain (minNm)              10000 non-null  float64\n",
      " 10  Power (W)                   10000 non-null  float64\n",
      " 11  Temperature Difference (K)  10000 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a276a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:20.476326Z",
     "iopub.status.busy": "2025-08-22T08:12:20.474420Z",
     "iopub.status.idle": "2025-08-22T08:12:33.276765Z",
     "shell.execute_reply": "2025-08-22T08:12:33.275832Z",
     "shell.execute_reply.started": "2025-08-22T08:12:20.476299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment  experiment  with run name  run\n",
      "\tMLflow Run ID : 42cad23dbad843c1920a95aec10a1db4\n",
      "\tRunning experiment: experiment, Run Name: run\n",
      "\tFinished: experiment  experiment  with run name  run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MultiOutputClassifier(estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                        random_state=42)),\n",
       " '42cad23dbad843c1920a95aec10a1db4',\n",
       " 0.9945,\n",
       " 0.8694362017804155)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train import run_experiment\n",
    "import mlflow\n",
    "import os \n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "run_experiment(df, \"experiment\",\"run\", \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87727fa3-32f8-4281-a9bc-26dc25cddf8a",
   "metadata": {},
   "source": [
    "**NOTE** we can use run_experiment mlruns to check whether our model is created properly in mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70624031",
   "metadata": {},
   "source": [
    "###  Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "927704d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:33.284452Z",
     "iopub.status.busy": "2025-08-22T08:12:33.284194Z",
     "iopub.status.idle": "2025-08-22T08:12:33.288859Z",
     "shell.execute_reply": "2025-08-22T08:12:33.287893Z",
     "shell.execute_reply.started": "2025-08-22T08:12:33.284430Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "base_folder = 'ai4i'      # e.g., 'users/my-name'\n",
    "experiment_name = \"ai4i-Experiment-manual\"  # e.g., 'my-experiment'\n",
    "model_name = \"ai4i-model\"  # e.g., 'my-model'\n",
    "tracking_server_name = \"Team16-MLFlow\"\n",
    "bucket_name=\"iti113-team16-bucket\" # s3://iti113-team16-bucket/ai4i/mlflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d95b6",
   "metadata": {},
   "source": [
    "### Create SageMaker and S3 Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f88d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:33.293623Z",
     "iopub.status.busy": "2025-08-22T08:12:33.293408Z",
     "iopub.status.idle": "2025-08-22T08:12:34.293752Z",
     "shell.execute_reply": "2025-08-22T08:12:34.293038Z",
     "shell.execute_reply.started": "2025-08-22T08:12:33.293603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your datasets will be versioned inside: s3://iti113-team16-bucket/ai4i/data/v1/data.csv\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sagemaker_client = None\n",
    "s3_client = None\n",
    "try:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sagemaker_client = boto3.client(\"sagemaker\")\n",
    "    s3_bucket = sagemaker_session.default_bucket()\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_data_key=f\"{base_folder}/data/v1/data.csv\"\n",
    "    s3_data_path = f\"s3://{bucket_name}/{s3_data_key}\"\n",
    "    s3_data_dir_uri = f\"s3://{bucket_name}/{base_folder}/data/v1\"\n",
    "    print(f\"Your datasets will be versioned inside: {s3_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SageMaker session or S3 client: {e}\")\n",
    "    s3_data_path = None\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not sagemaker_client or not s3_client:\n",
    "    raise Exception(\"Failed to initialize SageMaker session or S3 client.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb6953",
   "metadata": {},
   "source": [
    "### Connect to Tracking Server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62538491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:34.297685Z",
     "iopub.status.busy": "2025-08-22T08:12:34.297072Z",
     "iopub.status.idle": "2025-08-22T08:12:34.945936Z",
     "shell.execute_reply": "2025-08-22T08:12:34.944971Z",
     "shell.execute_reply.started": "2025-08-22T08:12:34.297663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "S3 Bucket: s3://iti113-team16-bucket/ai4i/data/v1/data.csv\n",
      "SageMaker Role ARN: arn:aws:iam::837028399719:role/iti113-team16-sagemaker-iti113-team16-domain-iti113-team16-Role\n",
      "MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "MLflow tracking URI set successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/22 08:12:34 INFO mlflow.tracking.fluent: Experiment with name 'ai4i-Experiment-manual' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI set to: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "MLflow experiment set to: 'ai4i-Experiment-manual'\n"
     ]
    }
   ],
   "source": [
    "mlflow_tracking_server_arn = None\n",
    "try:\n",
    "    response = sagemaker_client.describe_mlflow_tracking_server(\n",
    "        TrackingServerName=tracking_server_name\n",
    "    )\n",
    "    # ARN of MLflow Tracking Server\n",
    "    mlflow_tracking_server_arn = response['TrackingServerArn']\n",
    "    print(f\"Found MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find tracking server: {e}\")\n",
    "    mlflow_tracking_server_arn = None\n",
    "\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not mlflow_tracking_server_arn:\n",
    "    raise Exception(\"Failed to find MLflow Tracking Server.\")\n",
    "\n",
    "# IAM role for SageMaker execution\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"S3 Bucket: {s3_data_path}\")\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "\n",
    "# Connect to the MLflow Tracking Server\n",
    "# Set the MLflow tracking URI to managed server\n",
    "if mlflow_tracking_server_arn:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "    print(\"MLflow tracking URI set successfully.\")\n",
    "\n",
    "# Define an experiment name. If it doesn't exist, MLflow creates it.\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow experiment set to: '{experiment_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce0ece",
   "metadata": {},
   "source": [
    "### Run Experiments and Track\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410ef13",
   "metadata": {},
   "source": [
    "Let's run our experiments while varying the hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15be0a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:12:34.952658Z",
     "iopub.status.busy": "2025-08-22T08:12:34.952353Z",
     "iopub.status.idle": "2025-08-22T08:13:15.099814Z",
     "shell.execute_reply": "2025-08-22T08:13:15.099028Z",
     "shell.execute_reply.started": "2025-08-22T08:12:34.952628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment  ai4i-Experiment-manual  with run name  md4\n",
      "\tMLflow Run ID : 22c2345423214ef19fe6a5f79df110db\n",
      "\tRunning experiment: ai4i-Experiment-manual, Run Name: md4\n",
      "\tFinished: experiment  ai4i-Experiment-manual  with run name  md4\n",
      "üèÉ View run md4 at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/34/runs/22c2345423214ef19fe6a5f79df110db\n",
      "üß™ View experiment at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/34\n",
      "Starting experiment  ai4i-Experiment-manual  with run name  md5\n",
      "\tMLflow Run ID : e83df4ba9c7e4d528904792f2c8b2b23\n",
      "\tRunning experiment: ai4i-Experiment-manual, Run Name: md5\n",
      "\tFinished: experiment  ai4i-Experiment-manual  with run name  md5\n",
      "üèÉ View run md5 at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/34/runs/e83df4ba9c7e4d528904792f2c8b2b23\n",
      "üß™ View experiment at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/34\n",
      "Starting experiment  ai4i-Experiment-manual  with run name  md10\n",
      "\tMLflow Run ID : c7c8a9b6f0794645b43fab9a816f0f1b\n",
      "\tRunning experiment: ai4i-Experiment-manual, Run Name: md10\n",
      "\tFinished: experiment  ai4i-Experiment-manual  with run name  md10\n",
      "üèÉ View run md10 at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/34/runs/c7c8a9b6f0794645b43fab9a816f0f1b\n",
      "üß™ View experiment at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/34\n",
      "Starting experiment  ai4i-Experiment-manual  with run name  md100\n",
      "\tMLflow Run ID : 72263da969bc4e3387a91c23e055460b\n",
      "\tRunning experiment: ai4i-Experiment-manual, Run Name: md100\n",
      "\tFinished: experiment  ai4i-Experiment-manual  with run name  md100\n",
      "üèÉ View run md100 at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/34/runs/72263da969bc4e3387a91c23e055460b\n",
      "üß™ View experiment at: https://ap-southeast-1.experiments.sagemaker.aws/#/experiments/34\n",
      "Best run: md100 id: 72263da969bc4e3387a91c23e055460b with f2_score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Run experiments with different max_depth parameters\n",
    "#\n",
    "experiments={\n",
    "    \"md4\":4,\n",
    "    \"md5\":5,\n",
    "    \"md10\":10,\n",
    "    \"md100\":100\n",
    "}\n",
    "results = {}\n",
    "best_run_id = None\n",
    "best_run_name = None\n",
    "best_f2 = 0.0\n",
    "best_md_param = None\n",
    "for run_name, md_param in experiments.items():\n",
    "    model, run_id, accuracy_score, f2_score = run_experiment(df, experiment_name, run_name, model_name, max_depth=md_param)\n",
    "    results[run_name] = {\n",
    "        'run_id': run_id,\n",
    "        'accuracy': accuracy_score,\n",
    "        'f2': f2_score\n",
    "    }\n",
    "    if best_f2 < f2_score:\n",
    "        best_f2 = f2_score\n",
    "        best_run_id = run_id\n",
    "        best_run_name = run_name\n",
    "        best_md_param = md_param\n",
    "    elif best_f2 == f2_score:\n",
    "        print(f\"Found another run with same accuracy: {f2_score:.4f}\")\n",
    "        print(f\"run {best_run_name} vs run {run_name}\")\n",
    "        if best_md_param is None or md_param < best_md_param:\n",
    "            # Update the best run if the C parameter is lower\n",
    "            best_md_param = md_param\n",
    "            best_run_id = run_id\n",
    "            best_run_name = run_name\n",
    "            print(f\"\\t Updating best run to {run_name} with max_depth={md_param} and f2_score={f2_score:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\t Keeping best run {best_run_name} with smaller max_depth to have simpler model\")\n",
    "\n",
    "print(f\"Best run: {best_run_name} id: {best_run_id} with f2_score: {best_f2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b031e",
   "metadata": {},
   "source": [
    "### Model Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c9f28",
   "metadata": {},
   "source": [
    "The best model is the one with run_id stored in `best_run_id`\n",
    "Let us save it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d0fa512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:13:15.109249Z",
     "iopub.status.busy": "2025-08-22T08:13:15.108956Z",
     "iopub.status.idle": "2025-08-22T08:13:15.484375Z",
     "shell.execute_reply": "2025-08-22T08:13:15.483472Z",
     "shell.execute_reply.started": "2025-08-22T08:13:15.109227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model with run ID: 72263da969bc4e3387a91c23e055460b to S3\n",
      "\tRegistering model from URI: runs:/72263da969bc4e3387a91c23e055460b/ai4i-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ai4i-model' already exists. Creating a new version of this model...\n",
      "2025/08/22 08:13:15 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ai4i-model, version 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel 'ai4i-model' registered with version: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '10' of model 'ai4i-model'.\n"
     ]
    }
   ],
   "source": [
    "def mlflow_register_model(run_id):\n",
    "    print(f\"Saving model with run ID: {run_id} to S3\")\n",
    "    model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "    print(f\"\\tRegistering model from URI: {model_uri}\")\n",
    "    # Register the model to the MLflow Model Registry\n",
    "    reg_model = mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=model_name\n",
    "    )\n",
    "    print(f\"\\tModel '{model_name}' registered with version: {reg_model.version}\")\n",
    "    return reg_model\n",
    "\n",
    "\n",
    "registered_model = mlflow_register_model(best_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef6b94",
   "metadata": {},
   "source": [
    "Check Model has been Registered properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09893156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:13:15.488568Z",
     "iopub.status.busy": "2025-08-22T08:13:15.488239Z",
     "iopub.status.idle": "2025-08-22T08:13:15.684044Z",
     "shell.execute_reply": "2025-08-22T08:13:15.683178Z",
     "shell.execute_reply.started": "2025-08-22T08:13:15.488538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model S3 Artifact URI: s3://iti113-team16-bucket/ai4i/mlflow/34/72263da969bc4e3387a91c23e055460b/artifacts/ai4i-model\n",
      "Model Version No     : 10\n",
      "Model Version Name   : ai4i-model\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "model_version = client.get_model_version(model_name, registered_model.version)\n",
    "model_artifact_s3 = model_version.source\n",
    "model_version_no = model_version.version\n",
    "model_version_name = model_version.name\n",
    "print(\"Model S3 Artifact URI:\", model_artifact_s3)\n",
    "print(\"Model Version No     :\", model_version_no)\n",
    "print(\"Model Version Name   :\", model_version_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a7b2c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:13:15.686091Z",
     "iopub.status.busy": "2025-08-22T08:13:15.685699Z",
     "iopub.status.idle": "2025-08-22T08:13:18.243421Z",
     "shell.execute_reply": "2025-08-22T08:13:18.242515Z",
     "shell.execute_reply.started": "2025-08-22T08:13:15.686068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expect s3://iti113-team16-bucket/ai4i/mlflow/1/fc49513036cb442ea9eb764c32509bfa/artifacts/model\n",
      "Model artifact models:/ai4i-model/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e937b5c945b94fff930926612021b0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact models:/ai4i-model/10 downloaded to: /tmp/model\n",
      "Model archive created at: /tmp/model.tar.gz\n",
      "MultiOutputClassifier(estimator=RandomForestClassifier(max_depth=100,\n",
      "                                                       random_state=42))\n",
      "Uploading /tmp/model.tar.gz to s3 with key ai4i/models/ai4i-model-v10/model.tar.gz\n",
      "File /tmp/model.tar.gz uploaded to s3://sagemaker-ap-southeast-1-837028399719/ai4i/models/ai4i-model-v10/model.tar.gz\n",
      "‚úÖ Compressed model uploaded to: s3://sagemaker-ap-southeast-1-837028399719/ai4i/models/ai4i-model-v10/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "model_s3_uri = None\n",
    "def download_model_artifact(model_version_name,model_version_no, model_folder=\"/tmp/model\"):\n",
    "    \"\"\"\n",
    "    Download the model artifact from the MLflow Model Registry.\n",
    "    \"\"\"\n",
    "    artifact_uri=f\"models:/{model_version_name}/{model_version_no}\"\n",
    "    print(f\"Model artifact {artifact_uri}\")\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    mlflow.artifacts.download_artifacts(\n",
    "        artifact_uri=artifact_uri,\n",
    "        dst_path=model_folder\n",
    "    )\n",
    "    print(f\"Model artifact {artifact_uri} downloaded to: {model_folder}\")\n",
    "\n",
    "# Download the model artifact\n",
    "def create_model_archive(model_folder=\"/tmp/model\", model_tgz_path=\"/tmp/model.tar.gz\"):\n",
    "    \"\"\"\n",
    "    Create a tar.gz archive of the model folder.\n",
    "    \"\"\"\n",
    "    with tarfile.open(model_tgz_path, \"w:gz\") as tar:\n",
    "        tar.add(model_folder, arcname=\".\")\n",
    "    print(f\"Model archive created at: {model_tgz_path}\")\n",
    "\n",
    "def test_load_archive(model_folder=\"/tmp/model\"):\n",
    "    model=joblib.load(os.path.join(model_folder, \"model.pkl\"))\n",
    "    print(model)\n",
    "\n",
    "def upload_to_s3(local_file, model_version_name, model_version_no):\n",
    "    \"\"\"\n",
    "    Upload a local file to an S3 bucket.\n",
    "    \"\"\"\n",
    "    s3_key = f\"{base_folder}/models/{model_version_name}-v{model_version_no}/model.tar.gz\"\n",
    "    print(f\"Uploading {local_file} to s3 with key {s3_key}\")\n",
    "    model_s3_uri = None\n",
    "    try:\n",
    "        bucket = sagemaker_session.default_bucket() \n",
    "        s3_client.upload_file(local_file, bucket, s3_key)\n",
    "        model_s3_uri = f\"s3://{bucket}/{s3_key}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to S3: {e}\")\n",
    "    # minimize traceback in the output as we are not interested in the details\n",
    "    if not model_s3_uri:\n",
    "        raise Exception(\"Failed to upload model to S3.\")\n",
    "    print(f\"File {local_file} uploaded to {model_s3_uri}\")\n",
    "    return model_s3_uri\n",
    "\n",
    "# Create a compressed archive of the model folder\n",
    "model_folder=\"/tmp/model\"\n",
    "model_tgz_path=\"/tmp/model.tar.gz\"\n",
    "print(\"expect s3://iti113-team16-bucket/ai4i/mlflow/1/fc49513036cb442ea9eb764c32509bfa/artifacts/model\")\n",
    "download_model_artifact(model_version_name, model_version_no, model_folder)\n",
    "create_model_archive(model_folder, model_tgz_path)\n",
    "test_load_archive(model_folder)\n",
    "model_s3_uri = upload_to_s3(model_tgz_path, model_version_name, model_version_no)\n",
    "# Upload to S3\n",
    "print(\"‚úÖ Compressed model uploaded to:\", model_s3_uri)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d3af4-688b-4370-8beb-500c5c9e6f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T11:52:24.629739Z",
     "iopub.status.busy": "2025-08-20T11:52:24.629444Z",
     "iopub.status.idle": "2025-08-20T11:52:24.633423Z",
     "shell.execute_reply": "2025-08-20T11:52:24.632672Z",
     "shell.execute_reply.started": "2025-08-20T11:52:24.629717Z"
    }
   },
   "source": [
    "## Pipeline Automation For Preprocessing and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4dbf91",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf84bfc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:26.713123Z",
     "iopub.status.busy": "2025-08-22T08:50:26.712751Z",
     "iopub.status.idle": "2025-08-22T08:50:26.717198Z",
     "shell.execute_reply": "2025-08-22T08:50:26.716380Z",
     "shell.execute_reply.started": "2025-08-22T08:50:26.713098Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "model_name = \"ai4i-pipeline-model\"  # e.g., 'my-model'\n",
    "model_package_group_name = \"AI4IPipelineModels\"\n",
    "pipeline_name = \"AI4IClassifierPipeline\"\n",
    "# ----------------------\n",
    "base_folder = 'ai4i'      # e.g., 'users/my-name'\n",
    "experiment_name = \"ai4i-Experiment-pipeline\"  # e.g., 'my-experiment'\n",
    "model_name = \"ai4i-model\"  # e.g., 'my-model'\n",
    "tracking_server_name = \"Team16-MLFlow\"\n",
    "bucket_name=\"iti113-team16-bucket\" # s3://iti113-team16-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333828be",
   "metadata": {},
   "source": [
    "### Install dependencies and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a2b0a",
   "metadata": {},
   "source": [
    "#### Session setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af232277",
   "metadata": {},
   "source": [
    "Setup sagemaker and s3 session clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f679a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:30.810541Z",
     "iopub.status.busy": "2025-08-22T08:50:30.810006Z",
     "iopub.status.idle": "2025-08-22T08:50:31.720134Z",
     "shell.execute_reply": "2025-08-22T08:50:31.719212Z",
     "shell.execute_reply.started": "2025-08-22T08:50:30.810511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet will be stored inside: s3://iti113-team16-bucket/ai4i/data/v1/data.csv\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "sagemaker_client = None\n",
    "s3_client = None\n",
    "try:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sagemaker_client = boto3.client(\"sagemaker\")\n",
    "    s3_bucket = sagemaker_session.default_bucket()\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_data_key=f\"{base_folder}/data/v1/data.csv\"\n",
    "    s3_data_path = f\"s3://{bucket_name}/{s3_data_key}\"\n",
    "    s3_data_dir_uri = f\"s3://{bucket_name}/{base_folder}/data/v1\"\n",
    "    print(f\"DataSet will be stored inside: {s3_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SageMaker session or S3 client: {e}\")\n",
    "    s3_data_path = None\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not sagemaker_client or not s3_client:\n",
    "    raise Exception(\"Failed to initialize SageMaker session or S3 client.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfd1b6",
   "metadata": {},
   "source": [
    "Setup mlflow client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c43d27e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:33.546129Z",
     "iopub.status.busy": "2025-08-22T08:50:33.545840Z",
     "iopub.status.idle": "2025-08-22T08:50:33.728804Z",
     "shell.execute_reply": "2025-08-22T08:50:33.727894Z",
     "shell.execute_reply.started": "2025-08-22T08:50:33.546109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "SageMaker Role ARN: arn:aws:iam::837028399719:role/iti113-team16-sagemaker-iti113-team16-domain-iti113-team16-Role\n",
      "MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "MLflow tracking URI set successfully.\n",
      "MLflow tracking URI set to: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/Team16-MLFlow\n",
      "MLflow experiment set to: 'ai4i-Experiment-pipeline'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow_tracking_server_arn = None\n",
    "try:\n",
    "    response = sagemaker_client.describe_mlflow_tracking_server(\n",
    "        TrackingServerName=tracking_server_name\n",
    "    )\n",
    "    # ARN of MLflow Tracking Server\n",
    "    mlflow_tracking_server_arn = response['TrackingServerArn']\n",
    "    print(f\"Found MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find tracking server: {e}\")\n",
    "    mlflow_tracking_server_arn = None\n",
    "\n",
    "# minimize traceback in the output as we are not interested in the details\n",
    "if not mlflow_tracking_server_arn:\n",
    "    raise Exception(\"Failed to find MLflow Tracking Server.\")\n",
    "\n",
    "# IAM role for SageMaker execution\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")\n",
    "\n",
    "# Connect to the MLflow Tracking Server\n",
    "# Set the MLflow tracking URI to managed server\n",
    "if mlflow_tracking_server_arn:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_server_arn)\n",
    "    print(\"MLflow tracking URI set successfully.\")\n",
    "\n",
    "# Define an experiment name. If it doesn't exist, MLflow creates it.\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"MLflow experiment set to: '{experiment_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e6dda-51ff-4029-bca6-4ead406782fe",
   "metadata": {},
   "source": [
    "#### Upload DataSet To S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b96aa4c-acb2-4ce4-b775-4fcada322812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:36.592430Z",
     "iopub.status.busy": "2025-08-22T08:50:36.592019Z",
     "iopub.status.idle": "2025-08-22T08:50:36.776862Z",
     "shell.execute_reply": "2025-08-22T08:50:36.775839Z",
     "shell.execute_reply.started": "2025-08-22T08:50:36.592405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset v1.0 created and uploaded to: s3://iti113-team16-bucket/ai4i/data/v1/data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "if s3_data_path is None:\n",
    "    raise Exception(\"S3 data path is not set. Cannot proceed with dataset creation.\")\n",
    "df = pd.read_csv(\"ai4i2020.csv\")\n",
    "df.to_csv(s3_data_path, index=False)\n",
    "print(f\"Dataset v1.0 created and uploaded to: {s3_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699e1a3-1023-429c-8717-5679d80be9f5",
   "metadata": {},
   "source": [
    "Let us test whether we can load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b99a39b1-031a-416b-98b1-13c64f30aadb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:40.946395Z",
     "iopub.status.busy": "2025-08-22T08:50:40.946032Z",
     "iopub.status.idle": "2025-08-22T08:50:41.043497Z",
     "shell.execute_reply": "2025-08-22T08:50:41.042730Z",
     "shell.execute_reply.started": "2025-08-22T08:50:40.946371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded dataset v1.0:\n",
      "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
      "0    1     M14860    M                298.1                    308.6   \n",
      "\n",
      "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
      "0                    1551         42.8                0                0    0   \n",
      "\n",
      "   HDF  PWF  OSF  RNF  \n",
      "0    0    0    0    0  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_loaded = pd.read_csv(s3_data_path)\n",
    "    print(\"Successfully loaded dataset v1.0:\")\n",
    "    print(df_loaded.head(1))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"\\nPlease double-check that your bucket and folder names are correct in Step 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e4d1a",
   "metadata": {},
   "source": [
    "### Create the SageMaker Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a4b4939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:44.703435Z",
     "iopub.status.busy": "2025-08-22T08:50:44.703153Z",
     "iopub.status.idle": "2025-08-22T08:50:44.708360Z",
     "shell.execute_reply": "2025-08-22T08:50:44.707660Z",
     "shell.execute_reply.started": "2025-08-22T08:50:44.703414Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, TrainingInput\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.conditions import ConditionNot\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionEquals\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.parameters import ParameterFloat, ParameterString\n",
    "from sagemaker.model_metrics import ModelMetrics, FileSource\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02679f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:47.426067Z",
     "iopub.status.busy": "2025-08-22T08:50:47.425714Z",
     "iopub.status.idle": "2025-08-22T08:50:47.430223Z",
     "shell.execute_reply": "2025-08-22T08:50:47.429377Z",
     "shell.execute_reply.started": "2025-08-22T08:50:47.426043Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name_param = ParameterString(name=\"ExperimentName\", default_value=experiment_name)\n",
    "metric_threshold_param = ParameterFloat(name=\"F2Threshold\", default_value=0.70)\n",
    "pipeline_parameters = [experiment_name_param, metric_threshold_param]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0751ec",
   "metadata": {},
   "source": [
    "#### Processing Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "716b50f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:50.959629Z",
     "iopub.status.busy": "2025-08-22T08:50:50.958942Z",
     "iopub.status.idle": "2025-08-22T08:50:51.021337Z",
     "shell.execute_reply": "2025-08-22T08:50:51.020586Z",
     "shell.execute_reply.started": "2025-08-22T08:50:50.959601Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "processing_instance_type = \"ml.t3.medium\" # cheapest $0.063/hour\n",
    "preprocessor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, \"1.2-1\"),\n",
    "    command=[\n",
    "        \"python3\",\n",
    "    ],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"preprocess-data\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_preprocess = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=preprocessor,\n",
    "    inputs=[ProcessingInput(source=s3_data_dir_uri, destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"preprocess.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8554ae",
   "metadata": {},
   "source": [
    "#### Training Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ade9c770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:54.783785Z",
     "iopub.status.busy": "2025-08-22T08:50:54.783004Z",
     "iopub.status.idle": "2025-08-22T08:50:54.842674Z",
     "shell.execute_reply": "2025-08-22T08:50:54.841735Z",
     "shell.execute_reply.started": "2025-08-22T08:50:54.783754Z"
    }
   },
   "outputs": [],
   "source": [
    "training_instance_type = \"ml.t3.large\" # second cheapest $0.127/hour\n",
    "\n",
    "# Training Step\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"train.py\", \n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=training_instance_type,\n",
    "    role=role,\n",
    "    hyperparameters={\n",
    "        \"tracking_server_arn\": mlflow_tracking_server_arn,\n",
    "        \"experiment_name\": experiment_name_param,\n",
    "    },\n",
    "    py_version=\"py3\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    depends_on=[step_preprocess]  # Explicitly depends on the preprocess\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004d9f7",
   "metadata": {},
   "source": [
    "#### Evaluation Step Defintion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e8b2f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:50:57.591245Z",
     "iopub.status.busy": "2025-08-22T08:50:57.590598Z",
     "iopub.status.idle": "2025-08-22T08:50:57.644640Z",
     "shell.execute_reply": "2025-08-22T08:50:57.643749Z",
     "shell.execute_reply.started": "2025-08-22T08:50:57.591217Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "evaluation_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, \"1.2-1\"),\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"evaluate-model\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")],\n",
    "    code=\"evaluate.py\",  # SageMaker will handle uploading and running this script\n",
    "    job_arguments=[  # Pass arguments here instead of in command\n",
    "        \"--model-path\", \"/opt/ml/processing/model\",\n",
    "        \"--test-path\", \"/opt/ml/processing/test\",\n",
    "        \"--output-path\", \"/opt/ml/processing/evaluation\",\n",
    "        \"--model-package-group-name\", model_package_group_name,\n",
    "        \"--region\", \"ap-southeast-1\",\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    "    depends_on=[step_train]  # Explicitly depends on the train process\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4994b",
   "metadata": {},
   "source": [
    "#### Model Registration Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403732f",
   "metadata": {},
   "source": [
    "The model registration follows the following logic \n",
    "```bash\n",
    "if cond_no_registered \n",
    "   step_register_new\n",
    "else if cond_metric \n",
    "   step_register_better_model\n",
    "end if\n",
    "```\n",
    "where :\n",
    "- cond_no_registered check whether existing baseline model exist\n",
    "- cond_metric check whether new model has higher value of metric (F2) than existing baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb8dc392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:51:01.110433Z",
     "iopub.status.busy": "2025-08-22T08:51:01.109284Z",
     "iopub.status.idle": "2025-08-22T08:51:01.121069Z",
     "shell.execute_reply": "2025-08-22T08:51:01.119766Z",
     "shell.execute_reply.started": "2025-08-22T08:51:01.110405Z"
    }
   },
   "outputs": [],
   "source": [
    "# RegisterModel step (always defined, but executed conditionally)\n",
    "model_metrics_report = ModelMetrics(\n",
    "    model_statistics=FileSource(\n",
    "        s3_uri=step_eval.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "step_register_new = RegisterModel(\n",
    "    name=\"RegisterNewModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "step_register_better_model = RegisterModel(\n",
    "    name=\"RegisterBetterModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "\n",
    "# Conditions: check accuracy > threshold OR no model exists\n",
    "cond_metric = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"f2\"\n",
    "    ),\n",
    "    right=metric_threshold_param\n",
    ")\n",
    "\n",
    "cond_no_registered = ConditionEquals(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"baseline_exists\" # Check the key added to the report\n",
    "    ),\n",
    "    right=False # Condition is TRUE if baseline_exists is False\n",
    ")\n",
    "\n",
    "# Outer step: Checks for existence of registered model first\n",
    "step_cond_metric = ConditionStep(\n",
    "    name=\"CheckMetric\",\n",
    "    conditions=[cond_metric],\n",
    "    if_steps=[step_register_better_model], # Register model if metric (F2) is high\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "step_cond_no_registered = ConditionStep(\n",
    "    name=\"CheckIfModelExists\",\n",
    "    conditions=[cond_no_registered],\n",
    "    if_steps=[step_register_new], # Register model if no baseline exists\n",
    "    else_steps=[step_cond_metric], # Do nothing if a model exists and F2 was low\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d286d5",
   "metadata": {},
   "source": [
    "#### Pipeline Creation And Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd971683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:51:05.388819Z",
     "iopub.status.busy": "2025-08-22T08:51:05.388053Z",
     "iopub.status.idle": "2025-08-22T08:51:07.978333Z",
     "shell.execute_reply": "2025-08-22T08:51:07.977570Z",
     "shell.execute_reply.started": "2025-08-22T08:51:05.388791Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "# Define steps in the pipeline\n",
    "pipeline_steps = []\n",
    "pipeline_steps.append(step_preprocess)\n",
    "pipeline_steps.append(step_train)\n",
    "pipeline_steps.append(step_eval)\n",
    "pipeline_steps.append(step_cond_no_registered) \n",
    "# Define Pipeline\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=pipeline_parameters,\n",
    "    steps=pipeline_steps\n",
    ")\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b36b9",
   "metadata": {},
   "source": [
    "#### Pipeline Status and Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945d6b7-3339-449b-96fb-172ef4cc68ea",
   "metadata": {},
   "source": [
    "##### Pipeline Status Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47f10d7e-e90f-4e35-88ea-5d2426b9afd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:51:11.755529Z",
     "iopub.status.busy": "2025-08-22T08:51:11.755220Z",
     "iopub.status.idle": "2025-08-22T08:51:11.760739Z",
     "shell.execute_reply": "2025-08-22T08:51:11.759830Z",
     "shell.execute_reply.started": "2025-08-22T08:51:11.755508Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline_status(name)->str:\n",
    "    try:\n",
    "        response = sagemaker_client.describe_pipeline(\n",
    "            PipelineName=name\n",
    "        )\n",
    "        result= response[\"PipelineStatus\"]\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'ResourceNotFound':\n",
    "            result= (f\"Pipeline {name} not found {e}\")\n",
    "        else:\n",
    "            result= (f\"Unknown error {e.response} {type(e)}\")\n",
    "    return result\n",
    "def print_pipeline_status(name):\n",
    "    print(f\"Pipeline {name} is \",get_pipeline_status(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265c900-db70-4be9-a468-3d9789fbd35b",
   "metadata": {},
   "source": [
    "##### Pipeline Cleanup Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "340b48c2-3438-4fc2-994e-13b4c6e07069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:18:56.043991Z",
     "iopub.status.busy": "2025-08-22T08:18:56.043640Z",
     "iopub.status.idle": "2025-08-22T08:18:56.048929Z",
     "shell.execute_reply": "2025-08-22T08:18:56.048011Z",
     "shell.execute_reply.started": "2025-08-22T08:18:56.043967Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_pipeline(name)->str:\n",
    "    try:\n",
    "        response = sagemaker_client.delete_pipeline(\n",
    "            PipelineName=name\n",
    "        )\n",
    "        print(f\"Pipeline '{name}' deleted successfully.\")\n",
    "        print(response)\n",
    "    except sagemaker_client.exceptions.ResourceNotFoundException:\n",
    "        print(f\"Pipeline '{name}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811c7dd",
   "metadata": {},
   "source": [
    "##### Status check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "543a46ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:51:16.827086Z",
     "iopub.status.busy": "2025-08-22T08:51:16.826365Z",
     "iopub.status.idle": "2025-08-22T08:51:16.996419Z",
     "shell.execute_reply": "2025-08-22T08:51:16.995509Z",
     "shell.execute_reply.started": "2025-08-22T08:51:16.827061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline AI4IClassifierPipeline is  Active\n"
     ]
    }
   ],
   "source": [
    "# uncomment this to remove pipeline or call remove_pipeline(pipeline_name)\n",
    "#pipeline.delete()\n",
    "print_pipeline_status(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3b670",
   "metadata": {},
   "source": [
    "## Pipeline Automation For Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c7e1d1",
   "metadata": {},
   "source": [
    "This pipeline will be triggered when a new model is registered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f928d87-51dd-40d7-ae43-5617c5f6a6f2",
   "metadata": {},
   "source": [
    "### Deployment Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d330b6b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:25:49.390540Z",
     "iopub.status.busy": "2025-08-22T09:25:49.389985Z",
     "iopub.status.idle": "2025-08-22T09:25:51.091299Z",
     "shell.execute_reply": "2025-08-22T09:25:51.090631Z",
     "shell.execute_reply.started": "2025-08-22T09:25:49.390514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment pipeline ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:pipeline/AI4IDeployModelPipeline\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "import sagemaker\n",
    "deploy_pipeline_name = \"AI4IDeployModelPipeline\"\n",
    "# Define Parameters for the deployment pipeline\n",
    "# This will be provided by the EventBridge trigger\n",
    "model_package_arn_param = ParameterString(\n",
    "    name=\"ModelPackageArn\", default_value=\"\")\n",
    "role_param = ParameterString(name=\"ExecutionRole\", default_value=role)\n",
    "endpoint_name_param = ParameterString(\n",
    "    name=\"EndpointName\", default_value=\"AI4I-predictor-endpoint\")\n",
    "\n",
    "# Create a ScriptProcessor for deployment\n",
    "# Using a more recent scikit-learn version is generally a good idea\n",
    "deploy_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\n",
    "        \"sklearn\", sagemaker_session.boto_region_name, version=\"1.2-1\"),\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role_param,\n",
    "    base_job_name=\"deploy-registered-model\"\n",
    ")\n",
    "\n",
    "# Define the deployment step that takes the model ARN as an argument\n",
    "step_deploy = ProcessingStep(\n",
    "    name=\"DeployRegisteredModel\",\n",
    "    processor=deploy_processor,\n",
    "    code=\"deploy.py\",\n",
    "    job_arguments=[\n",
    "        \"--model-package-arn\", model_package_arn_param,\n",
    "        \"--role\", role_param,\n",
    "        \"--endpoint-name\", endpoint_name_param,\n",
    "        \"--region\", \"ap-southeast-1\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the independent deployment pipeline\n",
    "deploy_pipeline = Pipeline(\n",
    "    name=deploy_pipeline_name,\n",
    "    parameters=[model_package_arn_param, role_param, endpoint_name_param],\n",
    "    steps=[step_deploy]\n",
    ")\n",
    "\n",
    "# Create or update the pipeline definition\n",
    "# Capture the response which contains the ARN\n",
    "response = deploy_pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Extract the ARN from the response dictionary\n",
    "pipeline_arn = response['PipelineArn']\n",
    "\n",
    "print(f\"Deployment pipeline ARN: {pipeline_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99df4a9d-4d4b-4611-a6e1-cb37c8299903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:51:33.514605Z",
     "iopub.status.busy": "2025-08-22T08:51:33.514246Z",
     "iopub.status.idle": "2025-08-22T08:51:33.639755Z",
     "shell.execute_reply": "2025-08-22T08:51:33.638999Z",
     "shell.execute_reply.started": "2025-08-22T08:51:33.514581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline AI4IDeployModelPipeline is  Active\n"
     ]
    }
   ],
   "source": [
    "print_pipeline_status(deploy_pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4665078-306c-412d-878c-0cd4491290d3",
   "metadata": {},
   "source": [
    "## Deployment Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b6b0bba-4244-4763-a24e-a19796c470db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:25:56.204260Z",
     "iopub.status.busy": "2025-08-22T09:25:56.203740Z",
     "iopub.status.idle": "2025-08-22T09:25:56.209070Z",
     "shell.execute_reply": "2025-08-22T09:25:56.208149Z",
     "shell.execute_reply.started": "2025-08-22T09:25:56.204184Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def start_deploy_pipeline(model_package_arn):\n",
    "    deploy_pipeline_name = \"AI4IDeployModelPipeline\"\n",
    "    endpoint_name = \"AI4I-predictor-endpoint\"\n",
    "    now = datetime.now() # current date and time\n",
    "    now_str = now.strftime(\"%Y-%m-%d-%H-%M-%S\") # year-month-date_hour_minute_seconds e.g. 2025-08-20_11_30_05\n",
    "    response = sagemaker_client.start_pipeline_execution(\n",
    "        PipelineName=deploy_pipeline_name,\n",
    "        PipelineExecutionDisplayName=f\"{deploy_pipeline_name}-{now_str}\",\n",
    "        PipelineParameters=[\n",
    "            {\n",
    "                'Name': 'ModelPackageArn',\n",
    "                'Value': model_package_arn\n",
    "            }\n",
    "        ], # other parameter we use default values EndpointName = AI4I-predictor-endpoint defined in our pipeline definition above\n",
    "        PipelineExecutionDescription=f'Deploy image {model_package_arn} to {endpoint_name} on {now_str}'\n",
    "    )\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "603c2d27-a15f-4778-8fb5-0b6b8c15b8bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:26:01.359464Z",
     "iopub.status.busy": "2025-08-22T09:26:01.358902Z",
     "iopub.status.idle": "2025-08-22T09:26:01.670077Z",
     "shell.execute_reply": "2025-08-22T09:26:01.669083Z",
     "shell.execute_reply.started": "2025-08-22T09:26:01.359436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PipelineExecutionArn': 'arn:aws:sagemaker:ap-southeast-1:837028399719:pipeline/AI4IDeployModelPipeline/execution/mjw1ji8a8c2y', 'ResponseMetadata': {'RequestId': 'f80a4b46-6d76-4801-a9a6-aba243175c73', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'f80a4b46-6d76-4801-a9a6-aba243175c73', 'content-type': 'application/x-amz-json-1.1', 'content-length': '128', 'date': 'Fri, 22 Aug 2025 09:26:01 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "start_deploy_pipeline('arn:aws:sagemaker:ap-southeast-1:837028399719:model-package/AI4IPipelineModels/6') # change the last digit for model version i.e. /3 to /4 etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e8890ea9-920e-4a2c-adb9-f0ac39e48157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:26:04.421968Z",
     "iopub.status.busy": "2025-08-22T09:26:04.421550Z",
     "iopub.status.idle": "2025-08-22T09:26:04.609012Z",
     "shell.execute_reply": "2025-08-22T09:26:04.608151Z",
     "shell.execute_reply.started": "2025-08-22T09:26:04.421938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline AI4IDeployModelPipeline is  Active\n"
     ]
    }
   ],
   "source": [
    "# uncomment this to remove pipeline or call remove_pipeline(deploy_pipeline_name)\n",
    "#deploy_pipeline.delete()\n",
    "print_pipeline_status(deploy_pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e899a40-03eb-4525-b4ae-cf4f5883959c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Deployment Pipeline Event Bridge\n",
    "\n",
    "**NOTE** This cannot be run as we do not have permission"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2d73b94-4df9-47ab-8b9a-7a3b0f6ea1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T02:58:24.463429Z",
     "iopub.status.busy": "2025-08-22T02:58:24.462795Z",
     "iopub.status.idle": "2025-08-22T02:58:24.521880Z",
     "shell.execute_reply": "2025-08-22T02:58:24.518588Z",
     "shell.execute_reply.started": "2025-08-22T02:58:24.463399Z"
    }
   },
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize the EventBridge client\n",
    "events_client = boto3.client(\"events\")\n",
    "\n",
    "# Define the event pattern to listen for\n",
    "# This pattern triggers when a model package in your group has its status changed to \"Approved\"\n",
    "event_pattern = {\n",
    "    \"source\": [\"aws.sagemaker\"],\n",
    "    \"detail-type\": [\"SageMaker Model Package State Change\"],\n",
    "    \"detail\": {\n",
    "        \"ModelPackageGroupName\": [model_package_group_name], # From cell 10\n",
    "        \"ModelApprovalStatus\": [\"Approved\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the target for the rule (our deployment pipeline)\n",
    "# We need to map the event's detail to the pipeline's parameters\n",
    "target = {\n",
    "    \"Id\": \"AI4IDeployModelPipelineTarget\",\n",
    "    \"Arn\": pipeline_arn, # The ARN of the pipeline we just created\n",
    "    # \"RoleArn\": role, # The execution role for the pipeline\n",
    "    \"SageMakerPipelineParameters\": {\n",
    "        \"PipelineParameterList\": [\n",
    "            {\n",
    "                # Map the ARN from the event to the pipeline's \"ModelPackageArn\" parameter\n",
    "                \"Name\": \"ModelPackageArn\",\n",
    "                \"Value\": \"$.detail.ModelPackageArn\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create or update the EventBridge rule\n",
    "try:\n",
    "    rule_name = \"AI4I-Team16-TriggerDeploymentOnApproval\"\n",
    "    print(f\"Creating or updating EventBridge rule: {rule_name}\")\n",
    "    response = events_client.put_rule(\n",
    "        Name=rule_name,\n",
    "        EventPattern=json.dumps(event_pattern),\n",
    "        State=\"ENABLED\",\n",
    "        Description=\"Triggers the SageMaker pipeline to deploy a churn model upon approval.\"\n",
    "    )\n",
    "    \n",
    "    # Add the pipeline as a target for the rule\n",
    "    events_client.put_targets(Rule=rule_name, Targets=[target])\n",
    "    print(\"EventBridge rule created successfully!\")\n",
    "    print(\"Now, when a model is approved in the Model Registry, the deployment pipeline will trigger automatically.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating rule: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7404527",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Deployment Cloud Watch Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e72322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Enter the name of your SageMaker endpoint\n",
    "endpoint_name = \"AI4I-predictor-endpoint\"\n",
    "\n",
    "# The log group is created based on the endpoint name\n",
    "log_group_name = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "\n",
    "# Create a CloudWatch Logs client\n",
    "logs_client = boto3.client(\"logs\")\n",
    "\n",
    "print(f\"Searching for logs in: {log_group_name}\\n\")\n",
    "\n",
    "try:\n",
    "    # Find all log streams in the log group, ordered by the most recent\n",
    "    response = logs_client.describe_log_streams(\n",
    "        logGroupName=log_group_name,\n",
    "        orderBy='LastEventTime',\n",
    "        descending=True\n",
    "    )\n",
    "\n",
    "    log_streams = response.get(\"logStreams\", [])\n",
    "\n",
    "    if not log_streams:\n",
    "        print(\"No log streams found. The endpoint might not have processed any requests yet.\")\n",
    "    \n",
    "    # Loop through each stream and print its recent log events\n",
    "    for stream in log_streams:\n",
    "        stream_name = stream['logStreamName']\n",
    "        print(f\"--- Logs from stream: {stream_name} ---\")\n",
    "\n",
    "        # Get log events from the stream\n",
    "        log_events = logs_client.get_log_events(\n",
    "            logGroupName=log_group_name,\n",
    "            logStreamName=stream_name,\n",
    "            startFromHead=False,  # False gets recent logs first\n",
    "            limit=50  # Get up to 50 recent log events\n",
    "        )\n",
    "        \n",
    "        # Print events in chronological order\n",
    "        for event in reversed(log_events.get(\"events\", [])):\n",
    "            print(event['message'].strip())\n",
    "        \n",
    "        print(\"-\" * (len(stream_name) + 24), \"\\n\")\n",
    "\n",
    "except logs_client.exceptions.ResourceNotFoundException:\n",
    "    print(f\"Error: Log group '{log_group_name}' was not found.\")\n",
    "    print(\"Please check the endpoint name and ensure it has been invoked.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a580045-cca5-4f64-8591-6646f3cb5b74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:11:06.286492Z",
     "iopub.status.busy": "2025-08-22T08:11:06.285906Z",
     "iopub.status.idle": "2025-08-22T08:11:06.289611Z",
     "shell.execute_reply": "2025-08-22T08:11:06.289016Z",
     "shell.execute_reply.started": "2025-08-22T08:11:06.286461Z"
    }
   },
   "source": [
    "# DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f838be4a-7a85-464c-993a-a20467c2904a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T09:20:28.227428Z",
     "iopub.status.busy": "2025-08-22T09:20:28.227143Z",
     "iopub.status.idle": "2025-08-22T09:20:28.365321Z",
     "shell.execute_reply": "2025-08-22T09:20:28.364532Z",
     "shell.execute_reply.started": "2025-08-22T09:20:28.227408Z"
    }
   },
   "outputs": [],
   "source": [
    "s3_client.download_file(\"sagemaker-ap-southeast-1-837028399719\",\"pipelines-y5yyry3duggq-TrainModel-v51MRiQxrV/output/model.tar.gz\",\"model.tgz\") \n",
    "#s3://sagemaker-ap-southeast-1-837028399719/pipelines-y5yyry3duggq-TrainModel-v51MRiQxrV/output/model.tar.gz -> v6\n",
    "#s3://sagemaker-ap-southeast-1-837028399719/pipelines-jeugjlh6g5ai-TrainModel-8r4dqkoiGg/output/model.tar.gz\n",
    "#s3://sagemaker-ap-southeast-1-837028399719/pipelines-tqo6f49xi338-TrainModel-xoj6osopVH/output/model.tar.gz\n",
    "#s3://sagemaker-ap-southeast-1-837028399719/pipelines-w56ultqe3jg0-TrainModel-FQfJFrlqsP/output/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0159be2-199a-407f-91ce-83c2875da40c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:13:25.156901Z",
     "iopub.status.busy": "2025-08-22T08:13:25.155983Z",
     "iopub.status.idle": "2025-08-22T08:13:25.160765Z",
     "shell.execute_reply": "2025-08-22T08:13:25.159963Z",
     "shell.execute_reply.started": "2025-08-22T08:13:25.156868Z"
    }
   },
   "outputs": [],
   "source": [
    "#s3_client.download_file(\"sagemaker-ap-southeast-1-837028399719\",\"selected-model/model.tar.gz\",\"selected_model.tgz\") #s3://sagemaker-ap-southeast-1-837028399719/selected-model/model.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b76d4ae-b601-4647-874f-afaf23f1f9ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:13:25.163456Z",
     "iopub.status.busy": "2025-08-22T08:13:25.161567Z",
     "iopub.status.idle": "2025-08-22T08:13:25.166330Z",
     "shell.execute_reply": "2025-08-22T08:13:25.165652Z",
     "shell.execute_reply.started": "2025-08-22T08:13:25.163432Z"
    }
   },
   "outputs": [],
   "source": [
    "# sagemaker_session.delete_endpoint_config( \"AI4I-predictor-endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26ef516a-1175-4e02-9621-c55c6ef96772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T08:13:25.168417Z",
     "iopub.status.busy": "2025-08-22T08:13:25.167348Z",
     "iopub.status.idle": "2025-08-22T08:13:25.171678Z",
     "shell.execute_reply": "2025-08-22T08:13:25.170990Z",
     "shell.execute_reply.started": "2025-08-22T08:13:25.168385Z"
    }
   },
   "outputs": [],
   "source": [
    "# sagemaker_session.delete_endpoint( \"AI4I-predictor-endpoint\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
